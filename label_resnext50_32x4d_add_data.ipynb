{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import easydict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os.path import join as opj\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, grad_scaler\n",
    "from torchvision import transforms\n",
    "from torch import Tensor\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.cuda.amp as amp\n",
    "from adamp import AdamP, SGDP\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  file_name       class state            label  encoder_label\n",
      "0           0  10000.png  transistor  good  transistor-good             72\n",
      "1           1  10001.png     capsule  good     capsule-good             15\n",
      "2           2  10002.png  transistor  good  transistor-good             72\n",
      "3           3  10003.png        wood  good        wood-good             76\n",
      "4           4  10004.png      bottle  good      bottle-good              3\n",
      "   index  file_name\n",
      "0      0  20000.png\n",
      "1      1  20001.png\n",
      "2      2  20002.png\n",
      "3      3  20003.png\n",
      "4      4  20004.png\n",
      "(8813, 6)\n",
      "(2154, 2)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './open'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train_df_add_data.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test_df.csv'))\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hazelnut-good              391\n",
       "screw-good                 320\n",
       "carpet-good                280\n",
       "pill-good                  267\n",
       "grid-good                  264\n",
       "                          ... \n",
       "wood-hole                   40\n",
       "transistor-cut_lead         40\n",
       "wood-liquid                 40\n",
       "transistor-damaged_case     40\n",
       "wood-color                  32\n",
       "Name: label, Length: 88, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['transistor-good', 'capsule-good', 'wood-good', 'bottle-good',\n",
       "       'screw-good', 'cable-bent_wire', 'carpet-hole', 'hazelnut-good',\n",
       "       'pill-pill_type', 'cable-good', 'metal_nut-scratch', 'pill-good',\n",
       "       'screw-thread_side', 'zipper-fabric_border', 'leather-good',\n",
       "       'pill-scratch', 'toothbrush-good', 'hazelnut-crack',\n",
       "       'screw-manipulated_front', 'zipper-good', 'tile-good',\n",
       "       'carpet-good', 'metal_nut-good', 'bottle-contamination',\n",
       "       'grid-good', 'zipper-split_teeth', 'pill-crack', 'wood-combined',\n",
       "       'pill-color', 'screw-thread_top', 'cable-missing_cable',\n",
       "       'capsule-squeeze', 'zipper-rough', 'capsule-crack', 'capsule-poke',\n",
       "       'metal_nut-flip', 'carpet-metal_contamination', 'metal_nut-color',\n",
       "       'transistor-bent_lead', 'zipper-fabric_interior', 'leather-fold',\n",
       "       'tile-glue_strip', 'screw-scratch_neck', 'screw-scratch_head',\n",
       "       'hazelnut-cut', 'bottle-broken_large', 'bottle-broken_small',\n",
       "       'leather-cut', 'cable-cut_outer_insulation',\n",
       "       'zipper-squeezed_teeth', 'toothbrush-defective',\n",
       "       'cable-cut_inner_insulation', 'pill-contamination',\n",
       "       'cable-missing_wire', 'carpet-thread', 'grid-broken',\n",
       "       'pill-faulty_imprint', 'hazelnut-hole', 'leather-glue',\n",
       "       'leather-poke', 'transistor-damaged_case', 'wood-scratch',\n",
       "       'tile-gray_stroke', 'capsule-faulty_imprint', 'grid-glue',\n",
       "       'zipper-combined', 'carpet-color', 'grid-bent', 'pill-combined',\n",
       "       'hazelnut-print', 'cable-combined', 'capsule-scratch',\n",
       "       'metal_nut-bent', 'zipper-broken_teeth', 'tile-oil',\n",
       "       'transistor-misplaced', 'grid-thread', 'grid-metal_contamination',\n",
       "       'carpet-cut', 'wood-color', 'cable-cable_swap', 'tile-crack',\n",
       "       'leather-color', 'cable-poke_insulation', 'transistor-cut_lead',\n",
       "       'wood-hole', 'tile-rough', 'wood-liquid'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1\"  # Set the GPUs 2 and 3 to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = len(train_df.encoder_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {'exp_num':'0',\n",
    "     \n",
    "     # Path settings\n",
    "     'data_path':'./open',\n",
    "     'Kfold':5,\n",
    "     'model_path':'label_results_resnext50_32x4d/',\n",
    "     'image_type':'train_1024', \n",
    "     'class_num' : class_num,\n",
    "\n",
    "     # Model parameter settings\n",
    "     'model_name':'resnext50_32x4d',\n",
    "     'drop_path_rate':0.2,\n",
    "     \n",
    "     # Training parameter settings\n",
    "     ## Base Parameter\n",
    "     'img_size':512,\n",
    "     'batch_size':16,\n",
    "     'epochs':100,\n",
    "     'optimizer':'Lamb',\n",
    "     'initial_lr':5e-4,\n",
    "     'weight_decay':1e-3,\n",
    "\n",
    "     ## Augmentation\n",
    "     'aug_ver':2,\n",
    "\n",
    "     ## Scheduler (OnecycleLR)\n",
    "     'scheduler':'Reduce',\n",
    "     'warm_epoch':3,\n",
    "     'max_lr':1e-3,\n",
    "\n",
    "     ### Cosine Annealing\n",
    "     'min_lr':5e-5,\n",
    "     'tmax':145,\n",
    "\n",
    "     ## etc.\n",
    "     'patience': 7,\n",
    "     'clipping':None,\n",
    "\n",
    "     # Hardware settings\n",
    "     'amp':True,\n",
    "     'multi_gpu':True,\n",
    "     'logging':False,\n",
    "     'num_workers':4,\n",
    "     'seed':42\n",
    "     \n",
    "     \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimzier(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        \n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
    "\n",
    "# Logging\n",
    "def get_root_logger(logger_name='basicsr',\n",
    "                    log_level=logging.INFO,\n",
    "                    log_file=None):\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    # if the logger has been initialized, just return it\n",
    "    if logger.hasHandlers():\n",
    "        return logger\n",
    "\n",
    "    format_str = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(format=format_str, level=log_level)\n",
    "\n",
    "    if log_file is not None:\n",
    "        file_handler = logging.FileHandler(log_file, 'w')\n",
    "        file_handler.setFormatter(logging.Formatter(format_str))\n",
    "        file_handler.setLevel(log_level)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "class AvgMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.losses.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(transforms.RandomRotation):\n",
    "    def __init__(self, p: float, degrees: int):\n",
    "        super(RandomRotation, self).__init__(degrees)\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, img):\n",
    "        if torch.rand(1) < self.p:\n",
    "            fill = self.fill\n",
    "            if isinstance(img, Tensor):\n",
    "                if isinstance(fill, (int, float)):\n",
    "                    fill = [float(fill)] * F.get_image_num_channels(img)\n",
    "                else:\n",
    "                    fill = [float(f) for f in fill]\n",
    "            angle = self.get_params(self.degrees)\n",
    "\n",
    "            img = F.rotate(img, angle, self.resample, self.expand, self.center, fill)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.img_path = df['file_name'].values\n",
    "        self.target = df['encoder_label'].values \n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Dataset size:{len(self.img_path)}')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = Image.open(opj('./open/train_add_data/', self.img_path[idx])).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        target = self.target[idx]\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "class Test_dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.img_path = df['file_name'].values\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Test Dataset size:{len(self.img_path)}')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(opj('./open/test/', self.img_path[idx])).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "def get_loader(df, phase: str, batch_size, shuffle,\n",
    "               num_workers, transform):\n",
    "    if phase == 'test':\n",
    "        dataset = Test_dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    else:\n",
    "        dataset = Train_Dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=False)\n",
    "    return data_loader\n",
    "\n",
    "def get_train_augmentation(img_size, ver):\n",
    "    if ver==1: # for validset\n",
    "        transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    if ver == 2:\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.3),\n",
    "                transforms.RandomVerticalFlip(p=0.3),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "                transforms.RandomAffine((-20,20)),\n",
    "                RandomRotation(0.5, degrees=5),\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "    \n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.model_ft = timm.create_model( # timm ImageNet pre-trained 모델 load\n",
    "            args.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes = 88, drop_path_rate=args.drop_path_rate\n",
    "        )\n",
    "\n",
    "#         self.model_ft = coatnet_3()\n",
    "#         num_ftrs = self.model_ft.fc.in_features\n",
    "#         self.model_ft.fc = nn.Linear(num_ftrs, args.class_num)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model_ft(x)\n",
    "        return out\n",
    "\n",
    "class Network_test(nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super().__init__()\n",
    "        self.model_ft = timm.create_model( # timm ImageNet pre-trained 모델 load\n",
    "            encoder_name,\n",
    "            pretrained=True,\n",
    "            num_classes = 88, drop_path_rate=args.drop_path_rate\n",
    "        )\n",
    "\n",
    "#         self.model_ft = coatnet_3()\n",
    "#         num_ftrs = self.model_ft.fc.in_features\n",
    "#         self.model_ft.fc = nn.Linear(num_ftrs, args.class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model_ft(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: tensor([ 4.8875,  4.4432,  4.4432,  1.8708,  6.9821,  8.1458,  8.1458,  6.9821,\n",
      "         9.7750,  1.7455,  8.1458,  9.7750,  9.7750,  4.0729,  4.4432,  1.7854,\n",
      "         4.4432,  4.0729,  4.8875,  4.8875,  5.4306,  1.3964,  5.4306,  5.4306,\n",
      "         4.8875,  8.1458,  8.1458,  8.1458,  1.4811,  8.1458,  8.1458,  5.4306,\n",
      "         5.4306,  1.0000,  5.4306,  5.4306,  4.8875,  4.8875,  5.4306,  4.8875,\n",
      "         1.5959,  5.4306,  3.7596,  4.4432,  4.0729,  1.7773,  4.0729,  3.7596,\n",
      "         5.4306,  4.4432,  3.7596,  4.8875,  1.4644,  9.7750,  4.0729,  1.2219,\n",
      "         4.0729,  4.0729,  3.7596,  4.0729,  4.0729,  5.4306,  5.4306,  1.7000,\n",
      "         6.1094,  5.4306,  6.1094,  3.2583,  6.5167,  9.7750,  9.7750,  9.7750,\n",
      "         1.8357,  9.7750, 12.2188,  8.1458,  1.5830,  9.7750,  9.7750,  4.4432,\n",
      "         4.8875,  6.1094,  5.4306,  6.1094,  1.6292,  5.4306,  5.4306,  6.1094],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# # weighted crossentropy loss를 위한 weight 계산 함수\n",
    "\n",
    "class_num = train_df.groupby([\"encoder_label\"])[\"encoder_label\"].count().tolist()\n",
    "class_weight = torch.tensor(np.max(class_num) / class_num).to(\"cuda\", dtype=torch.float)\n",
    "print(f\"class_weight: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "class Lookahead(Optimizer):\n",
    "    def __init__(self, optimizer, k=5, alpha=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = defaultdict(dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "        for group in self.param_groups:\n",
    "            group[\"counter\"] = 0\n",
    "    \n",
    "    def update(self, group):\n",
    "        for fast in group[\"params\"]:\n",
    "            param_state = self.state[fast]\n",
    "            if \"slow_param\" not in param_state:\n",
    "                param_state[\"slow_param\"] = torch.zeros_like(fast.data)\n",
    "                param_state[\"slow_param\"].copy_(fast.data)\n",
    "            slow = param_state[\"slow_param\"]\n",
    "            slow += (fast.data - slow) * self.alpha\n",
    "            fast.data.copy_(slow)\n",
    "    \n",
    "    def update_lookahead(self):\n",
    "        for group in self.param_groups:\n",
    "            self.update(group)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = self.optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            if group[\"counter\"] == 0:\n",
    "                self.update(group)\n",
    "            group[\"counter\"] += 1\n",
    "            if group[\"counter\"] >= self.k:\n",
    "                group[\"counter\"] = 0\n",
    "        return loss\n",
    "\n",
    "    def state_dict(self):\n",
    "        fast_state_dict = self.optimizer.state_dict()\n",
    "        slow_state = {\n",
    "            (id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict[\"state\"]\n",
    "        param_groups = fast_state_dict[\"param_groups\"]\n",
    "        return {\n",
    "            \"fast_state\": fast_state,\n",
    "            \"slow_state\": slow_state,\n",
    "            \"param_groups\": param_groups,\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        slow_state_dict = {\n",
    "            \"state\": state_dict[\"slow_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        fast_state_dict = {\n",
    "            \"state\": state_dict[\"fast_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.optimizer.load_state_dict(fast_state_dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        param_group[\"counter\"] = 0\n",
    "        self.optimizer.add_param_group(param_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    https://dacon.io/competitions/official/235585/codeshare/1796\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=2.0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        # print(self.gamma)\n",
    "        self.eps = eps\n",
    "        self.ce = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, args, save_path):\n",
    "        '''\n",
    "        args: arguments\n",
    "        save_path: Model 가중치 저장 경로\n",
    "        '''\n",
    "        super(Trainer, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Logging\n",
    "        log_file = os.path.join(save_path, 'log.log')\n",
    "        self.logger = get_root_logger(logger_name='IR', log_level=logging.INFO, log_file=log_file)\n",
    "        self.logger.info(args)\n",
    "        # self.logger.info(args.tag)\n",
    "\n",
    "        # Train, Valid Set load\n",
    "        ############################################################################\n",
    "        if args.step == 0 :\n",
    "            df_train = pd.read_csv(opj(args.data_path, 'train_df_add_data.csv'))\n",
    "        else :\n",
    "            df_train = pd.read_csv(opj(args.data_path, f'train_{args.step}step.csv'))\n",
    "\n",
    "#         if args.image_type is not None:\n",
    "#             df_train['img_path'] = df_train['img_path'].apply(lambda x:x.replace('train_imgs', args.image_type))\n",
    "#             df_train['img_path'] = df_train['img_path'].apply(lambda x:x.replace('test_imgs', 'test_1024'))\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=args.Kfold, shuffle=True, random_state=args.seed)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(df_train)), y=df_train['encoder_label'])):\n",
    "            df_train.loc[val_idx, 'fold'] = fold\n",
    "        val_idx = list(df_train[df_train['fold'] == int(args.fold)].index)\n",
    "\n",
    "        df_val = df_train[df_train['fold'] == args.fold].reset_index(drop=True)\n",
    "        df_train = df_train[df_train['fold'] != args.fold].reset_index(drop=True)\n",
    "\n",
    "        # Augmentation\n",
    "        self.train_transform = get_train_augmentation(img_size=args.img_size, ver=args.aug_ver)\n",
    "        self.test_transform = get_train_augmentation(img_size=args.img_size, ver=1)\n",
    "\n",
    "        # TrainLoader\n",
    "        self.train_loader = get_loader(df_train, phase='train', batch_size=args.batch_size, shuffle=True,\n",
    "                                       num_workers=args.num_workers, transform=self.train_transform)\n",
    "        self.val_loader = get_loader(df_val, phase='train', batch_size=args.batch_size, shuffle=False,\n",
    "                                       num_workers=args.num_workers, transform=self.test_transform)\n",
    "\n",
    "        # Network\n",
    "        self.model = Network(args).to(self.device)\n",
    "\n",
    "        # Loss\n",
    "#         self.criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "        self.criterion = FocalLoss()\n",
    "#         self.criterion = CutMixCrossEntropyLoss(True)\n",
    "        \n",
    "        # Optimizer & Scheduler\n",
    "#         self.optimizer = Lookahead(torch.optim.Adam(self.model.parameters(), lr=args.initial_lr), k=5, alpha=0.5)\n",
    "        self.optimizer = optim.Lamb(self.model.parameters(), lr=args.initial_lr)\n",
    "        \n",
    "        iter_per_epoch = len(self.train_loader)\n",
    "        self.warmup_scheduler = WarmUpLR(self.optimizer, iter_per_epoch * args.warm_epoch)\n",
    "\n",
    "        if args.scheduler == 'step':\n",
    "            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=args.milestone, gamma=args.lr_factor, verbose=True)\n",
    "        elif args.scheduler == 'cos':\n",
    "            tmax = args.tmax # half-cycle \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max = tmax, eta_min=args.min_lr, verbose=True)\n",
    "        elif args.scheduler == 'cycle':\n",
    "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=args.max_lr, steps_per_epoch=iter_per_epoch, epochs=args.epochs)\n",
    "        else:\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=3, factor=0.2, mode=\"max\", verbose=True)\n",
    "            \n",
    "        if args.multi_gpu:\n",
    "            self.model = nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "        # Train / Validate\n",
    "        best_loss = np.inf\n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        early_stopping = 0\n",
    "        start = time.time()\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            if args.scheduler == 'cos':\n",
    "                if epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Training\n",
    "            train_loss, train_acc, train_f1 = self.training(args)\n",
    "\n",
    "            # Model weight in Multi_GPU or Single GPU\n",
    "            state_dict= self.model.module.state_dict() if args.multi_gpu else self.model.state_dict()\n",
    "\n",
    "            # Validation\n",
    "            val_loss, val_acc, val_f1 = self.validate(args, phase='val')\n",
    "\n",
    "            # Save models\n",
    "            if val_loss < best_loss:\n",
    "                early_stopping = 0\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_acc = val_acc\n",
    "                best_f1 = val_f1\n",
    "\n",
    "                torch.save({'epoch':epoch,\n",
    "                            'state_dict':state_dict,\n",
    "                            'optimizer': self.optimizer.state_dict(),\n",
    "                            'scheduler': self.scheduler.state_dict(),\n",
    "                    }, os.path.join(save_path, 'best_model.pth'))\n",
    "                self.logger.info(f'-----------------SAVE:{best_epoch}epoch----------------')\n",
    "            else:\n",
    "                early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if early_stopping == args.patience:\n",
    "                break\n",
    "\n",
    "        self.logger.info(f'\\nBest Val Epoch:{best_epoch} | Val Loss:{best_loss:.4f} | Val Acc:{best_acc:.4f} | Val F1:{best_f1:.4f}')\n",
    "        end = time.time()\n",
    "        self.logger.info(f'Total Process time:{(end - start) / 60:.3f}Minute')\n",
    "\n",
    "    # Training\n",
    "    def training(self, args):\n",
    "        self.model.train()\n",
    "        train_loss = AvgMeter()\n",
    "        train_acc = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        scaler = grad_scaler.GradScaler()\n",
    "        \n",
    "        for i, (images, targets) in enumerate(tqdm(self.train_loader)):\n",
    "            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "            targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            if self.epoch <= args.warm_epoch:\n",
    "                self.warmup_scheduler.step()\n",
    "\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "    \n",
    "            if args.amp:\n",
    "                with autocast():\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, targets)\n",
    "                    \n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Gradient Clipping\n",
    "                if args.clipping is not None:\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if args.scheduler == 'cycle':\n",
    "                if self.epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Metric\n",
    "            train_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "            targets_list.extend(targets.cpu().detach().numpy())\n",
    "            # log\n",
    "            train_loss.update(loss.item(), n=images.size(0))\n",
    "\n",
    "        train_acc /= len(self.train_loader.dataset)\n",
    "        train_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "        self.logger.info(f'Epoch:[{self.epoch:03d}/{args.epochs:03d}]')\n",
    "        self.logger.info(f'Train Loss:{train_loss.avg:.3f} | Acc:{train_acc:.4f} | F1:{train_f1:.4f}')\n",
    "        return train_loss.avg, train_acc, train_f1\n",
    "            \n",
    "    # Validation or Dev\n",
    "    def validate(self, args, phase='val'):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = AvgMeter()\n",
    "            val_acc = 0\n",
    "            preds_list = []\n",
    "            targets_list = []\n",
    "\n",
    "            for i, (images, targets) in enumerate(self.val_loader):\n",
    "                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "                targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "\n",
    "                # Metric\n",
    "                val_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "                preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "                targets_list.extend(targets.cpu().detach().numpy())\n",
    "\n",
    "                # log\n",
    "                val_loss.update(loss.item(), n=images.size(0))\n",
    "            val_acc /= len(self.val_loader.dataset)\n",
    "            val_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "            self.logger.info(f'{phase} Loss:{val_loss.avg:.3f} | Acc:{val_acc:.4f} | F1:{val_f1:.4f}')\n",
    "        return val_loss.avg, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print('<---- Training Params ---->')\n",
    "    \n",
    "    # Random Seed\n",
    "    seed = args.seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    save_path = os.path.join(args.model_path, (args.exp_num).zfill(3))\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    Trainer(args, save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sub = pd.read_csv('./open/sample_submission.csv')\n",
    "df_train = pd.read_csv('./open/train_df_add_data.csv')\n",
    "df_test = pd.read_csv('./open/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder_name, test_loader, device, model_path):\n",
    "    model = Network_test(encoder_name).to(device)\n",
    "    model.load_state_dict(torch.load(opj(model_path, 'best_model.pth'))['state_dict'])\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = torch.as_tensor(images, device=device, dtype=torch.float32)\n",
    "            preds = model(images)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            preds_list.extend(preds.cpu().tolist())\n",
    "\n",
    "    return np.array(preds_list)\n",
    "\n",
    "def ensemble_5fold(model_path_list, test_loader, device):\n",
    "    predict_list = []\n",
    "    for model_path in model_path_list:\n",
    "        prediction = predict(encoder_name= 'resnext50_32x4d', test_loader = test_loader, device = device, model_path = model_path)\n",
    "        predict_list.append(prediction)\n",
    "    ensemble = (predict_list[0] + predict_list[1] + predict_list[2] + predict_list[3] + predict_list[4])/len(predict_list)\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "def make_pseudo_df(train_df, test_df, ensemble, step, threshold = 0.9, z_sample = 500): \n",
    "    train_df_copy = train_df.copy()\n",
    "    test_df_copy = test_df.copy()\n",
    "\n",
    "    test_df_copy['disease'] = np.nan\n",
    "    test_df_copy['disease_code'] = ensemble.argmax(axis=1)\n",
    "    pseudo_test_df = test_df_copy.iloc[np.where(ensemble > threshold)[0]].reset_index(drop=True)\n",
    "    z_idx  = pseudo_test_df[pseudo_test_df['disease_code'] == 0].sample(n=z_sample, random_state=42).index.tolist()\n",
    "    ot_idx = pseudo_test_df[pseudo_test_df['disease_code'].isin([*range(1,8)])].index.tolist()\n",
    "    pseudo_test_df = pseudo_test_df.iloc[z_idx + ot_idx]\n",
    "\n",
    "    train_df_copy = train_df_copy.append(pseudo_test_df, ignore_index=True).reset_index(drop=True) # reset_index\n",
    "    # print(f'Make train_{step}step.csv')\n",
    "    train_df_copy.to_csv(f'../data/train_{step}step.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 10:42:03,984 INFO: {'exp_num': '0', 'data_path': './open', 'Kfold': 5, 'model_path': 'label_results_resnext50_32x4d/', 'image_type': 'train_1024', 'class_num': 88, 'model_name': 'resnext50_32x4d', 'drop_path_rate': 0.2, 'img_size': 512, 'batch_size': 16, 'epochs': 100, 'optimizer': 'Lamb', 'initial_lr': 0.0005, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'Reduce', 'warm_epoch': 3, 'max_lr': 0.001, 'min_lr': 5e-05, 'tmax': 145, 'patience': 7, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Dataset size:7050\n",
      "Dataset size:1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 10:42:04,330 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnext50_32x4d_a1h-0146ab0a.pth)\n",
      "100%|██████████| 441/441 [02:47<00:00,  2.64it/s]\n",
      "2022-05-03 10:44:51,861 INFO: Epoch:[001/100]\n",
      "2022-05-03 10:44:51,861 INFO: Train Loss:4.354 | Acc:0.0326 | F1:0.0138\n",
      "2022-05-03 10:45:16,001 INFO: val Loss:4.312 | Acc:0.1503 | F1:0.0383\n",
      "2022-05-03 10:45:16,619 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.80it/s]\n",
      "2022-05-03 10:47:54,041 INFO: Epoch:[002/100]\n",
      "2022-05-03 10:47:54,042 INFO: Train Loss:4.137 | Acc:0.2546 | F1:0.0610\n",
      "2022-05-03 10:48:15,276 INFO: val Loss:3.903 | Acc:0.3971 | F1:0.0904\n",
      "2022-05-03 10:48:15,901 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|██████████| 441/441 [02:34<00:00,  2.86it/s]\n",
      "2022-05-03 10:50:50,190 INFO: Epoch:[003/100]\n",
      "2022-05-03 10:50:50,191 INFO: Train Loss:3.357 | Acc:0.3470 | F1:0.0802\n",
      "2022-05-03 10:51:10,870 INFO: val Loss:2.481 | Acc:0.4050 | F1:0.0966\n",
      "2022-05-03 10:51:11,510 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|██████████| 441/441 [02:38<00:00,  2.79it/s]\n",
      "2022-05-03 10:53:49,757 INFO: Epoch:[004/100]\n",
      "2022-05-03 10:53:49,757 INFO: Train Loss:2.251 | Acc:0.4031 | F1:0.0972\n",
      "2022-05-03 10:54:11,363 INFO: val Loss:1.461 | Acc:0.4265 | F1:0.1186\n",
      "2022-05-03 10:54:11,990 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.79it/s]\n",
      "2022-05-03 10:56:49,867 INFO: Epoch:[005/100]\n",
      "2022-05-03 10:56:49,867 INFO: Train Loss:1.546 | Acc:0.4289 | F1:0.1285\n",
      "2022-05-03 10:57:10,995 INFO: val Loss:1.067 | Acc:0.4526 | F1:0.1593\n",
      "2022-05-03 10:57:11,603 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 10:59:48,203 INFO: Epoch:[006/100]\n",
      "2022-05-03 10:59:48,204 INFO: Train Loss:1.219 | Acc:0.4613 | F1:0.1884\n",
      "2022-05-03 11:00:09,287 INFO: val Loss:0.916 | Acc:0.4776 | F1:0.2067\n",
      "2022-05-03 11:00:09,893 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.83it/s]\n",
      "2022-05-03 11:02:45,983 INFO: Epoch:[007/100]\n",
      "2022-05-03 11:02:45,983 INFO: Train Loss:1.042 | Acc:0.4984 | F1:0.2588\n",
      "2022-05-03 11:03:06,957 INFO: val Loss:0.858 | Acc:0.5094 | F1:0.2877\n",
      "2022-05-03 11:03:07,579 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 11:05:43,817 INFO: Epoch:[008/100]\n",
      "2022-05-03 11:05:43,817 INFO: Train Loss:0.939 | Acc:0.5272 | F1:0.3134\n",
      "2022-05-03 11:06:05,311 INFO: val Loss:0.792 | Acc:0.5542 | F1:0.3476\n",
      "2022-05-03 11:06:05,922 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|██████████| 441/441 [02:35<00:00,  2.83it/s]\n",
      "2022-05-03 11:08:41,507 INFO: Epoch:[009/100]\n",
      "2022-05-03 11:08:41,508 INFO: Train Loss:0.844 | Acc:0.5643 | F1:0.3776\n",
      "2022-05-03 11:09:02,486 INFO: val Loss:0.728 | Acc:0.5882 | F1:0.4354\n",
      "2022-05-03 11:09:03,082 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|██████████| 441/441 [02:35<00:00,  2.83it/s]\n",
      "2022-05-03 11:11:39,007 INFO: Epoch:[010/100]\n",
      "2022-05-03 11:11:39,007 INFO: Train Loss:0.771 | Acc:0.6034 | F1:0.4420\n",
      "2022-05-03 11:11:59,885 INFO: val Loss:0.586 | Acc:0.6478 | F1:0.4699\n",
      "2022-05-03 11:12:00,503 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|██████████| 441/441 [02:34<00:00,  2.85it/s]\n",
      "2022-05-03 11:14:35,190 INFO: Epoch:[011/100]\n",
      "2022-05-03 11:14:35,190 INFO: Train Loss:0.693 | Acc:0.6326 | F1:0.4913\n",
      "2022-05-03 11:14:56,806 INFO: val Loss:0.628 | Acc:0.6273 | F1:0.4749\n",
      "100%|██████████| 441/441 [02:35<00:00,  2.84it/s]\n",
      "2022-05-03 11:17:31,926 INFO: Epoch:[012/100]\n",
      "2022-05-03 11:17:31,927 INFO: Train Loss:0.601 | Acc:0.6766 | F1:0.5545\n",
      "2022-05-03 11:17:52,773 INFO: val Loss:0.478 | Acc:0.7039 | F1:0.5674\n",
      "2022-05-03 11:17:53,413 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|██████████| 441/441 [02:39<00:00,  2.77it/s]\n",
      "2022-05-03 11:20:32,655 INFO: Epoch:[013/100]\n",
      "2022-05-03 11:20:32,655 INFO: Train Loss:0.535 | Acc:0.7091 | F1:0.6057\n",
      "2022-05-03 11:20:54,112 INFO: val Loss:0.374 | Acc:0.7788 | F1:0.6794\n",
      "2022-05-03 11:20:54,716 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|██████████| 441/441 [02:38<00:00,  2.78it/s]\n",
      "2022-05-03 11:23:33,637 INFO: Epoch:[014/100]\n",
      "2022-05-03 11:23:33,637 INFO: Train Loss:0.451 | Acc:0.7481 | F1:0.6628\n",
      "2022-05-03 11:23:55,517 INFO: val Loss:0.332 | Acc:0.7828 | F1:0.6994\n",
      "2022-05-03 11:23:56,174 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|██████████| 441/441 [02:41<00:00,  2.74it/s]\n",
      "2022-05-03 11:26:37,239 INFO: Epoch:[015/100]\n",
      "2022-05-03 11:26:37,240 INFO: Train Loss:0.389 | Acc:0.7782 | F1:0.7039\n",
      "2022-05-03 11:26:58,441 INFO: val Loss:0.283 | Acc:0.8179 | F1:0.7357\n",
      "2022-05-03 11:26:59,061 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|██████████| 441/441 [02:42<00:00,  2.72it/s]\n",
      "2022-05-03 11:29:41,096 INFO: Epoch:[016/100]\n",
      "2022-05-03 11:29:41,097 INFO: Train Loss:0.337 | Acc:0.7940 | F1:0.7333\n",
      "2022-05-03 11:30:02,146 INFO: val Loss:0.239 | Acc:0.8440 | F1:0.7900\n",
      "2022-05-03 11:30:02,887 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|██████████| 441/441 [02:39<00:00,  2.77it/s]\n",
      "2022-05-03 11:32:42,042 INFO: Epoch:[017/100]\n",
      "2022-05-03 11:32:42,042 INFO: Train Loss:0.287 | Acc:0.8235 | F1:0.7747\n",
      "2022-05-03 11:33:03,880 INFO: val Loss:0.210 | Acc:0.8525 | F1:0.8015\n",
      "2022-05-03 11:33:04,591 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|██████████| 441/441 [02:33<00:00,  2.87it/s]\n",
      "2022-05-03 11:35:38,177 INFO: Epoch:[018/100]\n",
      "2022-05-03 11:35:38,178 INFO: Train Loss:0.261 | Acc:0.8472 | F1:0.8038\n",
      "2022-05-03 11:36:00,094 INFO: val Loss:0.152 | Acc:0.8832 | F1:0.8568\n",
      "2022-05-03 11:36:00,720 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 11:38:37,379 INFO: Epoch:[019/100]\n",
      "2022-05-03 11:38:37,380 INFO: Train Loss:0.230 | Acc:0.8617 | F1:0.8282\n",
      "2022-05-03 11:38:58,390 INFO: val Loss:0.148 | Acc:0.9019 | F1:0.8684\n",
      "2022-05-03 11:38:58,988 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.80it/s]\n",
      "2022-05-03 11:41:36,638 INFO: Epoch:[020/100]\n",
      "2022-05-03 11:41:36,638 INFO: Train Loss:0.206 | Acc:0.8728 | F1:0.8414\n",
      "2022-05-03 11:41:57,624 INFO: val Loss:0.133 | Acc:0.8945 | F1:0.8652\n",
      "2022-05-03 11:41:58,252 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.80it/s]\n",
      "2022-05-03 11:44:35,542 INFO: Epoch:[021/100]\n",
      "2022-05-03 11:44:35,543 INFO: Train Loss:0.179 | Acc:0.8908 | F1:0.8662\n",
      "2022-05-03 11:44:56,546 INFO: val Loss:0.113 | Acc:0.9212 | F1:0.9014\n",
      "2022-05-03 11:44:57,155 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|██████████| 441/441 [02:39<00:00,  2.76it/s]\n",
      "2022-05-03 11:47:36,918 INFO: Epoch:[022/100]\n",
      "2022-05-03 11:47:36,918 INFO: Train Loss:0.155 | Acc:0.9009 | F1:0.8785\n",
      "2022-05-03 11:47:58,446 INFO: val Loss:0.088 | Acc:0.9280 | F1:0.9156\n",
      "2022-05-03 11:47:59,057 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|██████████| 441/441 [02:39<00:00,  2.77it/s]\n",
      "2022-05-03 11:50:38,328 INFO: Epoch:[023/100]\n",
      "2022-05-03 11:50:38,329 INFO: Train Loss:0.144 | Acc:0.9123 | F1:0.8951\n",
      "2022-05-03 11:50:59,704 INFO: val Loss:0.082 | Acc:0.9308 | F1:0.9213\n",
      "2022-05-03 11:51:00,337 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 11:53:36,506 INFO: Epoch:[024/100]\n",
      "2022-05-03 11:53:36,507 INFO: Train Loss:0.122 | Acc:0.9248 | F1:0.9096\n",
      "2022-05-03 11:53:57,917 INFO: val Loss:0.053 | Acc:0.9541 | F1:0.9527\n",
      "2022-05-03 11:53:58,537 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 11:56:35,030 INFO: Epoch:[025/100]\n",
      "2022-05-03 11:56:35,031 INFO: Train Loss:0.116 | Acc:0.9248 | F1:0.9114\n",
      "2022-05-03 11:56:55,871 INFO: val Loss:0.045 | Acc:0.9654 | F1:0.9618\n",
      "2022-05-03 11:56:56,487 INFO: -----------------SAVE:25epoch----------------\n",
      "100%|██████████| 441/441 [02:35<00:00,  2.84it/s]\n",
      "2022-05-03 11:59:31,840 INFO: Epoch:[026/100]\n",
      "2022-05-03 11:59:31,841 INFO: Train Loss:0.107 | Acc:0.9345 | F1:0.9233\n",
      "2022-05-03 11:59:52,685 INFO: val Loss:0.051 | Acc:0.9552 | F1:0.9512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 441/441 [02:33<00:00,  2.87it/s]\n",
      "2022-05-03 12:02:26,388 INFO: Epoch:[027/100]\n",
      "2022-05-03 12:02:26,389 INFO: Train Loss:0.094 | Acc:0.9366 | F1:0.9248\n",
      "2022-05-03 12:02:47,567 INFO: val Loss:0.056 | Acc:0.9495 | F1:0.9446\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 12:05:23,792 INFO: Epoch:[028/100]\n",
      "2022-05-03 12:05:23,793 INFO: Train Loss:0.084 | Acc:0.9435 | F1:0.9332\n",
      "2022-05-03 12:05:44,661 INFO: val Loss:0.033 | Acc:0.9682 | F1:0.9650\n",
      "2022-05-03 12:05:45,273 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|██████████| 441/441 [02:35<00:00,  2.83it/s]\n",
      "2022-05-03 12:08:21,162 INFO: Epoch:[029/100]\n",
      "2022-05-03 12:08:21,163 INFO: Train Loss:0.083 | Acc:0.9426 | F1:0.9334\n",
      "2022-05-03 12:08:42,175 INFO: val Loss:0.033 | Acc:0.9716 | F1:0.9692\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 12:11:18,779 INFO: Epoch:[030/100]\n",
      "2022-05-03 12:11:18,780 INFO: Train Loss:0.081 | Acc:0.9471 | F1:0.9365\n",
      "2022-05-03 12:11:39,884 INFO: val Loss:0.028 | Acc:0.9728 | F1:0.9702\n",
      "2022-05-03 12:11:40,489 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.83it/s]\n",
      "2022-05-03 12:14:16,605 INFO: Epoch:[031/100]\n",
      "2022-05-03 12:14:16,606 INFO: Train Loss:0.071 | Acc:0.9489 | F1:0.9398\n",
      "2022-05-03 12:14:37,788 INFO: val Loss:0.023 | Acc:0.9773 | F1:0.9735\n",
      "2022-05-03 12:14:38,398 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 12:17:14,985 INFO: Epoch:[032/100]\n",
      "2022-05-03 12:17:14,986 INFO: Train Loss:0.064 | Acc:0.9594 | F1:0.9540\n",
      "2022-05-03 12:17:36,084 INFO: val Loss:0.022 | Acc:0.9790 | F1:0.9762\n",
      "2022-05-03 12:17:36,696 INFO: -----------------SAVE:32epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.82it/s]\n",
      "2022-05-03 12:20:13,002 INFO: Epoch:[033/100]\n",
      "2022-05-03 12:20:13,002 INFO: Train Loss:0.066 | Acc:0.9567 | F1:0.9498\n",
      "2022-05-03 12:20:33,891 INFO: val Loss:0.027 | Acc:0.9773 | F1:0.9750\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.81it/s]\n",
      "2022-05-03 12:23:10,935 INFO: Epoch:[034/100]\n",
      "2022-05-03 12:23:10,936 INFO: Train Loss:0.055 | Acc:0.9613 | F1:0.9535\n",
      "2022-05-03 12:23:31,842 INFO: val Loss:0.032 | Acc:0.9682 | F1:0.9675\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.80it/s]\n",
      "2022-05-03 12:26:09,381 INFO: Epoch:[035/100]\n",
      "2022-05-03 12:26:09,382 INFO: Train Loss:0.060 | Acc:0.9607 | F1:0.9533\n",
      "2022-05-03 12:26:31,311 INFO: val Loss:0.020 | Acc:0.9801 | F1:0.9798\n",
      "2022-05-03 12:26:31,945 INFO: -----------------SAVE:35epoch----------------\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.79it/s]\n",
      "2022-05-03 12:29:09,860 INFO: Epoch:[036/100]\n",
      "2022-05-03 12:29:09,860 INFO: Train Loss:0.048 | Acc:0.9667 | F1:0.9613\n",
      "2022-05-03 12:29:30,908 INFO: val Loss:0.017 | Acc:0.9841 | F1:0.9829\n",
      "2022-05-03 12:29:31,528 INFO: -----------------SAVE:36epoch----------------\n",
      "100%|██████████| 441/441 [02:37<00:00,  2.80it/s]\n",
      "2022-05-03 12:32:09,073 INFO: Epoch:[037/100]\n",
      "2022-05-03 12:32:09,073 INFO: Train Loss:0.055 | Acc:0.9630 | F1:0.9570\n",
      "2022-05-03 12:32:30,615 INFO: val Loss:0.015 | Acc:0.9853 | F1:0.9830\n",
      "2022-05-03 12:32:31,233 INFO: -----------------SAVE:37epoch----------------\n",
      "100%|██████████| 441/441 [02:34<00:00,  2.85it/s]\n",
      "2022-05-03 12:35:05,932 INFO: Epoch:[038/100]\n",
      "2022-05-03 12:35:05,933 INFO: Train Loss:0.048 | Acc:0.9691 | F1:0.9641\n",
      "2022-05-03 12:35:27,518 INFO: val Loss:0.026 | Acc:0.9773 | F1:0.9753\n",
      "100%|██████████| 441/441 [02:35<00:00,  2.84it/s]\n",
      "2022-05-03 12:38:02,672 INFO: Epoch:[039/100]\n",
      "2022-05-03 12:38:02,673 INFO: Train Loss:0.046 | Acc:0.9674 | F1:0.9612\n",
      "2022-05-03 12:38:23,563 INFO: val Loss:0.017 | Acc:0.9853 | F1:0.9848\n",
      "100%|██████████| 441/441 [02:32<00:00,  2.89it/s]\n",
      "2022-05-03 12:40:56,035 INFO: Epoch:[040/100]\n",
      "2022-05-03 12:40:56,035 INFO: Train Loss:0.043 | Acc:0.9688 | F1:0.9633\n",
      "2022-05-03 12:41:17,361 INFO: val Loss:0.010 | Acc:0.9858 | F1:0.9842\n",
      "2022-05-03 12:41:17,958 INFO: -----------------SAVE:40epoch----------------\n",
      "100%|██████████| 441/441 [02:38<00:00,  2.78it/s]\n",
      "2022-05-03 12:43:56,772 INFO: Epoch:[041/100]\n",
      "2022-05-03 12:43:56,773 INFO: Train Loss:0.036 | Acc:0.9752 | F1:0.9715\n",
      "2022-05-03 12:44:18,018 INFO: val Loss:0.019 | Acc:0.9830 | F1:0.9810\n",
      "100%|██████████| 441/441 [02:41<00:00,  2.73it/s]\n",
      "2022-05-03 12:46:59,649 INFO: Epoch:[042/100]\n",
      "2022-05-03 12:46:59,649 INFO: Train Loss:0.041 | Acc:0.9738 | F1:0.9696\n",
      "2022-05-03 12:47:21,078 INFO: val Loss:0.011 | Acc:0.9904 | F1:0.9898\n",
      "100%|██████████| 441/441 [02:39<00:00,  2.76it/s]\n",
      "2022-05-03 12:50:00,998 INFO: Epoch:[043/100]\n",
      "2022-05-03 12:50:00,999 INFO: Train Loss:0.034 | Acc:0.9753 | F1:0.9708\n",
      "2022-05-03 12:50:22,826 INFO: val Loss:0.019 | Acc:0.9841 | F1:0.9813\n",
      "100%|██████████| 441/441 [02:34<00:00,  2.86it/s]\n",
      "2022-05-03 12:52:57,186 INFO: Epoch:[044/100]\n",
      "2022-05-03 12:52:57,187 INFO: Train Loss:0.035 | Acc:0.9736 | F1:0.9692\n",
      "2022-05-03 12:53:18,771 INFO: val Loss:0.015 | Acc:0.9898 | F1:0.9890\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.83it/s]\n",
      "2022-05-03 12:55:54,834 INFO: Epoch:[045/100]\n",
      "2022-05-03 12:55:54,835 INFO: Train Loss:0.037 | Acc:0.9739 | F1:0.9687\n",
      "2022-05-03 12:56:16,120 INFO: val Loss:0.013 | Acc:0.9915 | F1:0.9906\n",
      "100%|██████████| 441/441 [02:39<00:00,  2.76it/s]\n",
      "2022-05-03 12:58:56,016 INFO: Epoch:[046/100]\n",
      "2022-05-03 12:58:56,016 INFO: Train Loss:0.031 | Acc:0.9793 | F1:0.9767\n",
      "2022-05-03 12:59:17,166 INFO: val Loss:0.007 | Acc:0.9932 | F1:0.9924\n",
      "2022-05-03 12:59:17,861 INFO: -----------------SAVE:46epoch----------------\n",
      "100%|██████████| 441/441 [02:36<00:00,  2.81it/s]\n",
      "2022-05-03 13:01:54,590 INFO: Epoch:[047/100]\n",
      "2022-05-03 13:01:54,591 INFO: Train Loss:0.035 | Acc:0.9755 | F1:0.9711\n",
      "2022-05-03 13:02:15,627 INFO: val Loss:0.009 | Acc:0.9915 | F1:0.9917\n",
      " 82%|████████▏ | 361/441 [02:06<00:28,  2.78it/s]"
     ]
    }
   ],
   "source": [
    "args.step = 0\n",
    "models_path = []\n",
    "for s_fold in range(5): # 5fold\n",
    "    args.fold = s_fold\n",
    "    args.exp_num = str(s_fold)\n",
    "    save_path = main(args)\n",
    "    models_path.append(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 512\n",
    "\n",
    "test_transform = get_train_augmentation(img_size=img_size, ver=1)\n",
    "test_dataset = Test_dataset(df_test, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_path = ['./class_results/000', './class_results/001', './class_results/002', './class_results/003', './class_results/004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = ensemble_5fold(models_path, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred = ensemble.argmax(axis=1).tolist()\n",
    "f_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"./open/train_df_add2.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submission/label_result_add_0503_resnext50_32x4d.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
