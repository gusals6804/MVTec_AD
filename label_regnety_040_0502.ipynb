{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import easydict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os.path import join as opj\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "from natsort import natsorted\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, grad_scaler\n",
    "from torchvision import transforms\n",
    "from torch import Tensor\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.cuda.amp as amp\n",
    "from adamp import AdamP, SGDP\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  file_name       class state            label  label2\n",
      "0           0  10000.png  transistor  good  transistor-good      72\n",
      "1           1  10001.png     capsule  good     capsule-good      15\n",
      "2           2  10002.png  transistor  good  transistor-good      72\n",
      "3           3  10003.png        wood  good        wood-good      76\n",
      "4           4  10004.png      bottle  good      bottle-good       3\n",
      "   index  file_name\n",
      "0      0  20000.png\n",
      "1      1  20001.png\n",
      "2      2  20002.png\n",
      "3      3  20003.png\n",
      "4      4  20004.png\n",
      "(6221, 6)\n",
      "(2154, 2)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './open'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train_df_add2.csv'))\n",
    "# train_df = train_df.drop('index', axis=1)\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test_df.csv'))\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['transistor-good', 'capsule-good', 'wood-good', 'bottle-good',\n",
       "       'screw-good', 'cable-bent_wire', 'carpet-hole', 'hazelnut-good',\n",
       "       'pill-pill_type', 'cable-good', 'metal_nut-scratch', 'pill-good',\n",
       "       'screw-thread_side', 'zipper-fabric_border', 'leather-good',\n",
       "       'pill-scratch', 'toothbrush-good', 'hazelnut-crack',\n",
       "       'screw-manipulated_front', 'zipper-good', 'tile-good',\n",
       "       'carpet-good', 'metal_nut-good', 'bottle-contamination',\n",
       "       'grid-good', 'zipper-split_teeth', 'pill-crack', 'wood-combined',\n",
       "       'pill-color', 'screw-thread_top', 'cable-missing_cable',\n",
       "       'capsule-squeeze', 'zipper-rough', 'capsule-crack', 'capsule-poke',\n",
       "       'metal_nut-flip', 'carpet-metal_contamination', 'metal_nut-color',\n",
       "       'transistor-bent_lead', 'zipper-fabric_interior', 'leather-fold',\n",
       "       'tile-glue_strip', 'screw-scratch_neck', 'screw-scratch_head',\n",
       "       'hazelnut-cut', 'bottle-broken_large', 'bottle-broken_small',\n",
       "       'leather-cut', 'cable-cut_outer_insulation',\n",
       "       'zipper-squeezed_teeth', 'toothbrush-defective',\n",
       "       'cable-cut_inner_insulation', 'pill-contamination',\n",
       "       'cable-missing_wire', 'carpet-thread', 'grid-broken',\n",
       "       'pill-faulty_imprint', 'hazelnut-hole', 'leather-glue',\n",
       "       'leather-poke', 'transistor-damaged_case', 'wood-scratch',\n",
       "       'tile-gray_stroke', 'capsule-faulty_imprint', 'grid-glue',\n",
       "       'zipper-combined', 'carpet-color', 'grid-bent', 'pill-combined',\n",
       "       'hazelnut-print', 'cable-combined', 'capsule-scratch',\n",
       "       'metal_nut-bent', 'zipper-broken_teeth', 'tile-oil',\n",
       "       'transistor-misplaced', 'grid-thread', 'grid-metal_contamination',\n",
       "       'carpet-cut', 'wood-color', 'cable-cable_swap', 'tile-crack',\n",
       "       'leather-color', 'cable-poke_insulation', 'transistor-cut_lead',\n",
       "       'wood-hole', 'tile-rough', 'wood-liquid'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(img, angle):\n",
    "    angle = int(random.uniform(-angle, angle))\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "    img = cv2.warpAffine(img, M, (w, h)) \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import imutils\n",
    "# oslabel = list(train_df['label'].unique())\n",
    "\n",
    "\n",
    "# for label in tqdm(oslabel):\n",
    "#     if 'good' not in label:\n",
    "#         print(label)\n",
    "#         idx = 0\n",
    "#         one_sample = train_df[train_df['label'] == label].reset_index(drop=True)\n",
    "#         images_list = natsorted(one_sample['file_name'])\n",
    "#         print(images_list)\n",
    "#         for _, image_name in enumerate(images_list):\n",
    "#             image = np.array(Image.open(opj('./open/train_add/', image_name)).convert('RGB'))\n",
    "            \n",
    "#             aug_img = rotation(image, 30)  \n",
    "#             aug_img = cv2.resize(aug_img, dsize=(1024, 1024))\n",
    "#             aug_img = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)\n",
    "#             save_path = opj('./open/train_add', f'{label}_{idx}.png')\n",
    "#             save_name = f'{label}_{idx}.png'\n",
    "#             idx += 1\n",
    "#             cv2.imwrite(save_path, aug_img)\n",
    "#             train_df.loc[len(train_df)] = [save_name] + one_sample.iloc[0][1:].values.tolist()\n",
    "\n",
    "# for label in tqdm(oslabel):\n",
    "#     if 'good' not in label:\n",
    "#         print(label)\n",
    "#         idx = 0\n",
    "#         one_sample = train_df[train_df['label'] == label].reset_index(drop=True)\n",
    "#         images_list = natsorted(one_sample['file_name'])\n",
    "#         print(images_list)\n",
    "#         for _, image_name in enumerate(images_list):\n",
    "#             image = np.array(Image.open(opj('./open/train_add/', image_name)).convert('RGB'))\n",
    "            \n",
    "#             aug_img = cv2.flip(image, 1)\n",
    "#             aug_img = cv2.resize(aug_img, dsize=(1024, 1024))\n",
    "#             aug_img = cv2.cvtColor(aug_img, cv2.COLOR_BGR2RGB)\n",
    "#             save_path = opj('./open/train_add', f'{label}_{idx}_flip.png')\n",
    "#             save_name = f'{label}_{idx}_flip.png'\n",
    "#             idx += 1\n",
    "#             cv2.imwrite(save_path, aug_img)\n",
    "#             train_df.loc[len(train_df)] = [save_name] + one_sample.iloc[0][1:].values.tolist()    \n",
    "            \n",
    "   \n",
    "            \n",
    "# train_df.to_csv('./open/train_df_add.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = pd.read_csv(\"./open/train_df_add.csv\")\n",
    "\n",
    "# train_labels = train_y[\"label\"]\n",
    "\n",
    "# label_unique = sorted(np.unique(train_labels))\n",
    "# label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "# train_labels = [label_unique[k] for k in train_labels]\n",
    "# train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['label2'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('./open/train_df_add2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1\"  # Set the GPUs 2 and 3 to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = len(train_df.label2.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {'exp_num':'0',\n",
    "     \n",
    "     # Path settings\n",
    "     'data_path':'./open',\n",
    "     'Kfold':5,\n",
    "     'model_path':'label_results/',\n",
    "     'image_type':'train_1024', \n",
    "     'class_num' : class_num,\n",
    "\n",
    "     # Model parameter settings\n",
    "     'model_name':'regnety_040',\n",
    "     'drop_path_rate':0.2,\n",
    "     \n",
    "     # Training parameter settings\n",
    "     ## Base Parameter\n",
    "     'img_size':512,\n",
    "     'batch_size':16,\n",
    "     'epochs':100,\n",
    "     'optimizer':'Lamb',\n",
    "     'initial_lr':5e-4,\n",
    "     'weight_decay':1e-3,\n",
    "\n",
    "     ## Augmentation\n",
    "     'aug_ver':2,\n",
    "\n",
    "     ## Scheduler (OnecycleLR)\n",
    "     'scheduler':'Reduce',\n",
    "     'warm_epoch':5,\n",
    "     'max_lr':1e-3,\n",
    "\n",
    "     ### Cosine Annealing\n",
    "     'min_lr':5e-5,\n",
    "     'tmax':145,\n",
    "\n",
    "     ## etc.\n",
    "     'patience': 7,\n",
    "     'clipping':None,\n",
    "\n",
    "     # Hardware settings\n",
    "     'amp':True,\n",
    "     'multi_gpu':True,\n",
    "     'logging':False,\n",
    "     'num_workers':4,\n",
    "     'seed':42\n",
    "     \n",
    "     \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimzier(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        \n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
    "\n",
    "# Logging\n",
    "def get_root_logger(logger_name='basicsr',\n",
    "                    log_level=logging.INFO,\n",
    "                    log_file=None):\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    # if the logger has been initialized, just return it\n",
    "    if logger.hasHandlers():\n",
    "        return logger\n",
    "\n",
    "    format_str = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(format=format_str, level=log_level)\n",
    "\n",
    "    if log_file is not None:\n",
    "        file_handler = logging.FileHandler(log_file, 'w')\n",
    "        file_handler.setFormatter(logging.Formatter(format_str))\n",
    "        file_handler.setLevel(log_level)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "class AvgMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.losses.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(transforms.RandomRotation):\n",
    "    def __init__(self, p: float, degrees: int):\n",
    "        super(RandomRotation, self).__init__(degrees)\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, img):\n",
    "        if torch.rand(1) < self.p:\n",
    "            fill = self.fill\n",
    "            if isinstance(img, Tensor):\n",
    "                if isinstance(fill, (int, float)):\n",
    "                    fill = [float(fill)] * F.get_image_num_channels(img)\n",
    "                else:\n",
    "                    fill = [float(f) for f in fill]\n",
    "            angle = self.get_params(self.degrees)\n",
    "\n",
    "            img = F.rotate(img, angle, self.resample, self.expand, self.center, fill)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.img_path = df['file_name'].values\n",
    "        self.target = df['label2'].values \n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Dataset size:{len(self.img_path)}')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         image = cv2.imread(opj('./open/train_add/', self.img_path[idx])).astype(np.float32)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "        \n",
    "#         target = self.target[idx]\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "        \n",
    "        image = Image.open(opj('./open/train_add/', self.img_path[idx])).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "#         augmentation = random.randint(0,2)\n",
    "#             if augmentation==1:\n",
    "#                 img = img[::-1].copy()\n",
    "#             elif augmentation==2:\n",
    "#                 img = img[:,::-1].copy()\n",
    "#         img = transforms.ToTensor()(img)\n",
    "        target = self.target[idx]\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "class Test_dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.img_path = df['file_name'].values\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Test Dataset size:{len(self.img_path)}')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "#         image = cv2.imread(opj('./open/test/', self.img_path[idx])).astype(np.float32)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "        image = Image.open(opj('./open/test/', self.img_path[idx])).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "def get_loader(df, phase: str, batch_size, shuffle,\n",
    "               num_workers, transform):\n",
    "    if phase == 'test':\n",
    "        dataset = Test_dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    else:\n",
    "        dataset = Train_Dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                 pin_memory=True,\n",
    "                                 drop_last=False)\n",
    "    return data_loader\n",
    "\n",
    "def get_train_augmentation(img_size, ver):\n",
    "    if ver==1: # for validset\n",
    "        transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    if ver == 2:\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.3),\n",
    "                transforms.RandomVerticalFlip(p=0.3),\n",
    "#                 transforms.RandomCrop(500),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "                transforms.RandomAffine((-20,20)),\n",
    "                RandomRotation(0.5, degrees=5),\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "    \n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.model_ft = timm.create_model(args.model_name, pretrained=True,\n",
    "                                    drop_path_rate=args.drop_path_rate,\n",
    "                                    )\n",
    "        num_head = self.model_ft.head.fc.in_features\n",
    "        self.model_ft.head.fc = nn.Linear(num_head, 88)\n",
    "\n",
    "#         self.model_ft = coatnet_3()\n",
    "#         num_ftrs = self.model_ft.fc.in_features\n",
    "#         self.model_ft.fc = nn.Linear(num_ftrs, args.class_num)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model_ft(x)\n",
    "        return out\n",
    "\n",
    "class Network_test(nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super().__init__()\n",
    "        self.model_ft = timm.create_model(args.model_name, pretrained=True,\n",
    "                                    drop_path_rate=args.drop_path_rate,\n",
    "                                    )\n",
    "        num_head = self.model_ft.head.fc.in_features\n",
    "        self.model_ft.head.fc = nn.Linear(num_head, 88)\n",
    "\n",
    "#         self.model_ft = coatnet_3()\n",
    "#         num_ftrs = self.model_ft.fc.in_features\n",
    "#         self.model_ft.fc = nn.Linear(num_ftrs, args.class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model_ft(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: tensor([ 9.7750,  8.8864,  8.8864,  1.8708, 13.9643, 16.2917, 16.2917, 13.9643,\n",
      "        19.5500,  1.7455, 16.2917, 19.5500, 19.5500,  8.1458,  8.8864,  1.7854,\n",
      "         8.8864,  8.1458,  9.7750,  9.7750, 10.8611,  1.3964, 10.8611, 10.8611,\n",
      "         9.7750, 16.2917, 16.2917, 16.2917,  1.4811, 16.2917, 16.2917, 10.8611,\n",
      "        10.8611,  1.0000, 10.8611, 10.8611,  9.7750,  9.7750, 10.8611,  9.7750,\n",
      "         1.5959, 10.8611,  7.5192,  8.8864,  8.1458,  1.7773,  8.1458,  7.5192,\n",
      "        10.8611,  8.8864,  7.5192,  9.7750,  1.4644, 19.5500,  8.1458,  1.2219,\n",
      "         8.1458,  8.1458,  7.5192,  8.1458,  8.1458, 10.8611, 10.8611,  1.7000,\n",
      "        12.2188, 10.8611, 12.2188,  6.5167,  6.5167, 19.5500, 19.5500, 19.5500,\n",
      "         1.8357, 19.5500, 24.4375, 16.2917,  1.5830, 19.5500, 19.5500,  8.8864,\n",
      "         9.7750, 12.2188, 10.8611, 12.2188,  1.6292, 10.8611, 10.8611, 12.2188],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# # weighted crossentropy loss를 위한 weight 계산 함수\n",
    "# def get_class_weight():\n",
    "#     return 1 / train_df['label2'].value_counts().sort_index().values\n",
    "\n",
    "# class_weight = get_class_weight()\n",
    "\n",
    "\n",
    "class_num = train_df.groupby([\"label2\"])[\"label2\"].count().tolist()\n",
    "class_weight = torch.tensor(np.max(class_num) / class_num).to(\"cuda\", dtype=torch.float)\n",
    "print(f\"class_weight: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "class Lookahead(Optimizer):\n",
    "    def __init__(self, optimizer, k=5, alpha=0.5):\n",
    "        self.optimizer = optimizer\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.param_groups = self.optimizer.param_groups\n",
    "        self.state = defaultdict(dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "        for group in self.param_groups:\n",
    "            group[\"counter\"] = 0\n",
    "    \n",
    "    def update(self, group):\n",
    "        for fast in group[\"params\"]:\n",
    "            param_state = self.state[fast]\n",
    "            if \"slow_param\" not in param_state:\n",
    "                param_state[\"slow_param\"] = torch.zeros_like(fast.data)\n",
    "                param_state[\"slow_param\"].copy_(fast.data)\n",
    "            slow = param_state[\"slow_param\"]\n",
    "            slow += (fast.data - slow) * self.alpha\n",
    "            fast.data.copy_(slow)\n",
    "    \n",
    "    def update_lookahead(self):\n",
    "        for group in self.param_groups:\n",
    "            self.update(group)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = self.optimizer.step(closure)\n",
    "        for group in self.param_groups:\n",
    "            if group[\"counter\"] == 0:\n",
    "                self.update(group)\n",
    "            group[\"counter\"] += 1\n",
    "            if group[\"counter\"] >= self.k:\n",
    "                group[\"counter\"] = 0\n",
    "        return loss\n",
    "\n",
    "    def state_dict(self):\n",
    "        fast_state_dict = self.optimizer.state_dict()\n",
    "        slow_state = {\n",
    "            (id(k) if isinstance(k, torch.Tensor) else k): v\n",
    "            for k, v in self.state.items()\n",
    "        }\n",
    "        fast_state = fast_state_dict[\"state\"]\n",
    "        param_groups = fast_state_dict[\"param_groups\"]\n",
    "        return {\n",
    "            \"fast_state\": fast_state,\n",
    "            \"slow_state\": slow_state,\n",
    "            \"param_groups\": param_groups,\n",
    "        }\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        slow_state_dict = {\n",
    "            \"state\": state_dict[\"slow_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        fast_state_dict = {\n",
    "            \"state\": state_dict[\"fast_state\"],\n",
    "            \"param_groups\": state_dict[\"param_groups\"],\n",
    "        }\n",
    "        super(Lookahead, self).load_state_dict(slow_state_dict)\n",
    "        self.optimizer.load_state_dict(fast_state_dict)\n",
    "        self.fast_state = self.optimizer.state\n",
    "\n",
    "    def add_param_group(self, param_group):\n",
    "        param_group[\"counter\"] = 0\n",
    "        self.optimizer.add_param_group(param_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    https://dacon.io/competitions/official/235585/codeshare/1796\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=2.0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        # print(self.gamma)\n",
    "        self.eps = eps\n",
    "        self.ce = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, args, save_path):\n",
    "        '''\n",
    "        args: arguments\n",
    "        save_path: Model 가중치 저장 경로\n",
    "        '''\n",
    "        super(Trainer, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Logging\n",
    "        log_file = os.path.join(save_path, 'log.log')\n",
    "        self.logger = get_root_logger(logger_name='IR', log_level=logging.INFO, log_file=log_file)\n",
    "        self.logger.info(args)\n",
    "        # self.logger.info(args.tag)\n",
    "\n",
    "        # Train, Valid Set load\n",
    "        ############################################################################\n",
    "        if args.step == 0 :\n",
    "            df_train = pd.read_csv(opj(args.data_path, 'train_df_add2.csv'))\n",
    "        else :\n",
    "            df_train = pd.read_csv(opj(args.data_path, f'train_{args.step}step.csv'))\n",
    "\n",
    "#         if args.image_type is not None:\n",
    "#             df_train['img_path'] = df_train['img_path'].apply(lambda x:x.replace('train_imgs', args.image_type))\n",
    "#             df_train['img_path'] = df_train['img_path'].apply(lambda x:x.replace('test_imgs', 'test_1024'))\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=args.Kfold, shuffle=True, random_state=args.seed)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(df_train)), y=df_train['label2'])):\n",
    "            df_train.loc[val_idx, 'fold'] = fold\n",
    "        val_idx = list(df_train[df_train['fold'] == int(args.fold)].index)\n",
    "\n",
    "        df_val = df_train[df_train['fold'] == args.fold].reset_index(drop=True)\n",
    "        df_train = df_train[df_train['fold'] != args.fold].reset_index(drop=True)\n",
    "\n",
    "        # Augmentation\n",
    "        self.train_transform = get_train_augmentation(img_size=args.img_size, ver=args.aug_ver)\n",
    "        self.test_transform = get_train_augmentation(img_size=args.img_size, ver=1)\n",
    "\n",
    "        # TrainLoader\n",
    "        self.train_loader = get_loader(df_train, phase='train', batch_size=args.batch_size, shuffle=True,\n",
    "                                       num_workers=args.num_workers, transform=self.train_transform)\n",
    "        self.val_loader = get_loader(df_val, phase='train', batch_size=args.batch_size, shuffle=False,\n",
    "                                       num_workers=args.num_workers, transform=self.test_transform)\n",
    "\n",
    "        # Network\n",
    "        self.model = Network(args).to(self.device)\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "#         self.criterion = FocalLoss()\n",
    "#         self.criterion = CutMixCrossEntropyLoss(True)\n",
    "        \n",
    "        # Optimizer & Scheduler\n",
    "#         self.optimizer = Lookahead(torch.optim.Adam(self.model.parameters(), lr=args.initial_lr), k=5, alpha=0.5)\n",
    "        self.optimizer = optim.Lamb(self.model.parameters(), lr=args.initial_lr)\n",
    "        \n",
    "        iter_per_epoch = len(self.train_loader)\n",
    "        self.warmup_scheduler = WarmUpLR(self.optimizer, iter_per_epoch * args.warm_epoch)\n",
    "\n",
    "        if args.scheduler == 'step':\n",
    "            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=args.milestone, gamma=args.lr_factor, verbose=True)\n",
    "        elif args.scheduler == 'cos':\n",
    "            tmax = args.tmax # half-cycle \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max = tmax, eta_min=args.min_lr, verbose=True)\n",
    "        elif args.scheduler == 'cycle':\n",
    "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=args.max_lr, steps_per_epoch=iter_per_epoch, epochs=args.epochs)\n",
    "        else:\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=5, factor=0.5, mode=\"max\", verbose=True)\n",
    "            \n",
    "        if args.multi_gpu:\n",
    "            self.model = nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "        # Train / Validate\n",
    "        best_loss = np.inf\n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        early_stopping = 0\n",
    "        start = time.time()\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            if args.scheduler == 'cos':\n",
    "                if epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Training\n",
    "            train_loss, train_acc, train_f1 = self.training(args)\n",
    "\n",
    "            # Model weight in Multi_GPU or Single GPU\n",
    "            state_dict= self.model.module.state_dict() if args.multi_gpu else self.model.state_dict()\n",
    "\n",
    "            # Validation\n",
    "            val_loss, val_acc, val_f1 = self.validate(args, phase='val')\n",
    "\n",
    "            # Save models\n",
    "            if val_loss < best_loss:\n",
    "                early_stopping = 0\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_acc = val_acc\n",
    "                best_f1 = val_f1\n",
    "\n",
    "                torch.save({'epoch':epoch,\n",
    "                            'state_dict':state_dict,\n",
    "                            'optimizer': self.optimizer.state_dict(),\n",
    "                            'scheduler': self.scheduler.state_dict(),\n",
    "                    }, os.path.join(save_path, 'best_model.pth'))\n",
    "                self.logger.info(f'-----------------SAVE:{best_epoch}epoch----------------')\n",
    "            else:\n",
    "                early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if early_stopping == args.patience:\n",
    "                break\n",
    "\n",
    "        self.logger.info(f'\\nBest Val Epoch:{best_epoch} | Val Loss:{best_loss:.4f} | Val Acc:{best_acc:.4f} | Val F1:{best_f1:.4f}')\n",
    "        end = time.time()\n",
    "        self.logger.info(f'Total Process time:{(end - start) / 60:.3f}Minute')\n",
    "\n",
    "    # Training\n",
    "    def training(self, args):\n",
    "        self.model.train()\n",
    "        train_loss = AvgMeter()\n",
    "        train_acc = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        scaler = grad_scaler.GradScaler()\n",
    "        \n",
    "        for i, (images, targets) in enumerate(tqdm(self.train_loader)):\n",
    "            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "            targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            if self.epoch <= args.warm_epoch:\n",
    "                self.warmup_scheduler.step()\n",
    "\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "    \n",
    "            if args.amp:\n",
    "                with autocast():\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, targets)\n",
    "                    \n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Gradient Clipping\n",
    "                if args.clipping is not None:\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if args.scheduler == 'cycle':\n",
    "                if self.epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Metric\n",
    "            train_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "            targets_list.extend(targets.cpu().detach().numpy())\n",
    "            # log\n",
    "            train_loss.update(loss.item(), n=images.size(0))\n",
    "\n",
    "        train_acc /= len(self.train_loader.dataset)\n",
    "        train_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "        self.logger.info(f'Epoch:[{self.epoch:03d}/{args.epochs:03d}]')\n",
    "        self.logger.info(f'Train Loss:{train_loss.avg:.3f} | Acc:{train_acc:.4f} | F1:{train_f1:.4f}')\n",
    "        return train_loss.avg, train_acc, train_f1\n",
    "            \n",
    "    # Validation or Dev\n",
    "    def validate(self, args, phase='val'):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = AvgMeter()\n",
    "            val_acc = 0\n",
    "            preds_list = []\n",
    "            targets_list = []\n",
    "\n",
    "            for i, (images, targets) in enumerate(self.val_loader):\n",
    "                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "                targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "\n",
    "                # Metric\n",
    "                val_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "                preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "                targets_list.extend(targets.cpu().detach().numpy())\n",
    "\n",
    "                # log\n",
    "                val_loss.update(loss.item(), n=images.size(0))\n",
    "            val_acc /= len(self.val_loader.dataset)\n",
    "            val_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "            self.logger.info(f'{phase} Loss:{val_loss.avg:.3f} | Acc:{val_acc:.4f} | F1:{val_f1:.4f}')\n",
    "        return val_loss.avg, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print('<---- Training Params ---->')\n",
    "    \n",
    "    # Random Seed\n",
    "    seed = args.seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    save_path = os.path.join(args.model_path, (args.exp_num).zfill(3))\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    Trainer(args, save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sub = pd.read_csv('./open/sample_submission.csv')\n",
    "df_train = pd.read_csv('./open/train_df_add2.csv')\n",
    "df_test = pd.read_csv('./open/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder_name, test_loader, device, model_path):\n",
    "    model = Network_test(encoder_name).to(device)\n",
    "    model.load_state_dict(torch.load(opj(model_path, 'best_model.pth'))['state_dict'])\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = torch.as_tensor(images, device=device, dtype=torch.float32)\n",
    "            preds = model(images)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            preds_list.extend(preds.cpu().tolist())\n",
    "\n",
    "    return np.array(preds_list)\n",
    "\n",
    "def ensemble_5fold(model_path_list, test_loader, device):\n",
    "    predict_list = []\n",
    "    for model_path in model_path_list:\n",
    "        prediction = predict(encoder_name= 'regnety_040', test_loader = test_loader, device = device, model_path = model_path)\n",
    "        predict_list.append(prediction)\n",
    "    ensemble = (predict_list[0] + predict_list[1] + predict_list[2] + predict_list[3] + predict_list[4])/len(predict_list)\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "def make_pseudo_df(train_df, test_df, ensemble, step, threshold = 0.9, z_sample = 500): \n",
    "    train_df_copy = train_df.copy()\n",
    "    test_df_copy = test_df.copy()\n",
    "\n",
    "    test_df_copy['disease'] = np.nan\n",
    "    test_df_copy['disease_code'] = ensemble.argmax(axis=1)\n",
    "    pseudo_test_df = test_df_copy.iloc[np.where(ensemble > threshold)[0]].reset_index(drop=True)\n",
    "    z_idx  = pseudo_test_df[pseudo_test_df['disease_code'] == 0].sample(n=z_sample, random_state=42).index.tolist()\n",
    "    ot_idx = pseudo_test_df[pseudo_test_df['disease_code'].isin([*range(1,8)])].index.tolist()\n",
    "    pseudo_test_df = pseudo_test_df.iloc[z_idx + ot_idx]\n",
    "\n",
    "    train_df_copy = train_df_copy.append(pseudo_test_df, ignore_index=True).reset_index(drop=True) # reset_index\n",
    "    # print(f'Make train_{step}step.csv')\n",
    "    train_df_copy.to_csv(f'../data/train_{step}step.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:32:39,159 INFO: {'exp_num': '0', 'data_path': './open', 'Kfold': 5, 'model_path': 'label_results/', 'image_type': 'train_1024', 'class_num': 88, 'model_name': 'regnety_040', 'drop_path_rate': 0.2, 'img_size': 512, 'batch_size': 16, 'epochs': 100, 'optimizer': 'Lamb', 'initial_lr': 0.0005, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'Reduce', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-05, 'tmax': 145, 'patience': 7, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Dataset size:4976\n",
      "Dataset size:1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:32:39,553 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_040-f0d569f9.pth)\n",
      "100%|██████████| 311/311 [02:25<00:00,  2.14it/s]\n",
      "2022-05-02 15:35:04,812 INFO: Epoch:[001/100]\n",
      "2022-05-02 15:35:04,813 INFO: Train Loss:4.522 | Acc:0.0163 | F1:0.0073\n",
      "2022-05-02 15:35:22,923 INFO: val Loss:4.207 | Acc:0.0948 | F1:0.0273\n",
      "2022-05-02 15:35:23,603 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 311/311 [02:22<00:00,  2.19it/s]\n",
      "2022-05-02 15:37:45,948 INFO: Epoch:[002/100]\n",
      "2022-05-02 15:37:45,949 INFO: Train Loss:4.138 | Acc:0.1469 | F1:0.0637\n",
      "2022-05-02 15:38:02,706 INFO: val Loss:3.349 | Acc:0.3631 | F1:0.1334\n",
      "2022-05-02 15:38:03,361 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|██████████| 311/311 [02:20<00:00,  2.21it/s]\n",
      "2022-05-02 15:40:23,955 INFO: Epoch:[003/100]\n",
      "2022-05-02 15:40:23,956 INFO: Train Loss:3.509 | Acc:0.3515 | F1:0.1526\n",
      "2022-05-02 15:40:40,402 INFO: val Loss:2.559 | Acc:0.4651 | F1:0.1621\n",
      "2022-05-02 15:40:41,036 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|██████████| 311/311 [02:21<00:00,  2.20it/s]\n",
      "2022-05-02 15:43:02,106 INFO: Epoch:[004/100]\n",
      "2022-05-02 15:43:02,107 INFO: Train Loss:2.887 | Acc:0.3531 | F1:0.1807\n",
      "2022-05-02 15:43:18,610 INFO: val Loss:2.064 | Acc:0.3807 | F1:0.1630\n",
      "2022-05-02 15:43:19,240 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|██████████| 311/311 [02:18<00:00,  2.24it/s]\n",
      "2022-05-02 15:45:38,150 INFO: Epoch:[005/100]\n",
      "2022-05-02 15:45:38,151 INFO: Train Loss:2.510 | Acc:0.3314 | F1:0.2112\n",
      "2022-05-02 15:45:56,061 INFO: val Loss:1.830 | Acc:0.3791 | F1:0.1807\n",
      "2022-05-02 15:45:56,756 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|██████████| 311/311 [02:19<00:00,  2.24it/s]\n",
      "2022-05-02 15:48:15,905 INFO: Epoch:[006/100]\n",
      "2022-05-02 15:48:15,906 INFO: Train Loss:2.317 | Acc:0.3736 | F1:0.2442\n",
      "2022-05-02 15:48:32,193 INFO: val Loss:1.634 | Acc:0.4859 | F1:0.2256\n",
      "2022-05-02 15:48:32,818 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|██████████| 311/311 [02:16<00:00,  2.27it/s]\n",
      "2022-05-02 15:50:49,669 INFO: Epoch:[007/100]\n",
      "2022-05-02 15:50:49,670 INFO: Train Loss:2.129 | Acc:0.4381 | F1:0.3017\n",
      "2022-05-02 15:51:05,654 INFO: val Loss:1.475 | Acc:0.5695 | F1:0.3170\n",
      "2022-05-02 15:51:06,276 INFO: -----------------SAVE:7epoch----------------\n",
      " 85%|████████▍ | 264/311 [02:26<00:19,  2.44it/s]"
     ]
    }
   ],
   "source": [
    "args.step = 0\n",
    "models_path = []\n",
    "for s_fold in range(5): # 5fold\n",
    "    args.fold = s_fold\n",
    "    args.exp_num = str(s_fold)\n",
    "    save_path = main(args)\n",
    "    models_path.append(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 512\n",
    "\n",
    "test_transform = get_train_augmentation(img_size=img_size, ver=1)\n",
    "test_dataset = Test_dataset(df_test, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = ['./label_results/000', './label_results/001', './label_results/002', './label_results/003', './label_results/004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = ensemble_5fold(models_path, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred = ensemble.argmax(axis=1).tolist()\n",
    "f_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"./open/train_df_add2.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submission/label_result_add_0502_수정.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
