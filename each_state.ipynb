{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import easydict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os.path import join as opj\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, grad_scaler\n",
    "from torchvision import transforms\n",
    "from torch import Tensor\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  file_name       class state            label\n",
      "0      0  10000.png  transistor  good  transistor-good\n",
      "1      1  10001.png     capsule  good     capsule-good\n",
      "2      2  10002.png  transistor  good  transistor-good\n",
      "3      3  10003.png        wood  good        wood-good\n",
      "4      4  10004.png      bottle  good      bottle-good\n",
      "   index  file_name\n",
      "0      0  20000.png\n",
      "1      1  20001.png\n",
      "2      2  20002.png\n",
      "3      3  20003.png\n",
      "4      4  20004.png\n",
      "(4277, 5)\n",
      "(2154, 2)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './open'\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train_df.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test_df.csv'))\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {'exp_num':'0',\n",
    "     'class_name':'',\n",
    "     'class_num':0,\n",
    "     \n",
    "     # Path settings\n",
    "     'data_path':'./open',\n",
    "     'Kfold':7,\n",
    "     'model_path':'results/',\n",
    "     'image_type':'train_1024', \n",
    "\n",
    "     # Model parameter settings\n",
    "     'model_name':'regnety_064',\n",
    "     'drop_path_rate':0.2,\n",
    "     \n",
    "     # Training parameter settings\n",
    "     ## Base Parameter\n",
    "     'img_size':352,\n",
    "     'batch_size':8,\n",
    "     'epochs':70,\n",
    "     'optimizer':'Lamb',\n",
    "     'initial_lr':4e-5,\n",
    "     'weight_decay':1e-4,\n",
    "\n",
    "     ## Augmentation\n",
    "     'aug_ver':2,\n",
    "\n",
    "     ## Scheduler (OnecycleLR)\n",
    "     'scheduler':'cycle',\n",
    "     'warm_epoch':5,\n",
    "     'max_lr':5e-4,\n",
    "\n",
    "     ### Cosine Annealing\n",
    "     'min_lr':5e-6,\n",
    "     'tmax':145,\n",
    "\n",
    "     ## etc.\n",
    "     'patience':15,\n",
    "     'clipping':None,\n",
    "\n",
    "     # Hardware settings\n",
    "     'amp':True,\n",
    "     'multi_gpu':True,\n",
    "     'logging':False,\n",
    "     'num_workers':4,\n",
    "     'seed':42\n",
    "     \n",
    "     \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimzier(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        \n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
    "\n",
    "# Logging\n",
    "def get_root_logger(logger_name='basicsr',\n",
    "                    log_level=logging.INFO,\n",
    "                    log_file=None):\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    # if the logger has been initialized, just return it\n",
    "    if logger.hasHandlers():\n",
    "        return logger\n",
    "\n",
    "    format_str = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(format=format_str, level=log_level)\n",
    "\n",
    "    if log_file is not None:\n",
    "        file_handler = logging.FileHandler(log_file, 'w')\n",
    "        file_handler.setFormatter(logging.Formatter(format_str))\n",
    "        file_handler.setLevel(log_level)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "class AvgMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.losses.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(transforms.RandomRotation):\n",
    "    def __init__(self, p: float, degrees: int):\n",
    "        super(RandomRotation, self).__init__(degrees)\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, img):\n",
    "        if torch.rand(1) < self.p:\n",
    "            fill = self.fill\n",
    "            if isinstance(img, Tensor):\n",
    "                if isinstance(fill, (int, float)):\n",
    "                    fill = [float(fill)] * F.get_image_num_channels(img)\n",
    "                else:\n",
    "                    fill = [float(f) for f in fill]\n",
    "            angle = self.get_params(self.degrees)\n",
    "\n",
    "            img = F.rotate(img, angle, self.resample, self.expand, self.center, fill)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "class CutPaste(object):\n",
    "\n",
    "    def __init__(self, transform = True, type = 'binary'):\n",
    "\n",
    "        '''\n",
    "        This class creates to different augmentation CutPaste and CutPaste-Scar. Moreover, it returns augmented images\n",
    "        for binary and 3 way classification\n",
    "        :arg\n",
    "        :transform[binary]: - if True use Color Jitter augmentations for patches\n",
    "        :type[str]: options ['binary' or '3way'] - classification type\n",
    "        '''\n",
    "        self.type = type\n",
    "        if transform:\n",
    "            self.transform = transforms.ColorJitter(brightness = 0.1,\n",
    "                                                      contrast = 0.1,\n",
    "                                                      saturation = 0.1,\n",
    "                                                      hue = 0.1)\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    @staticmethod\n",
    "    def crop_and_paste_patch(image, patch_w, patch_h, transform, rotation=False):\n",
    "        \"\"\"\n",
    "        Crop patch from original image and paste it randomly on the same image.\n",
    "        :image: [PIL] _ original image\n",
    "        :patch_w: [int] _ width of the patch\n",
    "        :patch_h: [int] _ height of the patch\n",
    "        :transform: [binary] _ if True use Color Jitter augmentation\n",
    "        :rotation: [binary[ _ if True randomly rotates image from (-45, 45) range\n",
    "        :return: augmented image\n",
    "        \"\"\"\n",
    "\n",
    "        org_w, org_h = image.size\n",
    "        mask = None\n",
    "\n",
    "        patch_left, patch_top = random.randint(0, org_w - patch_w), random.randint(0, org_h - patch_h)\n",
    "        patch_right, patch_bottom = patch_left + patch_w, patch_top + patch_h\n",
    "        patch = image.crop((patch_left, patch_top, patch_right, patch_bottom))\n",
    "        if transform:\n",
    "            patch= transform(patch)\n",
    "\n",
    "        if rotation:\n",
    "            random_rotate = random.uniform(*rotation)\n",
    "            patch = patch.convert(\"RGBA\").rotate(random_rotate, expand=True)\n",
    "            mask = patch.split()[-1]\n",
    "\n",
    "        # new location\n",
    "        paste_left, paste_top = random.randint(0, org_w - patch_w), random.randint(0, org_h - patch_h)\n",
    "        aug_image = image.copy()\n",
    "        aug_image.paste(patch, (paste_left, paste_top), mask=mask)\n",
    "        return aug_image\n",
    "\n",
    "    def cutpaste(self, image, area_ratio = (0.02, 0.15), aspect_ratio = ((0.3, 1) , (1, 3.3))):\n",
    "        '''\n",
    "        CutPaste augmentation\n",
    "        :image: [PIL] - original image\n",
    "        :area_ratio: [tuple] - range for area ratio for patch\n",
    "        :aspect_ratio: [tuple] -  range for aspect ratio\n",
    "        :return: PIL image after CutPaste transformation\n",
    "        '''\n",
    "\n",
    "        img_area = image.size[0] * image.size[1]\n",
    "        patch_area = random.uniform(*area_ratio) * img_area\n",
    "        patch_aspect = random.choice([random.uniform(*aspect_ratio[0]), random.uniform(*aspect_ratio[1])])\n",
    "        patch_w  = int(np.sqrt(patch_area*patch_aspect))\n",
    "        patch_h = int(np.sqrt(patch_area/patch_aspect))\n",
    "        cutpaste = self.crop_and_paste_patch(image, patch_w, patch_h, self.transform, rotation = False)\n",
    "        return cutpaste\n",
    "\n",
    "    def cutpaste_scar(self, image, width = [2,16], length = [10,25], rotation = (-45, 45)):\n",
    "        '''\n",
    "        :image: [PIL] - original image\n",
    "        :width: [list] - range for width of patch\n",
    "        :length: [list] - range for length of patch\n",
    "        :rotation: [tuple] - range for rotation\n",
    "        :return: PIL image after CutPaste-Scare transformation\n",
    "        '''\n",
    "        patch_w, patch_h = random.randint(*width), random.randint(*length)\n",
    "        cutpaste_scar = self.crop_and_paste_patch(image, patch_w, patch_h, self.transform, rotation = rotation)\n",
    "        return cutpaste_scar\n",
    "\n",
    "    def __call__(self, image):\n",
    "        '''\n",
    "        :image: [PIL] - original image\n",
    "        :return: if type == 'binary' returns original image and randomly chosen transformation, else it returns\n",
    "                original image, an image after CutPaste transformation and an image after CutPaste-Scar transformation\n",
    "        '''\n",
    "        if self.type == 'binary':\n",
    "            image = random.choice([image, self.cutpaste(image), self.cutpaste_scar(image)])\n",
    "            return image\n",
    "\n",
    "        elif self.type == '3way':\n",
    "            cutpaste = self.cutpaste(image)\n",
    "            scar = self.cutpaste_scar(image)\n",
    "            return image, cutpaste, scar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.img_path = df['file_name'].values\n",
    "        self.target = df['state2'].values \n",
    "        self.cutpaste_transform = CutPaste(type='binary')\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Dataset size:{len(self.img_path)}')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         image = cv2.imread(opj('./open/train/', self.img_path[idx])).astype(np.float32)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "#         target = self.target[idx]\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "        \n",
    "        image = Image.open(opj(opj('./open/train/', self.img_path[idx]))).convert('RGB')\n",
    "        image = self.cutpaste_transform(image)\n",
    "#         image = [self.transform(i) for i in out]\n",
    "        image = self.transform(image)\n",
    "        target = self.target[idx]\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "class Test_dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "#         image = cv2.imread(opj('./open/train/', self.img_path[idx])).astype(np.float32)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "#         target = self.target[idx]\n",
    "\n",
    "#         if self.transform is not None:\n",
    "#             image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "        \n",
    "        image = Image.open(opj(opj('./open/test/', self.img_path[idx]))).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        target = self.target[idx]\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_img_path)\n",
    "\n",
    "def get_loader(df, phase: str, batch_size, shuffle,\n",
    "               num_workers, transform):\n",
    "    if phase == 'test':\n",
    "        dataset = Test_dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "                                 pin_memory=True)\n",
    "#     elif phase == 'val':\n",
    "#         dataset = Train_Dataset(df, transform)\n",
    "#         data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, \n",
    "#                                  pin_memory=True)\n",
    "    else:\n",
    "        dataset = Train_Dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True,\n",
    "                                 drop_last=False)\n",
    "    return data_loader\n",
    "\n",
    "def get_train_augmentation(img_size, ver, cls):\n",
    "    if ver==1: # for validset\n",
    "        transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "    if ver == 2:\n",
    "        if cls == 'cable' or cls == 'capsule' or cls == 'pill':\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                RandomRotation(0.7, degrees=5),\n",
    "                transforms.CenterCrop(340),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "                    ])\n",
    "        elif cls == 'toothbrush' or cls == 'zipper' or cls == 'transistor':\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.RandomHorizontalFlip(0.5),\n",
    "                RandomRotation(0.7, degrees=5),\n",
    "                transforms.CenterCrop(340),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "            ])\n",
    "        elif cls == 'metal_nut':\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                RandomRotation(0.7, 180),\n",
    "                transforms.CenterCrop(340),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.RandomHorizontalFlip(0.5),\n",
    "                transforms.RandomVerticalFlip(0.3),\n",
    "                RandomRotation(0.7, degrees=180),\n",
    "                transforms.CenterCrop(340),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "            ])\n",
    "    \n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model( # timm ImageNet pre-trained 모델 load\n",
    "            args.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes = args.class_num, drop_path_rate=args.drop_path_rate\n",
    "        )\n",
    "\n",
    "#         self.model_ft = coatnet_0()\n",
    "#         num_ftrs = self.model_ft.fc.in_features\n",
    "#         self.model_ft.fc = nn.Linear(num_ftrs, args.class_num)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        return out\n",
    "\n",
    "class Network_test(nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super().__init__()\n",
    "        self.cnn = timm.create_model( # timm ImageNet pre-trained 모델 load\n",
    "            args.model_name,\n",
    "            pretrained=True,\n",
    "            num_classes = args.class_num\n",
    "        )\n",
    "\n",
    "#         self.model_ft = coatnet_4()\n",
    "#         num_ftrs = self.model_ft.fc.in_features\n",
    "#         self.model_ft.fc = nn.Linear(num_ftrs, args.class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixup augmentation을 위한 코드입니다.\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    \"\"\"\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        first_cycle_steps (int): First cycle step size.\n",
    "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
    "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
    "        min_lr(float): Min learning rate. Default: 0.001.\n",
    "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
    "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 optimizer : torch.optim.Optimizer,\n",
    "                 first_cycle_steps : int,\n",
    "                 cycle_mult : float = 1.,\n",
    "                 max_lr : float = 0.1,\n",
    "                 min_lr : float = 0.001,\n",
    "                 warmup_steps : int = 0,\n",
    "                 gamma : float = 1.,\n",
    "                 last_epoch : int = -1\n",
    "        ):\n",
    "        assert warmup_steps < first_cycle_steps\n",
    "        \n",
    "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
    "        self.base_max_lr = max_lr # first max learning rate\n",
    "        self.max_lr = max_lr # max learning rate in the current cycle\n",
    "        self.min_lr = min_lr # min learning rate\n",
    "        self.warmup_steps = warmup_steps # warmup step size\n",
    "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
    "        \n",
    "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle = 0 # cycle count\n",
    "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
    "        \n",
    "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "        # set learning rate min_lr\n",
    "        self.init_lr()\n",
    "    \n",
    "    def init_lr(self):\n",
    "        self.base_lrs = []\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.min_lr\n",
    "            self.base_lrs.append(self.min_lr)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.step_in_cycle == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.step_in_cycle < self.warmup_steps:\n",
    "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.max_lr - base_lr) \\\n",
    "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
    "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.step_in_cycle = self.step_in_cycle + 1\n",
    "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
    "                self.cycle += 1\n",
    "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
    "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
    "        else:\n",
    "            if epoch >= self.first_cycle_steps:\n",
    "                if self.cycle_mult == 1.:\n",
    "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
    "                    self.cycle = epoch // self.first_cycle_steps\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
    "                    self.cycle = n\n",
    "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
    "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
    "            else:\n",
    "                self.cur_cycle_steps = self.first_cycle_steps\n",
    "                self.step_in_cycle = epoch\n",
    "                \n",
    "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_one_hot(targets:torch.Tensor, n_classes:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                    device=targets.device) \\\n",
    "                .fill_(smoothing /(n_classes-1)) \\\n",
    "                .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, args, save_path):\n",
    "        '''\n",
    "        args: arguments\n",
    "        save_path: Model 가중치 저장 경로\n",
    "        '''\n",
    "        super(Trainer, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Logging\n",
    "        log_file = os.path.join(save_path, 'log.log')\n",
    "        self.logger = get_root_logger(logger_name='IR', log_level=logging.INFO, log_file=log_file)\n",
    "        self.logger.info(args)\n",
    "        # self.logger.info(args.tag)\n",
    "\n",
    "        # Train, Valid Set load\n",
    "        ############################################################################\n",
    "        if args.step == 0 :\n",
    "            df_train = pd.read_csv(opj(args.data_path, 'train_df_%s.csv' % class_name))\n",
    "#             df_train = df_train[df_train['class'] == class_name]\n",
    "#             df_train = df_train.reset_index(drop=True)\n",
    "        else :\n",
    "            df_train = pd.read_csv(opj(args.data_path, f'train_{args.step}step.csv'))\n",
    "\n",
    "#         if args.image_type is not None:\n",
    "#             df_train['img_path'] = df_train['img_path'].apply(lambda x:x.replace('train_imgs', args.image_type))\n",
    "#             df_train['img_path'] = df_train['img_path'].apply(lambda x:x.replace('test_imgs', 'test_1024'))\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=args.Kfold, shuffle=True, random_state=args.seed)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(df_train)), y=df_train['state2'])):\n",
    "            df_train.loc[val_idx, 'fold'] = fold\n",
    "        val_idx = list(df_train[df_train['fold'] == int(args.fold)].index)\n",
    "\n",
    "        df_val = df_train[df_train['fold'] == args.fold].reset_index(drop=True)\n",
    "        df_train = df_train[df_train['fold'] != args.fold].reset_index(drop=True)\n",
    "        \n",
    "#         y_train=df_train['state2']\n",
    "#         class_counts = y_train.value_counts().to_list() #43200, 4800\n",
    "#         num_samples = sum(class_counts) # 48000 - 전체 데이터 갯수\n",
    "#         labels = y_train.to_list()\n",
    "\n",
    "#         #클래스별 가중치 부여 [48000/43200, 48000/4800] => class 1에 가중치 높게 부여하게 됨\n",
    "#         over_class_weights = [num_samples / class_counts[i] for i in range(len(class_counts))] \n",
    "\n",
    "#         # 해당 데이터의 label에 해당되는 가중치\n",
    "#         weights = [over_class_weights[labels[i]] for i in range(int(num_samples))] #해당 레이블마다의 가중치 비율\n",
    "#         sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "\n",
    "        # Augmentation\n",
    "        self.train_transform = get_train_augmentation(img_size=args.img_size, ver=args.aug_ver, cls=args.class_name)\n",
    "        self.test_transform = get_train_augmentation(img_size=args.img_size, ver=1, cls=args.class_name)\n",
    "\n",
    "        # TrainLoader\n",
    "        self.train_loader = get_loader(df_train, phase='train', batch_size=args.batch_size, shuffle=True,\n",
    "                                       num_workers=args.num_workers, transform=self.train_transform)\n",
    "        self.val_loader = get_loader(df_val, phase='train', batch_size=args.batch_size, shuffle=False,\n",
    "                                       num_workers=args.num_workers, transform=self.test_transform)\n",
    "\n",
    "        # Network\n",
    "        self.model = Network(args).to(self.device)\n",
    "        \n",
    "        # weighted crossentropy loss를 위한 weight 계산 함수\n",
    "        def get_class_weight():\n",
    "            return 1 / df_train['state2'].value_counts().sort_index().values\n",
    "\n",
    "        self.class_weight = get_class_weight()\n",
    "\n",
    "        # Loss\n",
    "#         self.criterion = SmoothCrossEntropyLoss(smoothing=0.2)\n",
    "        self.criterion = nn.CrossEntropyLoss(weight= torch.Tensor(self.class_weight).cuda())\n",
    "#         self.criterion = CutMixCrossEntropyLoss(True)\n",
    "\n",
    "        \n",
    "        # Optimizer & Scheduler\n",
    "        self.optimizer = optim.Lamb(self.model.parameters(), lr=args.initial_lr, weight_decay=args.weight_decay)\n",
    "        \n",
    "        iter_per_epoch = len(self.train_loader)\n",
    "        self.warmup_scheduler = WarmUpLR(self.optimizer, iter_per_epoch * args.warm_epoch)\n",
    "\n",
    "        if args.scheduler == 'step':\n",
    "            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=args.milestone, gamma=args.lr_factor, verbose=True)\n",
    "        elif args.scheduler == 'cos':\n",
    "            tmax = args.tmax # half-cycle \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max = tmax, eta_min=args.min_lr, verbose=True)\n",
    "        elif args.scheduler == 'cycle':\n",
    "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=args.max_lr, steps_per_epoch=iter_per_epoch, epochs=args.epochs)\n",
    "        else:\n",
    "            self.scheduler = CosineAnnealingWarmupRestarts(self.optimizer,\n",
    "                                          first_cycle_steps=60,\n",
    "                                          cycle_mult=1.0,\n",
    "                                          max_lr=args.max_lr,\n",
    "                                          min_lr=args.min_lr,\n",
    "                                          warmup_steps=args.warm_epoch,\n",
    "                                          gamma=1.0)\n",
    "            \n",
    "        if args.multi_gpu:\n",
    "            self.model = nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "        # Train / Validate\n",
    "        best_loss = np.inf\n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        early_stopping = 0\n",
    "        start = time.time()\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            if args.scheduler == 'cos':\n",
    "                if epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Training\n",
    "            train_loss, train_acc, train_f1 = self.training(args)\n",
    "\n",
    "            # Model weight in Multi_GPU or Single GPU\n",
    "            state_dict= self.model.module.state_dict() if args.multi_gpu else self.model.state_dict()\n",
    "\n",
    "            # Validation\n",
    "            val_loss, val_acc, val_f1 = self.validate(args, phase='val')\n",
    "\n",
    "            # Save models\n",
    "            if val_loss < best_loss:\n",
    "                early_stopping = 0\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_acc = val_acc\n",
    "                best_f1 = val_f1\n",
    "\n",
    "                torch.save({'epoch':epoch,\n",
    "                            'state_dict':state_dict,\n",
    "                            'optimizer': self.optimizer.state_dict(),\n",
    "                            'scheduler': self.scheduler.state_dict(),\n",
    "                    }, os.path.join(save_path, 'best_model.pth'))\n",
    "                self.logger.info(f'-----------------SAVE:{best_epoch}epoch----------------')\n",
    "            else:\n",
    "                early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if early_stopping == args.patience:\n",
    "                break\n",
    "\n",
    "        self.logger.info(f'\\nBest Val Epoch:{best_epoch} | Val Loss:{best_loss:.4f} | Val Acc:{best_acc:.4f} | Val F1:{best_f1:.4f}')\n",
    "        end = time.time()\n",
    "        self.logger.info(f'Total Process time:{(end - start) / 60:.3f}Minute')\n",
    "\n",
    "    # Training\n",
    "    def training(self, args):\n",
    "        self.model.train()\n",
    "        train_loss = AvgMeter()\n",
    "        train_acc = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        scaler = grad_scaler.GradScaler()\n",
    "        for i, (images, targets) in enumerate(tqdm(self.train_loader)):\n",
    "            \n",
    "            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "            targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            if i % 2 == 0:\n",
    "                images, targets_a, targets_b, lam = mixup_data(images, targets)\n",
    "            \n",
    "   \n",
    "            if self.epoch <= args.warm_epoch:\n",
    "                self.warmup_scheduler.step()\n",
    "\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "            if args.amp:\n",
    "                with autocast():\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, targets)\n",
    "                    \n",
    "                    if i % 3 == 0:\n",
    "                        loss = mixup_criterion(self.criterion, preds, targets_a, targets_b, lam)\n",
    "                    \n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                # Gradient Clipping\n",
    "                if args.clipping is not None:\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if args.scheduler == 'cycle':\n",
    "                if self.epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Metric\n",
    "            train_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "            targets_list.extend(targets.cpu().detach().numpy())\n",
    "            # log\n",
    "            train_loss.update(loss.item(), n=images.size(0))\n",
    "\n",
    "        train_acc /= len(self.train_loader.dataset)\n",
    "        train_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "        self.logger.info(f'Epoch:[{self.epoch:03d}/{args.epochs:03d}]')\n",
    "        self.logger.info(f'Train Loss:{train_loss.avg:.3f} | Acc:{train_acc:.4f} | F1:{train_f1:.4f}')\n",
    "        return train_loss.avg, train_acc, train_f1\n",
    "            \n",
    "    # Validation or Dev\n",
    "    def validate(self, args, phase='val'):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = AvgMeter()\n",
    "            val_acc = 0\n",
    "            preds_list = []\n",
    "            targets_list = []\n",
    "\n",
    "            for i, (images, targets) in enumerate(self.val_loader):\n",
    "                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "                targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "\n",
    "                # Metric\n",
    "                val_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "                preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "                targets_list.extend(targets.cpu().detach().numpy())\n",
    "\n",
    "                # log\n",
    "                val_loss.update(loss.item(), n=images.size(0))\n",
    "            val_acc /= len(self.val_loader.dataset)\n",
    "            val_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "            self.logger.info(f'{phase} Loss:{val_loss.avg:.3f} | Acc:{val_acc:.4f} | F1:{val_f1:.4f}')\n",
    "        return val_loss.avg, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print('<---- Training Params ---->')\n",
    "    \n",
    "    # Random Seed\n",
    "    seed = args.seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    save_path = os.path.join(args.model_path, args.class_name, (args.exp_num).zfill(3))\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    Trainer(args, save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1\"  # Set the GPUs 2 and 3 to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sub = pd.read_csv('./open/sample_submission.csv')\n",
    "df_train = pd.read_csv('./open/train_df2.csv')\n",
    "df_test = pd.read_csv('./open/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['transistor', 'capsule', 'wood', 'bottle', 'screw', 'cable',\n",
       "       'carpet', 'hazelnut', 'pill', 'metal_nut', 'zipper', 'leather',\n",
       "       'toothbrush', 'tile', 'grid'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['transistor', 'capsule', 'wood', 'bottle', 'screw', 'cable',\n",
    "       'carpet', 'hazelnut', 'pill', 'metal_nut', 'zipper', 'leather',\n",
    "       'toothbrush', 'tile', 'grid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 09:42:56,874 INFO: {'exp_num': '0', 'class_name': 'transistor', 'class_num': 5, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name       class      state                 label\n",
      "0        0  10000.png  transistor       good       transistor-good\n",
      "1        2  10002.png  transistor       good       transistor-good\n",
      "2        9  10009.png  transistor       good       transistor-good\n",
      "3       42  10042.png  transistor       good       transistor-good\n",
      "4       49  10049.png  transistor       good       transistor-good\n",
      "..     ...        ...         ...        ...                   ...\n",
      "228   4149  14149.png  transistor       good       transistor-good\n",
      "229   4203  14203.png  transistor  misplaced  transistor-misplaced\n",
      "230   4248  14248.png  transistor  bent_lead  transistor-bent_lead\n",
      "231   4272  14272.png  transistor       good       transistor-good\n",
      "232   4273  14273.png  transistor       good       transistor-good\n",
      "\n",
      "[233 rows x 5 columns]\n",
      "good            213\n",
      "damaged_case      5\n",
      "bent_lead         5\n",
      "misplaced         5\n",
      "cut_lead          5\n",
      "Name: state, dtype: int64\n",
      "5\n",
      "<---- Training Params ---->\n",
      "Dataset size:199\n",
      "Dataset size:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 09:42:57,333 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      "100%|██████████| 25/25 [00:13<00:00,  1.79it/s]\n",
      "2022-04-15 09:43:15,211 INFO: Epoch:[001/070]\n",
      "2022-04-15 09:43:15,212 INFO: Train Loss:1.710 | Acc:0.0302 | F1:0.0123\n",
      "2022-04-15 09:43:17,595 INFO: val Loss:1.652 | Acc:0.0294 | F1:0.0147\n",
      "2022-04-15 09:43:18,451 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.93it/s]\n",
      "2022-04-15 09:43:26,986 INFO: Epoch:[002/070]\n",
      "2022-04-15 09:43:26,987 INFO: Train Loss:1.700 | Acc:0.0352 | F1:0.0627\n",
      "2022-04-15 09:43:28,607 INFO: val Loss:1.672 | Acc:0.0294 | F1:0.0143\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.24it/s]\n",
      "2022-04-15 09:43:36,331 INFO: Epoch:[003/070]\n",
      "2022-04-15 09:43:36,331 INFO: Train Loss:1.704 | Acc:0.0302 | F1:0.0124\n",
      "2022-04-15 09:43:37,814 INFO: val Loss:1.665 | Acc:0.0294 | F1:0.0143\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.10it/s]\n",
      "2022-04-15 09:43:45,891 INFO: Epoch:[004/070]\n",
      "2022-04-15 09:43:45,892 INFO: Train Loss:1.662 | Acc:0.0201 | F1:0.0079\n",
      "2022-04-15 09:43:47,365 INFO: val Loss:1.637 | Acc:0.0294 | F1:0.0143\n",
      "2022-04-15 09:43:48,285 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.12it/s]\n",
      "2022-04-15 09:43:56,321 INFO: Epoch:[005/070]\n",
      "2022-04-15 09:43:56,321 INFO: Train Loss:1.682 | Acc:0.0201 | F1:0.0079\n",
      "2022-04-15 09:43:57,808 INFO: val Loss:1.653 | Acc:0.0294 | F1:0.0143\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.19it/s]\n",
      "2022-04-15 09:44:05,651 INFO: Epoch:[006/070]\n",
      "2022-04-15 09:44:05,651 INFO: Train Loss:1.679 | Acc:0.0201 | F1:0.0079\n",
      "2022-04-15 09:44:07,326 INFO: val Loss:1.650 | Acc:0.0294 | F1:0.0143\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.12it/s]\n",
      "2022-04-15 09:44:15,351 INFO: Epoch:[007/070]\n",
      "2022-04-15 09:44:15,352 INFO: Train Loss:1.639 | Acc:0.0201 | F1:0.0080\n",
      "2022-04-15 09:44:16,826 INFO: val Loss:1.630 | Acc:0.0294 | F1:0.0143\n",
      "2022-04-15 09:44:17,688 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.22it/s]\n",
      "2022-04-15 09:44:25,471 INFO: Epoch:[008/070]\n",
      "2022-04-15 09:44:25,472 INFO: Train Loss:1.664 | Acc:0.0201 | F1:0.0079\n",
      "2022-04-15 09:44:27,087 INFO: val Loss:1.623 | Acc:0.0294 | F1:0.0147\n",
      "2022-04-15 09:44:28,017 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.11it/s]\n",
      "2022-04-15 09:44:36,053 INFO: Epoch:[009/070]\n",
      "2022-04-15 09:44:36,054 INFO: Train Loss:1.633 | Acc:0.0302 | F1:0.0769\n",
      "2022-04-15 09:44:37,772 INFO: val Loss:1.606 | Acc:0.0294 | F1:0.0143\n",
      "2022-04-15 09:44:38,610 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.04it/s]\n",
      "2022-04-15 09:44:46,841 INFO: Epoch:[010/070]\n",
      "2022-04-15 09:44:46,842 INFO: Train Loss:1.662 | Acc:0.0251 | F1:0.0102\n",
      "2022-04-15 09:44:48,511 INFO: val Loss:1.539 | Acc:0.0294 | F1:0.0156\n",
      "2022-04-15 09:44:49,431 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.19it/s]\n",
      "2022-04-15 09:44:57,276 INFO: Epoch:[011/070]\n",
      "2022-04-15 09:44:57,277 INFO: Train Loss:1.603 | Acc:0.0302 | F1:0.0123\n",
      "2022-04-15 09:44:58,881 INFO: val Loss:1.511 | Acc:0.1176 | F1:0.0614\n",
      "2022-04-15 09:44:59,721 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.15it/s]\n",
      "2022-04-15 09:45:07,666 INFO: Epoch:[012/070]\n",
      "2022-04-15 09:45:07,667 INFO: Train Loss:1.598 | Acc:0.0653 | F1:0.0271\n",
      "2022-04-15 09:45:09,355 INFO: val Loss:1.501 | Acc:0.1471 | F1:0.0750\n",
      "2022-04-15 09:45:10,179 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.14it/s]\n",
      "2022-04-15 09:45:18,144 INFO: Epoch:[013/070]\n",
      "2022-04-15 09:45:18,145 INFO: Train Loss:1.558 | Acc:0.1809 | F1:0.0685\n",
      "2022-04-15 09:45:19,841 INFO: val Loss:1.467 | Acc:0.5000 | F1:0.2000\n",
      "2022-04-15 09:45:20,670 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.18it/s]\n",
      "2022-04-15 09:45:28,546 INFO: Epoch:[014/070]\n",
      "2022-04-15 09:45:28,547 INFO: Train Loss:1.544 | Acc:0.3869 | F1:0.1236\n",
      "2022-04-15 09:45:30,260 INFO: val Loss:1.419 | Acc:0.6765 | F1:0.2662\n",
      "2022-04-15 09:45:31,247 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.14it/s]\n",
      "2022-04-15 09:45:39,230 INFO: Epoch:[015/070]\n",
      "2022-04-15 09:45:39,231 INFO: Train Loss:1.511 | Acc:0.5980 | F1:0.1716\n",
      "2022-04-15 09:45:40,969 INFO: val Loss:1.346 | Acc:0.9412 | F1:0.4960\n",
      "2022-04-15 09:45:41,817 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n",
      "2022-04-15 09:45:49,738 INFO: Epoch:[016/070]\n",
      "2022-04-15 09:45:49,738 INFO: Train Loss:1.474 | Acc:0.6734 | F1:0.2194\n",
      "2022-04-15 09:45:51,428 INFO: val Loss:1.267 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:45:52,248 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.24it/s]\n",
      "2022-04-15 09:45:59,977 INFO: Epoch:[017/070]\n",
      "2022-04-15 09:45:59,978 INFO: Train Loss:1.470 | Acc:0.7789 | F1:0.1756\n",
      "2022-04-15 09:46:01,662 INFO: val Loss:1.247 | Acc:0.9118 | F1:0.4881\n",
      "2022-04-15 09:46:02,525 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 09:46:10,126 INFO: Epoch:[018/070]\n",
      "2022-04-15 09:46:10,127 INFO: Train Loss:1.408 | Acc:0.8543 | F1:0.2423\n",
      "2022-04-15 09:46:11,890 INFO: val Loss:1.090 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:46:12,731 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.19it/s]\n",
      "2022-04-15 09:46:20,584 INFO: Epoch:[019/070]\n",
      "2022-04-15 09:46:20,585 INFO: Train Loss:1.425 | Acc:0.9095 | F1:0.2904\n",
      "2022-04-15 09:46:22,130 INFO: val Loss:1.111 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.30it/s]\n",
      "2022-04-15 09:46:29,725 INFO: Epoch:[020/070]\n",
      "2022-04-15 09:46:29,725 INFO: Train Loss:1.411 | Acc:0.9196 | F1:0.2716\n",
      "2022-04-15 09:46:31,396 INFO: val Loss:1.069 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:46:32,083 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.20it/s]\n",
      "2022-04-15 09:46:39,894 INFO: Epoch:[021/070]\n",
      "2022-04-15 09:46:39,894 INFO: Train Loss:1.391 | Acc:0.9146 | F1:0.2577\n",
      "2022-04-15 09:46:41,637 INFO: val Loss:1.050 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:46:42,497 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.09it/s]\n",
      "2022-04-15 09:46:50,588 INFO: Epoch:[022/070]\n",
      "2022-04-15 09:46:50,589 INFO: Train Loss:1.311 | Acc:0.9246 | F1:0.3259\n",
      "2022-04-15 09:46:52,383 INFO: val Loss:0.927 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:46:53,207 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.19it/s]\n",
      "2022-04-15 09:47:01,058 INFO: Epoch:[023/070]\n",
      "2022-04-15 09:47:01,059 INFO: Train Loss:1.248 | Acc:0.9296 | F1:0.3874\n",
      "2022-04-15 09:47:02,671 INFO: val Loss:0.908 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:47:03,528 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n",
      "2022-04-15 09:47:11,460 INFO: Epoch:[024/070]\n",
      "2022-04-15 09:47:11,460 INFO: Train Loss:1.308 | Acc:0.9095 | F1:0.1905\n",
      "2022-04-15 09:47:13,049 INFO: val Loss:0.899 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:47:13,893 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.19it/s]\n",
      "2022-04-15 09:47:21,747 INFO: Epoch:[025/070]\n",
      "2022-04-15 09:47:21,747 INFO: Train Loss:1.213 | Acc:0.9146 | F1:0.2577\n",
      "2022-04-15 09:47:23,312 INFO: val Loss:0.937 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.14it/s]\n",
      "2022-04-15 09:47:31,288 INFO: Epoch:[026/070]\n",
      "2022-04-15 09:47:31,289 INFO: Train Loss:1.248 | Acc:0.9246 | F1:0.3735\n",
      "2022-04-15 09:47:32,924 INFO: val Loss:0.929 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.14it/s]\n",
      "2022-04-15 09:47:40,900 INFO: Epoch:[027/070]\n",
      "2022-04-15 09:47:40,901 INFO: Train Loss:1.222 | Acc:0.9146 | F1:0.2582\n",
      "2022-04-15 09:47:42,618 INFO: val Loss:0.840 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:47:43,473 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.15it/s]\n",
      "2022-04-15 09:47:51,420 INFO: Epoch:[028/070]\n",
      "2022-04-15 09:47:51,421 INFO: Train Loss:1.253 | Acc:0.9045 | F1:0.3015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 09:47:52,936 INFO: val Loss:0.860 | Acc:0.9118 | F1:0.4881\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.12it/s]\n",
      "2022-04-15 09:48:00,961 INFO: Epoch:[029/070]\n",
      "2022-04-15 09:48:00,962 INFO: Train Loss:1.169 | Acc:0.9196 | F1:0.4057\n",
      "2022-04-15 09:48:02,645 INFO: val Loss:0.821 | Acc:0.9118 | F1:0.4881\n",
      "2022-04-15 09:48:03,468 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.08it/s]\n",
      "2022-04-15 09:48:11,594 INFO: Epoch:[030/070]\n",
      "2022-04-15 09:48:11,595 INFO: Train Loss:1.103 | Acc:0.9246 | F1:0.4801\n",
      "2022-04-15 09:48:13,284 INFO: val Loss:0.787 | Acc:0.9118 | F1:0.4881\n",
      "2022-04-15 09:48:14,120 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.17it/s]\n",
      "2022-04-15 09:48:22,025 INFO: Epoch:[031/070]\n",
      "2022-04-15 09:48:22,026 INFO: Train Loss:1.172 | Acc:0.9146 | F1:0.3470\n",
      "2022-04-15 09:48:23,656 INFO: val Loss:0.720 | Acc:0.9118 | F1:0.4881\n",
      "2022-04-15 09:48:24,495 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.20it/s]\n",
      "2022-04-15 09:48:32,322 INFO: Epoch:[032/070]\n",
      "2022-04-15 09:48:32,323 INFO: Train Loss:1.076 | Acc:0.9146 | F1:0.2997\n",
      "2022-04-15 09:48:33,988 INFO: val Loss:0.759 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.27it/s]\n",
      "2022-04-15 09:48:41,636 INFO: Epoch:[033/070]\n",
      "2022-04-15 09:48:41,637 INFO: Train Loss:1.056 | Acc:0.8945 | F1:0.2692\n",
      "2022-04-15 09:48:43,314 INFO: val Loss:0.641 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:48:44,171 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.13it/s]\n",
      "2022-04-15 09:48:52,171 INFO: Epoch:[034/070]\n",
      "2022-04-15 09:48:52,172 INFO: Train Loss:1.109 | Acc:0.9196 | F1:0.3920\n",
      "2022-04-15 09:48:53,873 INFO: val Loss:0.751 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.10it/s]\n",
      "2022-04-15 09:49:01,933 INFO: Epoch:[035/070]\n",
      "2022-04-15 09:49:01,934 INFO: Train Loss:1.102 | Acc:0.9246 | F1:0.4658\n",
      "2022-04-15 09:49:03,552 INFO: val Loss:0.740 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.18it/s]\n",
      "2022-04-15 09:49:11,423 INFO: Epoch:[036/070]\n",
      "2022-04-15 09:49:11,423 INFO: Train Loss:1.098 | Acc:0.9347 | F1:0.5264\n",
      "2022-04-15 09:49:13,003 INFO: val Loss:0.755 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.17it/s]\n",
      "2022-04-15 09:49:20,887 INFO: Epoch:[037/070]\n",
      "2022-04-15 09:49:20,888 INFO: Train Loss:0.888 | Acc:0.9246 | F1:0.4729\n",
      "2022-04-15 09:49:22,605 INFO: val Loss:0.631 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:49:23,447 INFO: -----------------SAVE:37epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n",
      "2022-04-15 09:49:31,379 INFO: Epoch:[038/070]\n",
      "2022-04-15 09:49:31,379 INFO: Train Loss:1.171 | Acc:0.9045 | F1:0.3731\n",
      "2022-04-15 09:49:33,044 INFO: val Loss:0.699 | Acc:0.9118 | F1:0.4881\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.09it/s]\n",
      "2022-04-15 09:49:41,139 INFO: Epoch:[039/070]\n",
      "2022-04-15 09:49:41,139 INFO: Train Loss:1.021 | Acc:0.9397 | F1:0.6126\n",
      "2022-04-15 09:49:42,697 INFO: val Loss:0.671 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.10it/s]\n",
      "2022-04-15 09:49:50,777 INFO: Epoch:[040/070]\n",
      "2022-04-15 09:49:50,778 INFO: Train Loss:1.156 | Acc:0.8894 | F1:0.3880\n",
      "2022-04-15 09:49:52,377 INFO: val Loss:0.814 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.12it/s]\n",
      "2022-04-15 09:50:00,397 INFO: Epoch:[041/070]\n",
      "2022-04-15 09:50:00,397 INFO: Train Loss:1.137 | Acc:0.9246 | F1:0.5058\n",
      "2022-04-15 09:50:02,002 INFO: val Loss:0.807 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.17it/s]\n",
      "2022-04-15 09:50:09,904 INFO: Epoch:[042/070]\n",
      "2022-04-15 09:50:09,905 INFO: Train Loss:0.941 | Acc:0.9347 | F1:0.5840\n",
      "2022-04-15 09:50:11,591 INFO: val Loss:0.621 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:50:12,410 INFO: -----------------SAVE:42epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.27it/s]\n",
      "2022-04-15 09:50:20,061 INFO: Epoch:[043/070]\n",
      "2022-04-15 09:50:20,062 INFO: Train Loss:0.894 | Acc:0.9246 | F1:0.5433\n",
      "2022-04-15 09:50:21,778 INFO: val Loss:0.687 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.11it/s]\n",
      "2022-04-15 09:50:29,832 INFO: Epoch:[044/070]\n",
      "2022-04-15 09:50:29,833 INFO: Train Loss:0.955 | Acc:0.9347 | F1:0.6001\n",
      "2022-04-15 09:50:31,506 INFO: val Loss:0.786 | Acc:0.8824 | F1:0.3871\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.11it/s]\n",
      "2022-04-15 09:50:39,558 INFO: Epoch:[045/070]\n",
      "2022-04-15 09:50:39,558 INFO: Train Loss:0.954 | Acc:0.9196 | F1:0.5312\n",
      "2022-04-15 09:50:41,162 INFO: val Loss:0.710 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.20it/s]\n",
      "2022-04-15 09:50:48,989 INFO: Epoch:[046/070]\n",
      "2022-04-15 09:50:48,990 INFO: Train Loss:1.058 | Acc:0.9246 | F1:0.6077\n",
      "2022-04-15 09:50:50,681 INFO: val Loss:0.670 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.14it/s]\n",
      "2022-04-15 09:50:58,650 INFO: Epoch:[047/070]\n",
      "2022-04-15 09:50:58,651 INFO: Train Loss:1.122 | Acc:0.9146 | F1:0.5579\n",
      "2022-04-15 09:51:00,316 INFO: val Loss:0.571 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:51:01,168 INFO: -----------------SAVE:47epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n",
      "2022-04-15 09:51:09,083 INFO: Epoch:[048/070]\n",
      "2022-04-15 09:51:09,083 INFO: Train Loss:0.860 | Acc:0.9296 | F1:0.5986\n",
      "2022-04-15 09:51:10,708 INFO: val Loss:0.622 | Acc:0.9118 | F1:0.4881\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.24it/s]\n",
      "2022-04-15 09:51:18,428 INFO: Epoch:[049/070]\n",
      "2022-04-15 09:51:18,428 INFO: Train Loss:0.791 | Acc:0.9296 | F1:0.5422\n",
      "2022-04-15 09:51:20,037 INFO: val Loss:0.688 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 09:51:27,646 INFO: Epoch:[050/070]\n",
      "2022-04-15 09:51:27,647 INFO: Train Loss:0.826 | Acc:0.9146 | F1:0.5806\n",
      "2022-04-15 09:51:29,384 INFO: val Loss:0.688 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n",
      "2022-04-15 09:51:37,303 INFO: Epoch:[051/070]\n",
      "2022-04-15 09:51:37,303 INFO: Train Loss:0.717 | Acc:0.9296 | F1:0.6582\n",
      "2022-04-15 09:51:39,144 INFO: val Loss:0.693 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.24it/s]\n",
      "2022-04-15 09:51:46,867 INFO: Epoch:[052/070]\n",
      "2022-04-15 09:51:46,867 INFO: Train Loss:0.841 | Acc:0.9296 | F1:0.5573\n",
      "2022-04-15 09:51:48,470 INFO: val Loss:0.493 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:51:49,407 INFO: -----------------SAVE:52epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.17it/s]\n",
      "2022-04-15 09:51:57,296 INFO: Epoch:[053/070]\n",
      "2022-04-15 09:51:57,296 INFO: Train Loss:0.988 | Acc:0.9045 | F1:0.5633\n",
      "2022-04-15 09:51:58,929 INFO: val Loss:0.417 | Acc:0.9706 | F1:0.9126\n",
      "2022-04-15 09:51:59,766 INFO: -----------------SAVE:53epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.13it/s]\n",
      "2022-04-15 09:52:07,767 INFO: Epoch:[054/070]\n",
      "2022-04-15 09:52:07,767 INFO: Train Loss:1.158 | Acc:0.9146 | F1:0.4043\n",
      "2022-04-15 09:52:09,541 INFO: val Loss:0.424 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.33it/s]\n",
      "2022-04-15 09:52:17,052 INFO: Epoch:[055/070]\n",
      "2022-04-15 09:52:17,052 INFO: Train Loss:0.893 | Acc:0.9196 | F1:0.4548\n",
      "2022-04-15 09:52:18,658 INFO: val Loss:0.545 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.12it/s]\n",
      "2022-04-15 09:52:26,681 INFO: Epoch:[056/070]\n",
      "2022-04-15 09:52:26,682 INFO: Train Loss:1.062 | Acc:0.9347 | F1:0.6222\n",
      "2022-04-15 09:52:28,389 INFO: val Loss:0.467 | Acc:0.9118 | F1:0.4881\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.10it/s]\n",
      "2022-04-15 09:52:36,452 INFO: Epoch:[057/070]\n",
      "2022-04-15 09:52:36,453 INFO: Train Loss:1.020 | Acc:0.9246 | F1:0.5752\n",
      "2022-04-15 09:52:38,100 INFO: val Loss:0.458 | Acc:0.9412 | F1:0.6586\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.07it/s]\n",
      "2022-04-15 09:52:46,239 INFO: Epoch:[058/070]\n",
      "2022-04-15 09:52:46,240 INFO: Train Loss:0.846 | Acc:0.9347 | F1:0.5530\n",
      "2022-04-15 09:52:47,899 INFO: val Loss:0.574 | Acc:0.9118 | F1:0.4881\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.17it/s]\n",
      "2022-04-15 09:52:55,781 INFO: Epoch:[059/070]\n",
      "2022-04-15 09:52:55,782 INFO: Train Loss:0.677 | Acc:0.9296 | F1:0.6384\n",
      "2022-04-15 09:52:57,338 INFO: val Loss:0.435 | Acc:0.9412 | F1:0.6586\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.20it/s]\n",
      "2022-04-15 09:53:05,170 INFO: Epoch:[060/070]\n",
      "2022-04-15 09:53:05,171 INFO: Train Loss:1.013 | Acc:0.9246 | F1:0.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 09:53:06,932 INFO: val Loss:0.474 | Acc:0.9118 | F1:0.4881\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.28it/s]\n",
      "2022-04-15 09:53:14,563 INFO: Epoch:[061/070]\n",
      "2022-04-15 09:53:14,564 INFO: Train Loss:0.978 | Acc:0.8995 | F1:0.4292\n",
      "2022-04-15 09:53:16,256 INFO: val Loss:0.501 | Acc:0.8824 | F1:0.4839\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.07it/s]\n",
      "2022-04-15 09:53:24,408 INFO: Epoch:[062/070]\n",
      "2022-04-15 09:53:24,409 INFO: Train Loss:0.733 | Acc:0.9447 | F1:0.6417\n",
      "2022-04-15 09:53:26,033 INFO: val Loss:0.405 | Acc:0.9412 | F1:0.4922\n",
      "2022-04-15 09:53:26,874 INFO: -----------------SAVE:62epoch----------------\n",
      "100%|██████████| 25/25 [00:08<00:00,  3.04it/s]\n",
      "2022-04-15 09:53:35,106 INFO: Epoch:[063/070]\n",
      "2022-04-15 09:53:35,106 INFO: Train Loss:0.722 | Acc:0.9146 | F1:0.5485\n",
      "2022-04-15 09:53:36,669 INFO: val Loss:0.372 | Acc:0.9706 | F1:0.7460\n",
      "2022-04-15 09:53:37,505 INFO: -----------------SAVE:63epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.15it/s]\n",
      "2022-04-15 09:53:45,454 INFO: Epoch:[064/070]\n",
      "2022-04-15 09:53:45,455 INFO: Train Loss:0.921 | Acc:0.9095 | F1:0.4475\n",
      "2022-04-15 09:53:47,137 INFO: val Loss:0.461 | Acc:0.9412 | F1:0.4922\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.25it/s]\n",
      "2022-04-15 09:53:54,833 INFO: Epoch:[065/070]\n",
      "2022-04-15 09:53:54,834 INFO: Train Loss:0.955 | Acc:0.8995 | F1:0.4558\n",
      "2022-04-15 09:53:56,418 INFO: val Loss:0.398 | Acc:0.9118 | F1:0.4881\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.25it/s]\n",
      "2022-04-15 09:54:04,118 INFO: Epoch:[066/070]\n",
      "2022-04-15 09:54:04,119 INFO: Train Loss:0.813 | Acc:0.9045 | F1:0.5146\n",
      "2022-04-15 09:54:05,731 INFO: val Loss:0.351 | Acc:0.9412 | F1:0.7419\n",
      "2022-04-15 09:54:06,638 INFO: -----------------SAVE:66epoch----------------\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.27it/s]\n",
      "2022-04-15 09:54:14,291 INFO: Epoch:[067/070]\n",
      "2022-04-15 09:54:14,291 INFO: Train Loss:0.979 | Acc:0.9196 | F1:0.5294\n",
      "2022-04-15 09:54:15,913 INFO: val Loss:0.357 | Acc:0.9412 | F1:0.7419\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.31it/s]\n",
      "2022-04-15 09:54:23,486 INFO: Epoch:[068/070]\n",
      "2022-04-15 09:54:23,487 INFO: Train Loss:0.975 | Acc:0.9146 | F1:0.3947\n",
      "2022-04-15 09:54:25,206 INFO: val Loss:0.403 | Acc:0.9412 | F1:0.7419\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n",
      "2022-04-15 09:54:33,123 INFO: Epoch:[069/070]\n",
      "2022-04-15 09:54:33,124 INFO: Train Loss:0.859 | Acc:0.9497 | F1:0.7152\n",
      "2022-04-15 09:54:34,660 INFO: val Loss:0.371 | Acc:0.9412 | F1:0.7419\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n",
      "2022-04-15 09:54:42,584 INFO: Epoch:[070/070]\n",
      "2022-04-15 09:54:42,585 INFO: Train Loss:0.626 | Acc:0.9548 | F1:0.7351\n",
      "2022-04-15 09:54:44,216 INFO: val Loss:0.451 | Acc:0.9118 | F1:0.4881\n",
      "2022-04-15 09:54:44,217 INFO: \n",
      "Best Val Epoch:66 | Val Loss:0.3509 | Val Acc:0.9412 | Val F1:0.7419\n",
      "2022-04-15 09:54:44,218 INFO: Total Process time:11.716Minute\n",
      "2022-04-15 09:54:44,241 INFO: {'exp_num': '0', 'class_name': 'capsule', 'class_num': 6, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name    class    state            label\n",
      "0        1  10001.png  capsule     good     capsule-good\n",
      "1        6  10006.png  capsule     good     capsule-good\n",
      "2       22  10022.png  capsule     good     capsule-good\n",
      "3       24  10024.png  capsule     good     capsule-good\n",
      "4       80  10080.png  capsule     good     capsule-good\n",
      "..     ...        ...      ...      ...              ...\n",
      "270   4194  14194.png  capsule     good     capsule-good\n",
      "271   4198  14198.png  capsule     good     capsule-good\n",
      "272   4217  14217.png  capsule  squeeze  capsule-squeeze\n",
      "273   4218  14218.png  capsule     good     capsule-good\n",
      "274   4269  14269.png  capsule     good     capsule-good\n",
      "\n",
      "[275 rows x 5 columns]\n",
      "good              219\n",
      "scratch            12\n",
      "crack              12\n",
      "poke               11\n",
      "faulty_imprint     11\n",
      "squeeze            10\n",
      "Name: state, dtype: int64\n",
      "6\n",
      "<---- Training Params ---->\n",
      "Dataset size:235\n",
      "Dataset size:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 09:54:44,678 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "2022-04-15 09:54:55,835 INFO: Epoch:[001/070]\n",
      "2022-04-15 09:54:55,836 INFO: Train Loss:1.809 | Acc:0.0298 | F1:0.0228\n",
      "2022-04-15 09:54:57,964 INFO: val Loss:1.843 | Acc:0.0500 | F1:0.0615\n",
      "2022-04-15 09:54:58,864 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 09:55:08,236 INFO: Epoch:[002/070]\n",
      "2022-04-15 09:55:08,237 INFO: Train Loss:1.805 | Acc:0.0383 | F1:0.0375\n",
      "2022-04-15 09:55:10,166 INFO: val Loss:1.851 | Acc:0.0000 | F1:0.0000\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 09:55:19,706 INFO: Epoch:[003/070]\n",
      "2022-04-15 09:55:19,706 INFO: Train Loss:1.822 | Acc:0.0553 | F1:0.0658\n",
      "2022-04-15 09:55:21,559 INFO: val Loss:1.826 | Acc:0.0500 | F1:0.0992\n",
      "2022-04-15 09:55:22,467 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 09:55:31,836 INFO: Epoch:[004/070]\n",
      "2022-04-15 09:55:31,837 INFO: Train Loss:1.798 | Acc:0.0596 | F1:0.0534\n",
      "2022-04-15 09:55:33,684 INFO: val Loss:1.777 | Acc:0.0500 | F1:0.0722\n",
      "2022-04-15 09:55:34,540 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 09:55:43,852 INFO: Epoch:[005/070]\n",
      "2022-04-15 09:55:43,853 INFO: Train Loss:1.809 | Acc:0.0255 | F1:0.0371\n",
      "2022-04-15 09:55:45,746 INFO: val Loss:1.875 | Acc:0.0250 | F1:0.0208\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.11it/s]\n",
      "2022-04-15 09:55:55,413 INFO: Epoch:[006/070]\n",
      "2022-04-15 09:55:55,414 INFO: Train Loss:1.823 | Acc:0.0340 | F1:0.0291\n",
      "2022-04-15 09:55:57,357 INFO: val Loss:1.830 | Acc:0.0500 | F1:0.0610\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 09:56:06,652 INFO: Epoch:[007/070]\n",
      "2022-04-15 09:56:06,653 INFO: Train Loss:1.803 | Acc:0.0340 | F1:0.0310\n",
      "2022-04-15 09:56:08,521 INFO: val Loss:1.810 | Acc:0.0750 | F1:0.0620\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 09:56:18,034 INFO: Epoch:[008/070]\n",
      "2022-04-15 09:56:18,034 INFO: Train Loss:1.790 | Acc:0.0596 | F1:0.0622\n",
      "2022-04-15 09:56:19,800 INFO: val Loss:1.812 | Acc:0.0500 | F1:0.0240\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
      "2022-04-15 09:56:29,230 INFO: Epoch:[009/070]\n",
      "2022-04-15 09:56:29,231 INFO: Train Loss:1.795 | Acc:0.0596 | F1:0.0619\n",
      "2022-04-15 09:56:31,200 INFO: val Loss:1.805 | Acc:0.0750 | F1:0.0372\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 09:56:40,771 INFO: Epoch:[010/070]\n",
      "2022-04-15 09:56:40,771 INFO: Train Loss:1.794 | Acc:0.0596 | F1:0.0399\n",
      "2022-04-15 09:56:42,634 INFO: val Loss:1.799 | Acc:0.1250 | F1:0.0895\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 09:56:52,028 INFO: Epoch:[011/070]\n",
      "2022-04-15 09:56:52,029 INFO: Train Loss:1.762 | Acc:0.1191 | F1:0.0821\n",
      "2022-04-15 09:56:53,909 INFO: val Loss:1.822 | Acc:0.1500 | F1:0.0558\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
      "2022-04-15 09:57:03,066 INFO: Epoch:[012/070]\n",
      "2022-04-15 09:57:03,067 INFO: Train Loss:1.768 | Acc:0.2000 | F1:0.0870\n",
      "2022-04-15 09:57:04,944 INFO: val Loss:1.796 | Acc:0.1250 | F1:0.0471\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
      "2022-04-15 09:57:14,009 INFO: Epoch:[013/070]\n",
      "2022-04-15 09:57:14,009 INFO: Train Loss:1.780 | Acc:0.2511 | F1:0.0843\n",
      "2022-04-15 09:57:15,869 INFO: val Loss:1.829 | Acc:0.2500 | F1:0.0843\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.10it/s]\n",
      "2022-04-15 09:57:25,565 INFO: Epoch:[014/070]\n",
      "2022-04-15 09:57:25,566 INFO: Train Loss:1.744 | Acc:0.4511 | F1:0.1648\n",
      "2022-04-15 09:57:27,470 INFO: val Loss:1.792 | Acc:0.4250 | F1:0.1204\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 09:57:36,951 INFO: Epoch:[015/070]\n",
      "2022-04-15 09:57:36,952 INFO: Train Loss:1.715 | Acc:0.5617 | F1:0.1731\n",
      "2022-04-15 09:57:38,798 INFO: val Loss:1.801 | Acc:0.5500 | F1:0.1264\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
      "2022-04-15 09:57:47,887 INFO: Epoch:[016/070]\n",
      "2022-04-15 09:57:47,888 INFO: Train Loss:1.742 | Acc:0.6340 | F1:0.2009\n",
      "2022-04-15 09:57:49,738 INFO: val Loss:1.777 | Acc:0.6250 | F1:0.1661\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 09:57:59,129 INFO: Epoch:[017/070]\n",
      "2022-04-15 09:57:59,129 INFO: Train Loss:1.720 | Acc:0.7064 | F1:0.1701\n",
      "2022-04-15 09:58:01,053 INFO: val Loss:1.812 | Acc:0.7750 | F1:0.1455\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 09:58:10,623 INFO: Epoch:[018/070]\n",
      "2022-04-15 09:58:10,623 INFO: Train Loss:1.730 | Acc:0.6255 | F1:0.1314\n",
      "2022-04-15 09:58:12,441 INFO: val Loss:1.821 | Acc:0.6750 | F1:0.1953\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 09:58:21,940 INFO: Epoch:[019/070]\n",
      "2022-04-15 09:58:21,941 INFO: Train Loss:1.726 | Acc:0.7362 | F1:0.1675\n",
      "2022-04-15 09:58:23,815 INFO: val Loss:1.770 | Acc:0.8000 | F1:0.1502\n",
      "2022-04-15 09:58:24,770 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.06it/s]\n",
      "2022-04-15 09:58:34,574 INFO: Epoch:[020/070]\n",
      "2022-04-15 09:58:34,574 INFO: Train Loss:1.728 | Acc:0.7319 | F1:0.1631\n",
      "2022-04-15 09:58:36,654 INFO: val Loss:1.747 | Acc:0.8000 | F1:0.1481\n",
      "2022-04-15 09:58:37,522 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.10it/s]\n",
      "2022-04-15 09:58:47,208 INFO: Epoch:[021/070]\n",
      "2022-04-15 09:58:47,209 INFO: Train Loss:1.670 | Acc:0.7149 | F1:0.1646\n",
      "2022-04-15 09:58:49,252 INFO: val Loss:1.777 | Acc:0.8250 | F1:0.2379\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.11it/s]\n",
      "2022-04-15 09:58:58,918 INFO: Epoch:[022/070]\n",
      "2022-04-15 09:58:58,919 INFO: Train Loss:1.690 | Acc:0.7234 | F1:0.1601\n",
      "2022-04-15 09:59:00,847 INFO: val Loss:1.719 | Acc:0.5000 | F1:0.1506\n",
      "2022-04-15 09:59:01,714 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.09it/s]\n",
      "2022-04-15 09:59:11,426 INFO: Epoch:[023/070]\n",
      "2022-04-15 09:59:11,426 INFO: Train Loss:1.620 | Acc:0.7362 | F1:0.2433\n",
      "2022-04-15 09:59:13,357 INFO: val Loss:1.696 | Acc:0.8000 | F1:0.2587\n",
      "2022-04-15 09:59:14,208 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2022-04-15 09:59:23,397 INFO: Epoch:[024/070]\n",
      "2022-04-15 09:59:23,398 INFO: Train Loss:1.682 | Acc:0.7532 | F1:0.2344\n",
      "2022-04-15 09:59:25,313 INFO: val Loss:1.773 | Acc:0.6000 | F1:0.1623\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 09:59:34,620 INFO: Epoch:[025/070]\n",
      "2022-04-15 09:59:34,621 INFO: Train Loss:1.661 | Acc:0.7702 | F1:0.2780\n",
      "2022-04-15 09:59:36,555 INFO: val Loss:1.763 | Acc:0.8000 | F1:0.2186\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 09:59:46,123 INFO: Epoch:[026/070]\n",
      "2022-04-15 09:59:46,124 INFO: Train Loss:1.595 | Acc:0.7574 | F1:0.2163\n",
      "2022-04-15 09:59:48,045 INFO: val Loss:1.729 | Acc:0.7500 | F1:0.2154\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.05it/s]\n",
      "2022-04-15 09:59:57,880 INFO: Epoch:[027/070]\n",
      "2022-04-15 09:59:57,881 INFO: Train Loss:1.636 | Acc:0.7745 | F1:0.2710\n",
      "2022-04-15 09:59:59,969 INFO: val Loss:1.623 | Acc:0.7250 | F1:0.2014\n",
      "2022-04-15 10:00:00,889 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:00:10,227 INFO: Epoch:[028/070]\n",
      "2022-04-15 10:00:10,228 INFO: Train Loss:1.595 | Acc:0.7234 | F1:0.1885\n",
      "2022-04-15 10:00:12,154 INFO: val Loss:1.680 | Acc:0.3250 | F1:0.1045\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:00:21,417 INFO: Epoch:[029/070]\n",
      "2022-04-15 10:00:21,417 INFO: Train Loss:1.543 | Acc:0.7745 | F1:0.3001\n",
      "2022-04-15 10:00:23,296 INFO: val Loss:1.555 | Acc:0.7250 | F1:0.2103\n",
      "2022-04-15 10:00:24,178 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
      "2022-04-15 10:00:33,276 INFO: Epoch:[030/070]\n",
      "2022-04-15 10:00:33,277 INFO: Train Loss:1.573 | Acc:0.7532 | F1:0.2656\n",
      "2022-04-15 10:00:35,243 INFO: val Loss:1.540 | Acc:0.7250 | F1:0.2483\n",
      "2022-04-15 10:00:36,127 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 10:00:45,690 INFO: Epoch:[031/070]\n",
      "2022-04-15 10:00:45,690 INFO: Train Loss:1.624 | Acc:0.7532 | F1:0.2453\n",
      "2022-04-15 10:00:47,621 INFO: val Loss:1.505 | Acc:0.7750 | F1:0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:00:48,562 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.04it/s]\n",
      "2022-04-15 10:00:58,427 INFO: Epoch:[032/070]\n",
      "2022-04-15 10:00:58,427 INFO: Train Loss:1.517 | Acc:0.7702 | F1:0.2649\n",
      "2022-04-15 10:01:00,312 INFO: val Loss:1.460 | Acc:0.8500 | F1:0.6237\n",
      "2022-04-15 10:01:01,154 INFO: -----------------SAVE:32epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 10:01:10,667 INFO: Epoch:[033/070]\n",
      "2022-04-15 10:01:10,667 INFO: Train Loss:1.499 | Acc:0.7362 | F1:0.3078\n",
      "2022-04-15 10:01:12,559 INFO: val Loss:1.412 | Acc:0.7000 | F1:0.3555\n",
      "2022-04-15 10:01:13,409 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:01:22,893 INFO: Epoch:[034/070]\n",
      "2022-04-15 10:01:22,894 INFO: Train Loss:1.462 | Acc:0.7319 | F1:0.3131\n",
      "2022-04-15 10:01:24,806 INFO: val Loss:1.420 | Acc:0.6000 | F1:0.2421\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.11it/s]\n",
      "2022-04-15 10:01:34,458 INFO: Epoch:[035/070]\n",
      "2022-04-15 10:01:34,458 INFO: Train Loss:1.493 | Acc:0.7617 | F1:0.3399\n",
      "2022-04-15 10:01:36,327 INFO: val Loss:1.335 | Acc:0.8250 | F1:0.4618\n",
      "2022-04-15 10:01:37,217 INFO: -----------------SAVE:35epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:01:46,553 INFO: Epoch:[036/070]\n",
      "2022-04-15 10:01:46,554 INFO: Train Loss:1.485 | Acc:0.7574 | F1:0.3286\n",
      "2022-04-15 10:01:48,426 INFO: val Loss:1.220 | Acc:0.9000 | F1:0.6592\n",
      "2022-04-15 10:01:49,292 INFO: -----------------SAVE:36epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:01:58,551 INFO: Epoch:[037/070]\n",
      "2022-04-15 10:01:58,552 INFO: Train Loss:1.398 | Acc:0.7532 | F1:0.3666\n",
      "2022-04-15 10:02:00,306 INFO: val Loss:1.314 | Acc:0.7250 | F1:0.3136\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:02:09,648 INFO: Epoch:[038/070]\n",
      "2022-04-15 10:02:09,649 INFO: Train Loss:1.414 | Acc:0.7574 | F1:0.3473\n",
      "2022-04-15 10:02:11,366 INFO: val Loss:1.212 | Acc:0.8750 | F1:0.3783\n",
      "2022-04-15 10:02:12,281 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.12it/s]\n",
      "2022-04-15 10:02:21,917 INFO: Epoch:[039/070]\n",
      "2022-04-15 10:02:21,918 INFO: Train Loss:1.309 | Acc:0.8255 | F1:0.4851\n",
      "2022-04-15 10:02:23,721 INFO: val Loss:1.261 | Acc:0.8500 | F1:0.4899\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:02:33,197 INFO: Epoch:[040/070]\n",
      "2022-04-15 10:02:33,198 INFO: Train Loss:1.298 | Acc:0.8170 | F1:0.4924\n",
      "2022-04-15 10:02:35,010 INFO: val Loss:1.218 | Acc:0.8250 | F1:0.4618\n",
      "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
      "2022-04-15 10:02:43,997 INFO: Epoch:[041/070]\n",
      "2022-04-15 10:02:43,998 INFO: Train Loss:1.246 | Acc:0.8426 | F1:0.5523\n",
      "2022-04-15 10:02:45,734 INFO: val Loss:1.491 | Acc:0.7500 | F1:0.2368\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
      "2022-04-15 10:02:55,150 INFO: Epoch:[042/070]\n",
      "2022-04-15 10:02:55,151 INFO: Train Loss:1.367 | Acc:0.7915 | F1:0.3902\n",
      "2022-04-15 10:02:56,866 INFO: val Loss:1.095 | Acc:0.9000 | F1:0.6868\n",
      "2022-04-15 10:02:57,895 INFO: -----------------SAVE:42epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 10:03:07,263 INFO: Epoch:[043/070]\n",
      "2022-04-15 10:03:07,263 INFO: Train Loss:1.261 | Acc:0.8383 | F1:0.5329\n",
      "2022-04-15 10:03:09,111 INFO: val Loss:1.203 | Acc:0.8750 | F1:0.4648\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 10:03:18,405 INFO: Epoch:[044/070]\n",
      "2022-04-15 10:03:18,405 INFO: Train Loss:1.414 | Acc:0.8043 | F1:0.4503\n",
      "2022-04-15 10:03:20,113 INFO: val Loss:1.155 | Acc:0.8250 | F1:0.4281\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
      "2022-04-15 10:03:29,246 INFO: Epoch:[045/070]\n",
      "2022-04-15 10:03:29,246 INFO: Train Loss:1.342 | Acc:0.7660 | F1:0.3801\n",
      "2022-04-15 10:03:31,005 INFO: val Loss:1.522 | Acc:0.8500 | F1:0.3259\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
      "2022-04-15 10:03:40,086 INFO: Epoch:[046/070]\n",
      "2022-04-15 10:03:40,086 INFO: Train Loss:1.324 | Acc:0.7957 | F1:0.4636\n",
      "2022-04-15 10:03:41,885 INFO: val Loss:1.400 | Acc:0.8500 | F1:0.5010\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:03:51,411 INFO: Epoch:[047/070]\n",
      "2022-04-15 10:03:51,411 INFO: Train Loss:1.241 | Acc:0.8043 | F1:0.4586\n",
      "2022-04-15 10:03:53,251 INFO: val Loss:1.307 | Acc:0.8000 | F1:0.3483\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.94it/s]\n",
      "2022-04-15 10:04:03,479 INFO: Epoch:[048/070]\n",
      "2022-04-15 10:04:03,480 INFO: Train Loss:1.148 | Acc:0.7787 | F1:0.4138\n",
      "2022-04-15 10:04:05,254 INFO: val Loss:1.101 | Acc:0.8500 | F1:0.3948\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
      "2022-04-15 10:04:14,292 INFO: Epoch:[049/070]\n",
      "2022-04-15 10:04:14,292 INFO: Train Loss:1.063 | Acc:0.7830 | F1:0.5231\n",
      "2022-04-15 10:04:16,074 INFO: val Loss:1.230 | Acc:0.8500 | F1:0.3590\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
      "2022-04-15 10:04:25,138 INFO: Epoch:[050/070]\n",
      "2022-04-15 10:04:25,138 INFO: Train Loss:1.287 | Acc:0.7787 | F1:0.4165\n",
      "2022-04-15 10:04:26,944 INFO: val Loss:1.202 | Acc:0.8500 | F1:0.4421\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
      "2022-04-15 10:04:36,189 INFO: Epoch:[051/070]\n",
      "2022-04-15 10:04:36,190 INFO: Train Loss:1.224 | Acc:0.7319 | F1:0.3927\n",
      "2022-04-15 10:04:37,931 INFO: val Loss:1.201 | Acc:0.8500 | F1:0.4201\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 10:04:47,214 INFO: Epoch:[052/070]\n",
      "2022-04-15 10:04:47,214 INFO: Train Loss:1.041 | Acc:0.8043 | F1:0.5262\n",
      "2022-04-15 10:04:48,967 INFO: val Loss:1.127 | Acc:0.8500 | F1:0.3283\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:04:58,235 INFO: Epoch:[053/070]\n",
      "2022-04-15 10:04:58,236 INFO: Train Loss:1.300 | Acc:0.7957 | F1:0.4221\n",
      "2022-04-15 10:05:00,034 INFO: val Loss:1.147 | Acc:0.8500 | F1:0.3283\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 10:05:09,406 INFO: Epoch:[054/070]\n",
      "2022-04-15 10:05:09,407 INFO: Train Loss:1.129 | Acc:0.8128 | F1:0.4836\n",
      "2022-04-15 10:05:11,278 INFO: val Loss:1.210 | Acc:0.8000 | F1:0.2897\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:05:20,594 INFO: Epoch:[055/070]\n",
      "2022-04-15 10:05:20,595 INFO: Train Loss:1.082 | Acc:0.8085 | F1:0.5106\n",
      "2022-04-15 10:05:22,357 INFO: val Loss:1.388 | Acc:0.7750 | F1:0.2118\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n",
      "2022-04-15 10:05:31,404 INFO: Epoch:[056/070]\n",
      "2022-04-15 10:05:31,404 INFO: Train Loss:1.141 | Acc:0.7191 | F1:0.3697\n",
      "2022-04-15 10:05:33,079 INFO: val Loss:1.190 | Acc:0.8000 | F1:0.3062\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:05:42,609 INFO: Epoch:[057/070]\n",
      "2022-04-15 10:05:42,610 INFO: Train Loss:1.231 | Acc:0.7574 | F1:0.3821\n",
      "2022-04-15 10:05:44,397 INFO: val Loss:1.383 | Acc:0.7750 | F1:0.2677\n",
      "2022-04-15 10:05:44,398 INFO: \n",
      "Best Val Epoch:42 | Val Loss:1.0951 | Val Acc:0.9000 | Val F1:0.6868\n",
      "2022-04-15 10:05:44,399 INFO: Total Process time:10.991Minute\n",
      "2022-04-15 10:05:44,432 INFO: {'exp_num': '0', 'class_name': 'wood', 'class_num': 6, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name class state      label\n",
      "0        3  10003.png  wood  good  wood-good\n",
      "1        5  10005.png  wood  good  wood-good\n",
      "2       12  10012.png  wood  good  wood-good\n",
      "3       15  10015.png  wood  good  wood-good\n",
      "4       17  10017.png  wood  good  wood-good\n",
      "..     ...        ...   ...   ...        ...\n",
      "273   4227  14227.png  wood  good  wood-good\n",
      "274   4232  14232.png  wood  good  wood-good\n",
      "275   4254  14254.png  wood  good  wood-good\n",
      "276   4259  14259.png  wood  good  wood-good\n",
      "277   4270  14270.png  wood  good  wood-good\n",
      "\n",
      "[278 rows x 5 columns]\n",
      "good        247\n",
      "scratch      11\n",
      "combined      6\n",
      "liquid        5\n",
      "hole          5\n",
      "color         4\n",
      "Name: state, dtype: int64\n",
      "6\n",
      "<---- Training Params ---->\n",
      "Dataset size:238\n",
      "Dataset size:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:05:44,962 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.90it/s]\n",
      "2022-04-15 10:05:55,571 INFO: Epoch:[001/070]\n",
      "2022-04-15 10:05:55,572 INFO: Train Loss:1.834 | Acc:0.0294 | F1:0.0297\n",
      "2022-04-15 10:05:57,396 INFO: val Loss:1.771 | Acc:0.0500 | F1:0.2100\n",
      "2022-04-15 10:05:58,262 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
      "2022-04-15 10:06:07,505 INFO: Epoch:[002/070]\n",
      "2022-04-15 10:06:07,506 INFO: Train Loss:1.855 | Acc:0.0210 | F1:0.0155\n",
      "2022-04-15 10:06:09,380 INFO: val Loss:1.805 | Acc:0.0500 | F1:0.0759\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
      "2022-04-15 10:06:18,816 INFO: Epoch:[003/070]\n",
      "2022-04-15 10:06:18,817 INFO: Train Loss:1.868 | Acc:0.0462 | F1:0.0400\n",
      "2022-04-15 10:06:20,658 INFO: val Loss:1.795 | Acc:0.0500 | F1:0.1754\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.10it/s]\n",
      "2022-04-15 10:06:30,350 INFO: Epoch:[004/070]\n",
      "2022-04-15 10:06:30,351 INFO: Train Loss:1.843 | Acc:0.0504 | F1:0.1032\n",
      "2022-04-15 10:06:32,135 INFO: val Loss:1.764 | Acc:0.0500 | F1:0.1105\n",
      "2022-04-15 10:06:33,008 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2022-04-15 10:06:42,206 INFO: Epoch:[005/070]\n",
      "2022-04-15 10:06:42,206 INFO: Train Loss:1.812 | Acc:0.0210 | F1:0.0178\n",
      "2022-04-15 10:06:43,977 INFO: val Loss:1.753 | Acc:0.0500 | F1:0.2100\n",
      "2022-04-15 10:06:44,879 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.89it/s]\n",
      "2022-04-15 10:06:55,284 INFO: Epoch:[006/070]\n",
      "2022-04-15 10:06:55,285 INFO: Train Loss:1.845 | Acc:0.0294 | F1:0.0306\n",
      "2022-04-15 10:06:57,062 INFO: val Loss:1.804 | Acc:0.0500 | F1:0.1436\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:07:06,611 INFO: Epoch:[007/070]\n",
      "2022-04-15 10:07:06,612 INFO: Train Loss:1.836 | Acc:0.0378 | F1:0.0361\n",
      "2022-04-15 10:07:08,519 INFO: val Loss:1.746 | Acc:0.0750 | F1:0.1550\n",
      "2022-04-15 10:07:09,374 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2022-04-15 10:07:18,555 INFO: Epoch:[008/070]\n",
      "2022-04-15 10:07:18,556 INFO: Train Loss:1.846 | Acc:0.0168 | F1:0.0165\n",
      "2022-04-15 10:07:20,431 INFO: val Loss:1.734 | Acc:0.0750 | F1:0.1299\n",
      "2022-04-15 10:07:21,294 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 10:07:30,579 INFO: Epoch:[009/070]\n",
      "2022-04-15 10:07:30,580 INFO: Train Loss:1.814 | Acc:0.0714 | F1:0.0542\n",
      "2022-04-15 10:07:32,478 INFO: val Loss:1.694 | Acc:0.1500 | F1:0.2514\n",
      "2022-04-15 10:07:33,342 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:07:42,615 INFO: Epoch:[010/070]\n",
      "2022-04-15 10:07:42,615 INFO: Train Loss:1.807 | Acc:0.1050 | F1:0.0682\n",
      "2022-04-15 10:07:44,420 INFO: val Loss:1.715 | Acc:0.1500 | F1:0.1848\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 10:07:53,791 INFO: Epoch:[011/070]\n",
      "2022-04-15 10:07:53,791 INFO: Train Loss:1.785 | Acc:0.1429 | F1:0.0631\n",
      "2022-04-15 10:07:55,734 INFO: val Loss:1.671 | Acc:0.3000 | F1:0.3003\n",
      "2022-04-15 10:07:56,542 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
      "2022-04-15 10:08:05,740 INFO: Epoch:[012/070]\n",
      "2022-04-15 10:08:05,741 INFO: Train Loss:1.757 | Acc:0.3067 | F1:0.1024\n",
      "2022-04-15 10:08:07,516 INFO: val Loss:1.696 | Acc:0.2250 | F1:0.0852\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 10:08:16,804 INFO: Epoch:[013/070]\n",
      "2022-04-15 10:08:16,805 INFO: Train Loss:1.727 | Acc:0.5336 | F1:0.1700\n",
      "2022-04-15 10:08:18,601 INFO: val Loss:1.614 | Acc:0.7000 | F1:0.3963\n",
      "2022-04-15 10:08:19,455 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "2022-04-15 10:08:28,405 INFO: Epoch:[014/070]\n",
      "2022-04-15 10:08:28,405 INFO: Train Loss:1.701 | Acc:0.6218 | F1:0.1652\n",
      "2022-04-15 10:08:30,385 INFO: val Loss:1.611 | Acc:0.6750 | F1:0.1662\n",
      "2022-04-15 10:08:31,260 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:08:40,524 INFO: Epoch:[015/070]\n",
      "2022-04-15 10:08:40,525 INFO: Train Loss:1.654 | Acc:0.6639 | F1:0.1495\n",
      "2022-04-15 10:08:42,362 INFO: val Loss:1.568 | Acc:0.8750 | F1:0.1867\n",
      "2022-04-15 10:08:43,239 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2022-04-15 10:08:52,411 INFO: Epoch:[016/070]\n",
      "2022-04-15 10:08:52,411 INFO: Train Loss:1.643 | Acc:0.7479 | F1:0.1741\n",
      "2022-04-15 10:08:54,181 INFO: val Loss:1.506 | Acc:0.9000 | F1:0.1895\n",
      "2022-04-15 10:08:55,075 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.89it/s]\n",
      "2022-04-15 10:09:05,460 INFO: Epoch:[017/070]\n",
      "2022-04-15 10:09:05,460 INFO: Train Loss:1.660 | Acc:0.7773 | F1:0.1461\n",
      "2022-04-15 10:09:07,295 INFO: val Loss:1.484 | Acc:0.9000 | F1:0.1895\n",
      "2022-04-15 10:09:08,290 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
      "2022-04-15 10:09:17,511 INFO: Epoch:[018/070]\n",
      "2022-04-15 10:09:17,512 INFO: Train Loss:1.569 | Acc:0.7689 | F1:0.1545\n",
      "2022-04-15 10:09:19,329 INFO: val Loss:1.433 | Acc:0.9000 | F1:0.1895\n",
      "2022-04-15 10:09:20,199 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 10:09:29,562 INFO: Epoch:[019/070]\n",
      "2022-04-15 10:09:29,563 INFO: Train Loss:1.551 | Acc:0.8739 | F1:0.1558\n",
      "2022-04-15 10:09:31,340 INFO: val Loss:1.421 | Acc:0.9000 | F1:0.1895\n",
      "2022-04-15 10:09:32,263 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
      "2022-04-15 10:09:41,383 INFO: Epoch:[020/070]\n",
      "2022-04-15 10:09:41,383 INFO: Train Loss:1.486 | Acc:0.8739 | F1:0.1555\n",
      "2022-04-15 10:09:43,214 INFO: val Loss:1.415 | Acc:0.9000 | F1:0.1895\n",
      "2022-04-15 10:09:44,089 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:09:53,360 INFO: Epoch:[021/070]\n",
      "2022-04-15 10:09:53,360 INFO: Train Loss:1.446 | Acc:0.8908 | F1:0.2237\n",
      "2022-04-15 10:09:55,237 INFO: val Loss:1.409 | Acc:0.9250 | F1:0.3920\n",
      "2022-04-15 10:09:56,113 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:10:05,379 INFO: Epoch:[022/070]\n",
      "2022-04-15 10:10:05,380 INFO: Train Loss:1.446 | Acc:0.8824 | F1:0.1566\n",
      "2022-04-15 10:10:07,179 INFO: val Loss:1.374 | Acc:0.9000 | F1:0.1895\n",
      "2022-04-15 10:10:08,049 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.30it/s]\n",
      "2022-04-15 10:10:17,162 INFO: Epoch:[023/070]\n",
      "2022-04-15 10:10:17,162 INFO: Train Loss:1.370 | Acc:0.8824 | F1:0.1562\n",
      "2022-04-15 10:10:18,989 INFO: val Loss:1.392 | Acc:0.9250 | F1:0.3920\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
      "2022-04-15 10:10:28,189 INFO: Epoch:[024/070]\n",
      "2022-04-15 10:10:28,190 INFO: Train Loss:1.445 | Acc:0.8782 | F1:0.1814\n",
      "2022-04-15 10:10:29,971 INFO: val Loss:1.299 | Acc:0.9250 | F1:0.3920\n",
      "2022-04-15 10:10:30,852 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
      "2022-04-15 10:10:40,108 INFO: Epoch:[025/070]\n",
      "2022-04-15 10:10:40,109 INFO: Train Loss:1.438 | Acc:0.8782 | F1:0.1932\n",
      "2022-04-15 10:10:42,089 INFO: val Loss:1.252 | Acc:0.9000 | F1:0.1895\n",
      "2022-04-15 10:10:42,986 INFO: -----------------SAVE:25epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
      "2022-04-15 10:10:52,231 INFO: Epoch:[026/070]\n",
      "2022-04-15 10:10:52,232 INFO: Train Loss:1.462 | Acc:0.8697 | F1:0.1897\n",
      "2022-04-15 10:10:54,117 INFO: val Loss:1.261 | Acc:0.9000 | F1:0.1895\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:11:03,634 INFO: Epoch:[027/070]\n",
      "2022-04-15 10:11:03,634 INFO: Train Loss:1.353 | Acc:0.8908 | F1:0.2317\n",
      "2022-04-15 10:11:05,500 INFO: val Loss:1.118 | Acc:0.9250 | F1:0.3920\n",
      "2022-04-15 10:11:06,368 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:11:15,625 INFO: Epoch:[028/070]\n",
      "2022-04-15 10:11:15,626 INFO: Train Loss:1.312 | Acc:0.8824 | F1:0.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:11:17,476 INFO: val Loss:1.042 | Acc:0.9500 | F1:0.5946\n",
      "2022-04-15 10:11:18,351 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 10:11:27,912 INFO: Epoch:[029/070]\n",
      "2022-04-15 10:11:27,912 INFO: Train Loss:1.283 | Acc:0.8950 | F1:0.3910\n",
      "2022-04-15 10:11:29,770 INFO: val Loss:0.943 | Acc:0.9250 | F1:0.3920\n",
      "2022-04-15 10:11:30,732 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 10:11:40,031 INFO: Epoch:[030/070]\n",
      "2022-04-15 10:11:40,032 INFO: Train Loss:1.354 | Acc:0.8697 | F1:0.2479\n",
      "2022-04-15 10:11:41,981 INFO: val Loss:0.952 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n",
      "2022-04-15 10:11:51,411 INFO: Epoch:[031/070]\n",
      "2022-04-15 10:11:51,412 INFO: Train Loss:1.322 | Acc:0.8950 | F1:0.3080\n",
      "2022-04-15 10:11:53,235 INFO: val Loss:1.031 | Acc:0.9500 | F1:0.4667\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
      "2022-04-15 10:12:02,403 INFO: Epoch:[032/070]\n",
      "2022-04-15 10:12:02,404 INFO: Train Loss:1.184 | Acc:0.8950 | F1:0.3642\n",
      "2022-04-15 10:12:04,226 INFO: val Loss:0.966 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.12it/s]\n",
      "2022-04-15 10:12:13,850 INFO: Epoch:[033/070]\n",
      "2022-04-15 10:12:13,851 INFO: Train Loss:1.378 | Acc:0.8824 | F1:0.3308\n",
      "2022-04-15 10:12:15,733 INFO: val Loss:0.868 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:12:16,641 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.00it/s]\n",
      "2022-04-15 10:12:26,649 INFO: Epoch:[034/070]\n",
      "2022-04-15 10:12:26,649 INFO: Train Loss:1.258 | Acc:0.8782 | F1:0.2529\n",
      "2022-04-15 10:12:28,535 INFO: val Loss:0.831 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:12:29,433 INFO: -----------------SAVE:34epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 10:12:38,782 INFO: Epoch:[035/070]\n",
      "2022-04-15 10:12:38,783 INFO: Train Loss:1.313 | Acc:0.8950 | F1:0.3942\n",
      "2022-04-15 10:12:40,635 INFO: val Loss:0.779 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:12:41,605 INFO: -----------------SAVE:35epoch----------------\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.99it/s]\n",
      "2022-04-15 10:12:51,653 INFO: Epoch:[036/070]\n",
      "2022-04-15 10:12:51,654 INFO: Train Loss:1.199 | Acc:0.9034 | F1:0.4475\n",
      "2022-04-15 10:12:53,502 INFO: val Loss:0.789 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.19it/s]\n",
      "2022-04-15 10:13:02,919 INFO: Epoch:[037/070]\n",
      "2022-04-15 10:13:02,920 INFO: Train Loss:1.125 | Acc:0.8992 | F1:0.4380\n",
      "2022-04-15 10:13:04,786 INFO: val Loss:0.709 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:13:05,773 INFO: -----------------SAVE:37epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 10:13:15,161 INFO: Epoch:[038/070]\n",
      "2022-04-15 10:13:15,161 INFO: Train Loss:1.234 | Acc:0.9034 | F1:0.3567\n",
      "2022-04-15 10:13:16,997 INFO: val Loss:0.703 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:13:17,850 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:13:27,178 INFO: Epoch:[039/070]\n",
      "2022-04-15 10:13:27,179 INFO: Train Loss:1.023 | Acc:0.9328 | F1:0.6062\n",
      "2022-04-15 10:13:29,188 INFO: val Loss:0.652 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:13:30,082 INFO: -----------------SAVE:39epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 10:13:39,660 INFO: Epoch:[040/070]\n",
      "2022-04-15 10:13:39,660 INFO: Train Loss:0.997 | Acc:0.9286 | F1:0.5587\n",
      "2022-04-15 10:13:41,575 INFO: val Loss:0.634 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:13:42,464 INFO: -----------------SAVE:40epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2022-04-15 10:13:51,654 INFO: Epoch:[041/070]\n",
      "2022-04-15 10:13:51,655 INFO: Train Loss:1.100 | Acc:0.9118 | F1:0.5454\n",
      "2022-04-15 10:13:53,453 INFO: val Loss:0.606 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:13:54,444 INFO: -----------------SAVE:41epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:14:03,724 INFO: Epoch:[042/070]\n",
      "2022-04-15 10:14:03,725 INFO: Train Loss:1.107 | Acc:0.9244 | F1:0.6370\n",
      "2022-04-15 10:14:05,542 INFO: val Loss:0.552 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:14:06,401 INFO: -----------------SAVE:42epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2022-04-15 10:14:15,589 INFO: Epoch:[043/070]\n",
      "2022-04-15 10:14:15,590 INFO: Train Loss:1.221 | Acc:0.9076 | F1:0.4757\n",
      "2022-04-15 10:14:17,399 INFO: val Loss:0.589 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.27it/s]\n",
      "2022-04-15 10:14:26,578 INFO: Epoch:[044/070]\n",
      "2022-04-15 10:14:26,579 INFO: Train Loss:1.188 | Acc:0.8992 | F1:0.4588\n",
      "2022-04-15 10:14:28,505 INFO: val Loss:0.646 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n",
      "2022-04-15 10:14:37,435 INFO: Epoch:[045/070]\n",
      "2022-04-15 10:14:37,436 INFO: Train Loss:1.457 | Acc:0.8866 | F1:0.3278\n",
      "2022-04-15 10:14:39,329 INFO: val Loss:0.565 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.33it/s]\n",
      "2022-04-15 10:14:48,353 INFO: Epoch:[046/070]\n",
      "2022-04-15 10:14:48,354 INFO: Train Loss:0.932 | Acc:0.9454 | F1:0.6685\n",
      "2022-04-15 10:14:50,230 INFO: val Loss:0.570 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
      "2022-04-15 10:14:59,213 INFO: Epoch:[047/070]\n",
      "2022-04-15 10:14:59,213 INFO: Train Loss:0.964 | Acc:0.9412 | F1:0.6049\n",
      "2022-04-15 10:15:01,041 INFO: val Loss:0.535 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:15:01,969 INFO: -----------------SAVE:47epoch----------------\n",
      "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
      "2022-04-15 10:15:10,959 INFO: Epoch:[048/070]\n",
      "2022-04-15 10:15:10,959 INFO: Train Loss:0.930 | Acc:0.9412 | F1:0.6582\n",
      "2022-04-15 10:15:12,858 INFO: val Loss:0.552 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:15:22,189 INFO: Epoch:[049/070]\n",
      "2022-04-15 10:15:22,190 INFO: Train Loss:1.137 | Acc:0.9286 | F1:0.6150\n",
      "2022-04-15 10:15:24,031 INFO: val Loss:0.500 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:15:25,015 INFO: -----------------SAVE:49epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.28it/s]\n",
      "2022-04-15 10:15:34,171 INFO: Epoch:[050/070]\n",
      "2022-04-15 10:15:34,172 INFO: Train Loss:1.081 | Acc:0.9286 | F1:0.5343\n",
      "2022-04-15 10:15:36,006 INFO: val Loss:0.472 | Acc:0.9750 | F1:0.7333\n",
      "2022-04-15 10:15:36,887 INFO: -----------------SAVE:50epoch----------------\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.25it/s]\n",
      "2022-04-15 10:15:46,130 INFO: Epoch:[051/070]\n",
      "2022-04-15 10:15:46,131 INFO: Train Loss:0.871 | Acc:0.9286 | F1:0.6064\n",
      "2022-04-15 10:15:48,041 INFO: val Loss:0.583 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:08<00:00,  3.34it/s]\n",
      "2022-04-15 10:15:57,019 INFO: Epoch:[052/070]\n",
      "2022-04-15 10:15:57,020 INFO: Train Loss:0.968 | Acc:0.9034 | F1:0.3809\n",
      "2022-04-15 10:15:58,842 INFO: val Loss:0.548 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.26it/s]\n",
      "2022-04-15 10:16:08,050 INFO: Epoch:[053/070]\n",
      "2022-04-15 10:16:08,050 INFO: Train Loss:1.246 | Acc:0.9034 | F1:0.4198\n",
      "2022-04-15 10:16:09,846 INFO: val Loss:0.678 | Acc:0.9750 | F1:0.7333\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.10it/s]\n",
      "2022-04-15 10:16:19,532 INFO: Epoch:[054/070]\n",
      "2022-04-15 10:16:19,532 INFO: Train Loss:1.004 | Acc:0.9286 | F1:0.6584\n",
      "2022-04-15 10:16:21,365 INFO: val Loss:0.529 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
      "2022-04-15 10:16:30,449 INFO: Epoch:[055/070]\n",
      "2022-04-15 10:16:30,450 INFO: Train Loss:1.125 | Acc:0.9328 | F1:0.6569\n",
      "2022-04-15 10:16:32,303 INFO: val Loss:0.587 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.31it/s]\n",
      "2022-04-15 10:16:41,378 INFO: Epoch:[056/070]\n",
      "2022-04-15 10:16:41,378 INFO: Train Loss:1.104 | Acc:0.9076 | F1:0.5067\n",
      "2022-04-15 10:16:43,320 INFO: val Loss:0.666 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:16:52,592 INFO: Epoch:[057/070]\n",
      "2022-04-15 10:16:52,592 INFO: Train Loss:1.021 | Acc:0.9118 | F1:0.5260\n",
      "2022-04-15 10:16:54,414 INFO: val Loss:0.595 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:17:03,693 INFO: Epoch:[058/070]\n",
      "2022-04-15 10:17:03,694 INFO: Train Loss:1.069 | Acc:0.9286 | F1:0.6975\n",
      "2022-04-15 10:17:05,526 INFO: val Loss:0.540 | Acc:0.9750 | F1:0.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 10:17:15,044 INFO: Epoch:[059/070]\n",
      "2022-04-15 10:17:15,045 INFO: Train Loss:1.197 | Acc:0.8950 | F1:0.3893\n",
      "2022-04-15 10:17:16,921 INFO: val Loss:0.552 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.23it/s]\n",
      "2022-04-15 10:17:26,218 INFO: Epoch:[060/070]\n",
      "2022-04-15 10:17:26,219 INFO: Train Loss:1.231 | Acc:0.9328 | F1:0.6403\n",
      "2022-04-15 10:17:28,001 INFO: val Loss:0.686 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:17:37,279 INFO: Epoch:[061/070]\n",
      "2022-04-15 10:17:37,280 INFO: Train Loss:0.955 | Acc:0.9076 | F1:0.4059\n",
      "2022-04-15 10:17:39,138 INFO: val Loss:0.563 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:17:48,679 INFO: Epoch:[062/070]\n",
      "2022-04-15 10:17:48,680 INFO: Train Loss:0.811 | Acc:0.9244 | F1:0.6495\n",
      "2022-04-15 10:17:50,470 INFO: val Loss:0.542 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n",
      "2022-04-15 10:17:59,734 INFO: Epoch:[063/070]\n",
      "2022-04-15 10:17:59,735 INFO: Train Loss:0.827 | Acc:0.9538 | F1:0.7645\n",
      "2022-04-15 10:18:01,503 INFO: val Loss:0.529 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:10<00:00,  2.93it/s]\n",
      "2022-04-15 10:18:11,762 INFO: Epoch:[064/070]\n",
      "2022-04-15 10:18:11,762 INFO: Train Loss:0.767 | Acc:0.9328 | F1:0.5977\n",
      "2022-04-15 10:18:13,605 INFO: val Loss:0.509 | Acc:0.9750 | F1:0.7973\n",
      "100%|██████████| 30/30 [00:09<00:00,  3.29it/s]\n",
      "2022-04-15 10:18:22,739 INFO: Epoch:[065/070]\n",
      "2022-04-15 10:18:22,740 INFO: Train Loss:1.045 | Acc:0.9202 | F1:0.5957\n",
      "2022-04-15 10:18:24,588 INFO: val Loss:0.544 | Acc:0.9750 | F1:0.7973\n",
      "2022-04-15 10:18:24,589 INFO: \n",
      "Best Val Epoch:50 | Val Loss:0.4724 | Val Acc:0.9750 | Val F1:0.7333\n",
      "2022-04-15 10:18:24,590 INFO: Total Process time:12.656Minute\n",
      "2022-04-15 10:18:24,615 INFO: {'exp_num': '0', 'class_name': 'bottle', 'class_num': 4, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name   class          state                 label\n",
      "0        4  10004.png  bottle           good           bottle-good\n",
      "1       26  10026.png  bottle           good           bottle-good\n",
      "2       53  10053.png  bottle  contamination  bottle-contamination\n",
      "3       58  10058.png  bottle           good           bottle-good\n",
      "4       60  10060.png  bottle           good           bottle-good\n",
      "..     ...        ...     ...            ...                   ...\n",
      "236   4174  14174.png  bottle           good           bottle-good\n",
      "237   4179  14179.png  bottle           good           bottle-good\n",
      "238   4200  14200.png  bottle           good           bottle-good\n",
      "239   4236  14236.png  bottle           good           bottle-good\n",
      "240   4271  14271.png  bottle           good           bottle-good\n",
      "\n",
      "[241 rows x 5 columns]\n",
      "good             209\n",
      "contamination     11\n",
      "broken_small      11\n",
      "broken_large      10\n",
      "Name: state, dtype: int64\n",
      "4\n",
      "<---- Training Params ---->\n",
      "Dataset size:206\n",
      "Dataset size:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:18:25,086 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.28it/s]\n",
      "2022-04-15 10:18:33,332 INFO: Epoch:[001/070]\n",
      "2022-04-15 10:18:33,332 INFO: Train Loss:1.436 | Acc:0.0437 | F1:0.0399\n",
      "2022-04-15 10:18:34,974 INFO: val Loss:1.422 | Acc:0.0286 | F1:0.0147\n",
      "2022-04-15 10:18:35,886 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.24it/s]\n",
      "2022-04-15 10:18:43,925 INFO: Epoch:[002/070]\n",
      "2022-04-15 10:18:43,926 INFO: Train Loss:1.409 | Acc:0.0583 | F1:0.0544\n",
      "2022-04-15 10:18:45,290 INFO: val Loss:1.442 | Acc:0.0286 | F1:0.0143\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.19it/s]\n",
      "2022-04-15 10:18:53,449 INFO: Epoch:[003/070]\n",
      "2022-04-15 10:18:53,450 INFO: Train Loss:1.443 | Acc:0.0485 | F1:0.0691\n",
      "2022-04-15 10:18:54,938 INFO: val Loss:1.445 | Acc:0.0286 | F1:0.0143\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.17it/s]\n",
      "2022-04-15 10:19:03,143 INFO: Epoch:[004/070]\n",
      "2022-04-15 10:19:03,143 INFO: Train Loss:1.415 | Acc:0.0680 | F1:0.0910\n",
      "2022-04-15 10:19:04,533 INFO: val Loss:1.470 | Acc:0.0286 | F1:0.0143\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 10:19:12,433 INFO: Epoch:[005/070]\n",
      "2022-04-15 10:19:12,433 INFO: Train Loss:1.417 | Acc:0.0485 | F1:0.0561\n",
      "2022-04-15 10:19:13,801 INFO: val Loss:1.440 | Acc:0.0286 | F1:0.0143\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.27it/s]\n",
      "2022-04-15 10:19:21,757 INFO: Epoch:[006/070]\n",
      "2022-04-15 10:19:21,757 INFO: Train Loss:1.421 | Acc:0.0485 | F1:0.0721\n",
      "2022-04-15 10:19:23,202 INFO: val Loss:1.439 | Acc:0.0000 | F1:0.0000\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.28it/s]\n",
      "2022-04-15 10:19:31,126 INFO: Epoch:[007/070]\n",
      "2022-04-15 10:19:31,127 INFO: Train Loss:1.413 | Acc:0.0534 | F1:0.0810\n",
      "2022-04-15 10:19:32,577 INFO: val Loss:1.420 | Acc:0.0286 | F1:0.0143\n",
      "2022-04-15 10:19:33,489 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.00it/s]\n",
      "2022-04-15 10:19:42,173 INFO: Epoch:[008/070]\n",
      "2022-04-15 10:19:42,174 INFO: Train Loss:1.402 | Acc:0.0388 | F1:0.0305\n",
      "2022-04-15 10:19:43,518 INFO: val Loss:1.399 | Acc:0.0286 | F1:0.0139\n",
      "2022-04-15 10:19:44,501 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.23it/s]\n",
      "2022-04-15 10:19:52,564 INFO: Epoch:[009/070]\n",
      "2022-04-15 10:19:52,565 INFO: Train Loss:1.400 | Acc:0.0583 | F1:0.0428\n",
      "2022-04-15 10:19:53,964 INFO: val Loss:1.394 | Acc:0.0286 | F1:0.0139\n",
      "2022-04-15 10:19:54,851 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.25it/s]\n",
      "2022-04-15 10:20:02,861 INFO: Epoch:[010/070]\n",
      "2022-04-15 10:20:02,862 INFO: Train Loss:1.382 | Acc:0.0922 | F1:0.0867\n",
      "2022-04-15 10:20:04,186 INFO: val Loss:1.390 | Acc:0.0286 | F1:0.0139\n",
      "2022-04-15 10:20:05,114 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.23it/s]\n",
      "2022-04-15 10:20:13,181 INFO: Epoch:[011/070]\n",
      "2022-04-15 10:20:13,182 INFO: Train Loss:1.360 | Acc:0.1117 | F1:0.1175\n",
      "2022-04-15 10:20:14,615 INFO: val Loss:1.367 | Acc:0.0286 | F1:0.0139\n",
      "2022-04-15 10:20:15,510 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 10:20:23,432 INFO: Epoch:[012/070]\n",
      "2022-04-15 10:20:23,432 INFO: Train Loss:1.367 | Acc:0.2330 | F1:0.1339\n",
      "2022-04-15 10:20:24,887 INFO: val Loss:1.315 | Acc:0.1714 | F1:0.0876\n",
      "2022-04-15 10:20:25,738 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.16it/s]\n",
      "2022-04-15 10:20:33,963 INFO: Epoch:[013/070]\n",
      "2022-04-15 10:20:33,963 INFO: Train Loss:1.371 | Acc:0.3058 | F1:0.1857\n",
      "2022-04-15 10:20:35,303 INFO: val Loss:1.289 | Acc:0.6571 | F1:0.2473\n",
      "2022-04-15 10:20:36,176 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.21it/s]\n",
      "2022-04-15 10:20:44,272 INFO: Epoch:[014/070]\n",
      "2022-04-15 10:20:44,272 INFO: Train Loss:1.305 | Acc:0.4806 | F1:0.2921\n",
      "2022-04-15 10:20:45,653 INFO: val Loss:1.240 | Acc:0.6000 | F1:0.2313\n",
      "2022-04-15 10:20:46,554 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.15it/s]\n",
      "2022-04-15 10:20:54,808 INFO: Epoch:[015/070]\n",
      "2022-04-15 10:20:54,808 INFO: Train Loss:1.299 | Acc:0.5971 | F1:0.2789\n",
      "2022-04-15 10:20:56,256 INFO: val Loss:1.216 | Acc:0.7714 | F1:0.2821\n",
      "2022-04-15 10:20:57,119 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "2022-04-15 10:21:04,893 INFO: Epoch:[016/070]\n",
      "2022-04-15 10:21:04,893 INFO: Train Loss:1.302 | Acc:0.7330 | F1:0.3211\n",
      "2022-04-15 10:21:06,298 INFO: val Loss:1.179 | Acc:0.8000 | F1:0.2924\n",
      "2022-04-15 10:21:07,226 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  2.99it/s]\n",
      "2022-04-15 10:21:15,922 INFO: Epoch:[017/070]\n",
      "2022-04-15 10:21:15,922 INFO: Train Loss:1.270 | Acc:0.8058 | F1:0.3945\n",
      "2022-04-15 10:21:17,308 INFO: val Loss:1.213 | Acc:0.6857 | F1:0.2554\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 10:21:25,224 INFO: Epoch:[018/070]\n",
      "2022-04-15 10:21:25,225 INFO: Train Loss:1.264 | Acc:0.7864 | F1:0.3740\n",
      "2022-04-15 10:21:26,698 INFO: val Loss:1.039 | Acc:0.8571 | F1:0.3172\n",
      "2022-04-15 10:21:27,603 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.22it/s]\n",
      "2022-04-15 10:21:35,686 INFO: Epoch:[019/070]\n",
      "2022-04-15 10:21:35,687 INFO: Train Loss:1.286 | Acc:0.8447 | F1:0.4429\n",
      "2022-04-15 10:21:37,129 INFO: val Loss:0.988 | Acc:0.9143 | F1:0.5167\n",
      "2022-04-15 10:21:38,032 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.25it/s]\n",
      "2022-04-15 10:21:46,032 INFO: Epoch:[020/070]\n",
      "2022-04-15 10:21:46,037 INFO: Train Loss:1.202 | Acc:0.7913 | F1:0.3456\n",
      "2022-04-15 10:21:47,485 INFO: val Loss:1.043 | Acc:0.8571 | F1:0.4795\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.32it/s]\n",
      "2022-04-15 10:21:55,324 INFO: Epoch:[021/070]\n",
      "2022-04-15 10:21:55,324 INFO: Train Loss:1.190 | Acc:0.8495 | F1:0.3426\n",
      "2022-04-15 10:21:56,717 INFO: val Loss:1.036 | Acc:0.7714 | F1:0.2821\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.27it/s]\n",
      "2022-04-15 10:22:04,683 INFO: Epoch:[022/070]\n",
      "2022-04-15 10:22:04,684 INFO: Train Loss:1.194 | Acc:0.8398 | F1:0.3525\n",
      "2022-04-15 10:22:06,147 INFO: val Loss:0.911 | Acc:0.8857 | F1:0.4958\n",
      "2022-04-15 10:22:07,010 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n",
      "2022-04-15 10:22:14,731 INFO: Epoch:[023/070]\n",
      "2022-04-15 10:22:14,731 INFO: Train Loss:1.111 | Acc:0.8689 | F1:0.4158\n",
      "2022-04-15 10:22:16,068 INFO: val Loss:0.836 | Acc:0.8857 | F1:0.4958\n",
      "2022-04-15 10:22:16,961 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.22it/s]\n",
      "2022-04-15 10:22:25,033 INFO: Epoch:[024/070]\n",
      "2022-04-15 10:22:25,034 INFO: Train Loss:1.176 | Acc:0.8350 | F1:0.3627\n",
      "2022-04-15 10:22:26,424 INFO: val Loss:0.796 | Acc:0.9143 | F1:0.5376\n",
      "2022-04-15 10:22:27,324 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.21it/s]\n",
      "2022-04-15 10:22:35,428 INFO: Epoch:[025/070]\n",
      "2022-04-15 10:22:35,429 INFO: Train Loss:1.070 | Acc:0.8786 | F1:0.5073\n",
      "2022-04-15 10:22:36,815 INFO: val Loss:0.828 | Acc:0.8286 | F1:0.4411\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.28it/s]\n",
      "2022-04-15 10:22:44,761 INFO: Epoch:[026/070]\n",
      "2022-04-15 10:22:44,761 INFO: Train Loss:1.081 | Acc:0.8495 | F1:0.3619\n",
      "2022-04-15 10:22:46,180 INFO: val Loss:0.640 | Acc:0.9429 | F1:0.7459\n",
      "2022-04-15 10:22:47,054 INFO: -----------------SAVE:26epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.11it/s]\n",
      "2022-04-15 10:22:55,411 INFO: Epoch:[027/070]\n",
      "2022-04-15 10:22:55,412 INFO: Train Loss:0.985 | Acc:0.8592 | F1:0.5293\n",
      "2022-04-15 10:22:56,787 INFO: val Loss:0.669 | Acc:0.8286 | F1:0.4411\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.23it/s]\n",
      "2022-04-15 10:23:04,855 INFO: Epoch:[028/070]\n",
      "2022-04-15 10:23:04,855 INFO: Train Loss:1.085 | Acc:0.8447 | F1:0.4139\n",
      "2022-04-15 10:23:06,305 INFO: val Loss:0.588 | Acc:0.8857 | F1:0.4917\n",
      "2022-04-15 10:23:07,187 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.26it/s]\n",
      "2022-04-15 10:23:15,173 INFO: Epoch:[029/070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:23:15,174 INFO: Train Loss:0.976 | Acc:0.8738 | F1:0.5032\n",
      "2022-04-15 10:23:16,502 INFO: val Loss:0.629 | Acc:0.8571 | F1:0.4623\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.24it/s]\n",
      "2022-04-15 10:23:24,531 INFO: Epoch:[030/070]\n",
      "2022-04-15 10:23:24,531 INFO: Train Loss:0.966 | Acc:0.8835 | F1:0.5087\n",
      "2022-04-15 10:23:25,955 INFO: val Loss:0.591 | Acc:0.9143 | F1:0.5708\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "2022-04-15 10:23:33,733 INFO: Epoch:[031/070]\n",
      "2022-04-15 10:23:33,733 INFO: Train Loss:0.971 | Acc:0.8641 | F1:0.4447\n",
      "2022-04-15 10:23:35,082 INFO: val Loss:0.529 | Acc:0.9429 | F1:0.7459\n",
      "2022-04-15 10:23:36,020 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.34it/s]\n",
      "2022-04-15 10:23:43,805 INFO: Epoch:[032/070]\n",
      "2022-04-15 10:23:43,806 INFO: Train Loss:0.927 | Acc:0.8883 | F1:0.5755\n",
      "2022-04-15 10:23:45,243 INFO: val Loss:0.539 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 10:23:53,161 INFO: Epoch:[033/070]\n",
      "2022-04-15 10:23:53,162 INFO: Train Loss:0.996 | Acc:0.8350 | F1:0.5216\n",
      "2022-04-15 10:23:54,553 INFO: val Loss:0.562 | Acc:0.9429 | F1:0.8583\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.25it/s]\n",
      "2022-04-15 10:24:02,552 INFO: Epoch:[034/070]\n",
      "2022-04-15 10:24:02,552 INFO: Train Loss:0.972 | Acc:0.8981 | F1:0.6475\n",
      "2022-04-15 10:24:03,904 INFO: val Loss:0.623 | Acc:0.8571 | F1:0.6244\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.25it/s]\n",
      "2022-04-15 10:24:11,910 INFO: Epoch:[035/070]\n",
      "2022-04-15 10:24:11,911 INFO: Train Loss:1.000 | Acc:0.8689 | F1:0.5540\n",
      "2022-04-15 10:24:13,379 INFO: val Loss:0.600 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.42it/s]\n",
      "2022-04-15 10:24:20,999 INFO: Epoch:[036/070]\n",
      "2022-04-15 10:24:21,000 INFO: Train Loss:1.052 | Acc:0.8544 | F1:0.5408\n",
      "2022-04-15 10:24:22,370 INFO: val Loss:0.636 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 10:24:30,286 INFO: Epoch:[037/070]\n",
      "2022-04-15 10:24:30,287 INFO: Train Loss:0.824 | Acc:0.9175 | F1:0.7194\n",
      "2022-04-15 10:24:31,759 INFO: val Loss:0.649 | Acc:0.8571 | F1:0.6494\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.26it/s]\n",
      "2022-04-15 10:24:39,748 INFO: Epoch:[038/070]\n",
      "2022-04-15 10:24:39,751 INFO: Train Loss:0.900 | Acc:0.8835 | F1:0.6433\n",
      "2022-04-15 10:24:41,099 INFO: val Loss:0.587 | Acc:0.8286 | F1:0.6328\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.00it/s]\n",
      "2022-04-15 10:24:49,770 INFO: Epoch:[039/070]\n",
      "2022-04-15 10:24:49,770 INFO: Train Loss:0.772 | Acc:0.8932 | F1:0.6589\n",
      "2022-04-15 10:24:51,111 INFO: val Loss:0.560 | Acc:0.8857 | F1:0.6706\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.31it/s]\n",
      "2022-04-15 10:24:58,971 INFO: Epoch:[040/070]\n",
      "2022-04-15 10:24:58,971 INFO: Train Loss:0.888 | Acc:0.9078 | F1:0.6761\n",
      "2022-04-15 10:25:00,428 INFO: val Loss:0.510 | Acc:0.9429 | F1:0.7459\n",
      "2022-04-15 10:25:01,302 INFO: -----------------SAVE:40epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.25it/s]\n",
      "2022-04-15 10:25:09,321 INFO: Epoch:[041/070]\n",
      "2022-04-15 10:25:09,321 INFO: Train Loss:0.896 | Acc:0.9126 | F1:0.6874\n",
      "2022-04-15 10:25:10,671 INFO: val Loss:0.523 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.18it/s]\n",
      "2022-04-15 10:25:18,855 INFO: Epoch:[042/070]\n",
      "2022-04-15 10:25:18,855 INFO: Train Loss:0.939 | Acc:0.9175 | F1:0.7112\n",
      "2022-04-15 10:25:20,357 INFO: val Loss:0.545 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.24it/s]\n",
      "2022-04-15 10:25:28,392 INFO: Epoch:[043/070]\n",
      "2022-04-15 10:25:28,392 INFO: Train Loss:0.913 | Acc:0.8883 | F1:0.6315\n",
      "2022-04-15 10:25:29,786 INFO: val Loss:0.588 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  2.96it/s]\n",
      "2022-04-15 10:25:38,593 INFO: Epoch:[044/070]\n",
      "2022-04-15 10:25:38,593 INFO: Train Loss:1.029 | Acc:0.8883 | F1:0.5954\n",
      "2022-04-15 10:25:39,957 INFO: val Loss:1.595 | Acc:0.1714 | F1:0.3958\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.31it/s]\n",
      "2022-04-15 10:25:47,814 INFO: Epoch:[045/070]\n",
      "2022-04-15 10:25:47,815 INFO: Train Loss:0.906 | Acc:0.9175 | F1:0.7204\n",
      "2022-04-15 10:25:49,271 INFO: val Loss:0.693 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.32it/s]\n",
      "2022-04-15 10:25:57,107 INFO: Epoch:[046/070]\n",
      "2022-04-15 10:25:57,107 INFO: Train Loss:0.718 | Acc:0.9175 | F1:0.7313\n",
      "2022-04-15 10:25:58,460 INFO: val Loss:0.659 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "2022-04-15 10:26:06,222 INFO: Epoch:[047/070]\n",
      "2022-04-15 10:26:06,222 INFO: Train Loss:0.763 | Acc:0.9417 | F1:0.8024\n",
      "2022-04-15 10:26:07,660 INFO: val Loss:0.545 | Acc:0.9714 | F1:0.9126\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.23it/s]\n",
      "2022-04-15 10:26:15,708 INFO: Epoch:[048/070]\n",
      "2022-04-15 10:26:15,709 INFO: Train Loss:0.900 | Acc:0.9272 | F1:0.7621\n",
      "2022-04-15 10:26:17,051 INFO: val Loss:0.515 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.27it/s]\n",
      "2022-04-15 10:26:25,006 INFO: Epoch:[049/070]\n",
      "2022-04-15 10:26:25,007 INFO: Train Loss:0.880 | Acc:0.8835 | F1:0.5472\n",
      "2022-04-15 10:26:26,373 INFO: val Loss:0.528 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.05it/s]\n",
      "2022-04-15 10:26:34,902 INFO: Epoch:[050/070]\n",
      "2022-04-15 10:26:34,903 INFO: Train Loss:1.100 | Acc:0.9029 | F1:0.6422\n",
      "2022-04-15 10:26:36,333 INFO: val Loss:0.472 | Acc:0.9714 | F1:0.9126\n",
      "2022-04-15 10:26:37,163 INFO: -----------------SAVE:50epoch----------------\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n",
      "2022-04-15 10:26:44,795 INFO: Epoch:[051/070]\n",
      "2022-04-15 10:26:44,795 INFO: Train Loss:0.903 | Acc:0.8932 | F1:0.6435\n",
      "2022-04-15 10:26:46,108 INFO: val Loss:0.578 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.28it/s]\n",
      "2022-04-15 10:26:54,034 INFO: Epoch:[052/070]\n",
      "2022-04-15 10:26:54,034 INFO: Train Loss:0.873 | Acc:0.9272 | F1:0.6963\n",
      "2022-04-15 10:26:55,486 INFO: val Loss:0.562 | Acc:0.9143 | F1:0.5753\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.37it/s]\n",
      "2022-04-15 10:27:03,211 INFO: Epoch:[053/070]\n",
      "2022-04-15 10:27:03,212 INFO: Train Loss:0.813 | Acc:0.9126 | F1:0.6943\n",
      "2022-04-15 10:27:04,550 INFO: val Loss:0.491 | Acc:0.9714 | F1:0.9126\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.28it/s]\n",
      "2022-04-15 10:27:12,496 INFO: Epoch:[054/070]\n",
      "2022-04-15 10:27:12,497 INFO: Train Loss:0.830 | Acc:0.9126 | F1:0.7134\n",
      "2022-04-15 10:27:13,958 INFO: val Loss:0.547 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.30it/s]\n",
      "2022-04-15 10:27:21,844 INFO: Epoch:[055/070]\n",
      "2022-04-15 10:27:21,844 INFO: Train Loss:0.702 | Acc:0.9417 | F1:0.8071\n",
      "2022-04-15 10:27:23,273 INFO: val Loss:0.688 | Acc:0.9143 | F1:0.7000\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 10:27:31,179 INFO: Epoch:[056/070]\n",
      "2022-04-15 10:27:31,180 INFO: Train Loss:0.901 | Acc:0.9175 | F1:0.7329\n",
      "2022-04-15 10:27:32,587 INFO: val Loss:0.501 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.13it/s]\n",
      "2022-04-15 10:27:40,905 INFO: Epoch:[057/070]\n",
      "2022-04-15 10:27:40,906 INFO: Train Loss:0.780 | Acc:0.9417 | F1:0.7939\n",
      "2022-04-15 10:27:42,367 INFO: val Loss:0.506 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.33it/s]\n",
      "2022-04-15 10:27:50,180 INFO: Epoch:[058/070]\n",
      "2022-04-15 10:27:50,180 INFO: Train Loss:0.995 | Acc:0.8981 | F1:0.6195\n",
      "2022-04-15 10:27:51,515 INFO: val Loss:0.578 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  2.99it/s]\n",
      "2022-04-15 10:28:00,231 INFO: Epoch:[059/070]\n",
      "2022-04-15 10:28:00,232 INFO: Train Loss:1.029 | Acc:0.9078 | F1:0.6890\n",
      "2022-04-15 10:28:01,575 INFO: val Loss:0.669 | Acc:0.9143 | F1:0.7000\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.19it/s]\n",
      "2022-04-15 10:28:09,732 INFO: Epoch:[060/070]\n",
      "2022-04-15 10:28:09,733 INFO: Train Loss:0.766 | Acc:0.9223 | F1:0.7659\n",
      "2022-04-15 10:28:11,149 INFO: val Loss:0.678 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.35it/s]\n",
      "2022-04-15 10:28:18,926 INFO: Epoch:[061/070]\n",
      "2022-04-15 10:28:18,927 INFO: Train Loss:0.932 | Acc:0.9126 | F1:0.6758\n",
      "2022-04-15 10:28:20,305 INFO: val Loss:0.587 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n",
      "2022-04-15 10:28:28,006 INFO: Epoch:[062/070]\n",
      "2022-04-15 10:28:28,006 INFO: Train Loss:0.679 | Acc:0.8883 | F1:0.6707\n",
      "2022-04-15 10:28:29,466 INFO: val Loss:0.607 | Acc:0.9429 | F1:0.7459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:07<00:00,  3.28it/s]\n",
      "2022-04-15 10:28:37,404 INFO: Epoch:[063/070]\n",
      "2022-04-15 10:28:37,404 INFO: Train Loss:0.586 | Acc:0.9466 | F1:0.8390\n",
      "2022-04-15 10:28:38,736 INFO: val Loss:0.514 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.20it/s]\n",
      "2022-04-15 10:28:46,864 INFO: Epoch:[064/070]\n",
      "2022-04-15 10:28:46,865 INFO: Train Loss:0.620 | Acc:0.9126 | F1:0.7001\n",
      "2022-04-15 10:28:48,202 INFO: val Loss:0.263 | Acc:0.9714 | F1:0.8333\n",
      "2022-04-15 10:28:49,063 INFO: -----------------SAVE:64epoch----------------\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.24it/s]\n",
      "2022-04-15 10:28:57,104 INFO: Epoch:[065/070]\n",
      "2022-04-15 10:28:57,105 INFO: Train Loss:0.745 | Acc:0.9126 | F1:0.7031\n",
      "2022-04-15 10:28:58,578 INFO: val Loss:0.543 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.26it/s]\n",
      "2022-04-15 10:29:06,574 INFO: Epoch:[066/070]\n",
      "2022-04-15 10:29:06,574 INFO: Train Loss:0.794 | Acc:0.9126 | F1:0.7042\n",
      "2022-04-15 10:29:07,909 INFO: val Loss:0.568 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.43it/s]\n",
      "2022-04-15 10:29:15,496 INFO: Epoch:[067/070]\n",
      "2022-04-15 10:29:15,497 INFO: Train Loss:0.600 | Acc:0.9175 | F1:0.7518\n",
      "2022-04-15 10:29:16,927 INFO: val Loss:0.505 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.29it/s]\n",
      "2022-04-15 10:29:24,845 INFO: Epoch:[068/070]\n",
      "2022-04-15 10:29:24,846 INFO: Train Loss:0.773 | Acc:0.9126 | F1:0.6896\n",
      "2022-04-15 10:29:26,150 INFO: val Loss:0.545 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:08<00:00,  3.22it/s]\n",
      "2022-04-15 10:29:34,227 INFO: Epoch:[069/070]\n",
      "2022-04-15 10:29:34,228 INFO: Train Loss:0.837 | Acc:0.9320 | F1:0.7843\n",
      "2022-04-15 10:29:35,548 INFO: val Loss:0.722 | Acc:0.9429 | F1:0.7459\n",
      "100%|██████████| 26/26 [00:07<00:00,  3.36it/s]\n",
      "2022-04-15 10:29:43,299 INFO: Epoch:[070/070]\n",
      "2022-04-15 10:29:43,300 INFO: Train Loss:0.771 | Acc:0.8932 | F1:0.6346\n",
      "2022-04-15 10:29:44,871 INFO: val Loss:0.571 | Acc:0.9429 | F1:0.7459\n",
      "2022-04-15 10:29:44,872 INFO: \n",
      "Best Val Epoch:64 | Val Loss:0.2629 | Val Acc:0.9714 | Val F1:0.8333\n",
      "2022-04-15 10:29:44,873 INFO: Total Process time:11.325Minute\n",
      "2022-04-15 10:29:44,904 INFO: {'exp_num': '0', 'class_name': 'screw', 'class_num': 6, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name  class              state                    label\n",
      "0        7  10007.png  screw               good               screw-good\n",
      "1       19  10019.png  screw        thread_side        screw-thread_side\n",
      "2       35  10035.png  screw  manipulated_front  screw-manipulated_front\n",
      "3       44  10044.png  screw               good               screw-good\n",
      "4       46  10046.png  screw               good               screw-good\n",
      "..     ...        ...    ...                ...                      ...\n",
      "376   4223  14223.png  screw               good               screw-good\n",
      "377   4234  14234.png  screw               good               screw-good\n",
      "378   4246  14246.png  screw               good               screw-good\n",
      "379   4253  14253.png  screw               good               screw-good\n",
      "380   4276  14276.png  screw               good               screw-good\n",
      "\n",
      "[381 rows x 5 columns]\n",
      "good                 320\n",
      "scratch_neck          13\n",
      "thread_top            12\n",
      "thread_side           12\n",
      "scratch_head          12\n",
      "manipulated_front     12\n",
      "Name: state, dtype: int64\n",
      "6\n",
      "<---- Training Params ---->\n",
      "Dataset size:326\n",
      "Dataset size:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:29:45,333 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.52it/s]\n",
      "2022-04-15 10:29:57,286 INFO: Epoch:[001/070]\n",
      "2022-04-15 10:29:57,286 INFO: Train Loss:1.829 | Acc:0.0613 | F1:0.0378\n",
      "2022-04-15 10:29:59,146 INFO: val Loss:1.832 | Acc:0.0364 | F1:0.0370\n",
      "2022-04-15 10:30:00,006 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.44it/s]\n",
      "2022-04-15 10:30:11,921 INFO: Epoch:[002/070]\n",
      "2022-04-15 10:30:11,921 INFO: Train Loss:1.818 | Acc:0.0491 | F1:0.0330\n",
      "2022-04-15 10:30:13,462 INFO: val Loss:1.825 | Acc:0.0545 | F1:0.0810\n",
      "2022-04-15 10:30:14,373 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.29it/s]\n",
      "2022-04-15 10:30:26,852 INFO: Epoch:[003/070]\n",
      "2022-04-15 10:30:26,852 INFO: Train Loss:1.827 | Acc:0.0583 | F1:0.0457\n",
      "2022-04-15 10:30:28,299 INFO: val Loss:1.836 | Acc:0.0364 | F1:0.0730\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.51it/s]\n",
      "2022-04-15 10:30:39,986 INFO: Epoch:[004/070]\n",
      "2022-04-15 10:30:39,987 INFO: Train Loss:1.802 | Acc:0.0583 | F1:0.0329\n",
      "2022-04-15 10:30:41,645 INFO: val Loss:1.860 | Acc:0.0364 | F1:0.0895\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:30:53,590 INFO: Epoch:[005/070]\n",
      "2022-04-15 10:30:53,591 INFO: Train Loss:1.786 | Acc:0.0583 | F1:0.0396\n",
      "2022-04-15 10:30:55,141 INFO: val Loss:1.830 | Acc:0.0545 | F1:0.1018\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.44it/s]\n",
      "2022-04-15 10:31:07,086 INFO: Epoch:[006/070]\n",
      "2022-04-15 10:31:07,086 INFO: Train Loss:1.807 | Acc:0.0828 | F1:0.0527\n",
      "2022-04-15 10:31:08,794 INFO: val Loss:1.823 | Acc:0.0545 | F1:0.0628\n",
      "2022-04-15 10:31:09,711 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.48it/s]\n",
      "2022-04-15 10:31:21,499 INFO: Epoch:[007/070]\n",
      "2022-04-15 10:31:21,500 INFO: Train Loss:1.799 | Acc:0.1135 | F1:0.0630\n",
      "2022-04-15 10:31:23,227 INFO: val Loss:1.835 | Acc:0.0545 | F1:0.0677\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.42it/s]\n",
      "2022-04-15 10:31:35,224 INFO: Epoch:[008/070]\n",
      "2022-04-15 10:31:35,225 INFO: Train Loss:1.787 | Acc:0.0951 | F1:0.0572\n",
      "2022-04-15 10:31:36,809 INFO: val Loss:1.827 | Acc:0.0364 | F1:0.0403\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:31:48,898 INFO: Epoch:[009/070]\n",
      "2022-04-15 10:31:48,899 INFO: Train Loss:1.775 | Acc:0.0890 | F1:0.0505\n",
      "2022-04-15 10:31:50,474 INFO: val Loss:1.836 | Acc:0.0364 | F1:0.0374\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:32:02,567 INFO: Epoch:[010/070]\n",
      "2022-04-15 10:32:02,568 INFO: Train Loss:1.781 | Acc:0.1288 | F1:0.0568\n",
      "2022-04-15 10:32:04,306 INFO: val Loss:1.832 | Acc:0.0545 | F1:0.0809\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.49it/s]\n",
      "2022-04-15 10:32:16,060 INFO: Epoch:[011/070]\n",
      "2022-04-15 10:32:16,061 INFO: Train Loss:1.755 | Acc:0.3006 | F1:0.1114\n",
      "2022-04-15 10:32:17,658 INFO: val Loss:1.818 | Acc:0.0545 | F1:0.0587\n",
      "2022-04-15 10:32:18,505 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.52it/s]\n",
      "2022-04-15 10:32:30,166 INFO: Epoch:[012/070]\n",
      "2022-04-15 10:32:30,167 INFO: Train Loss:1.766 | Acc:0.3650 | F1:0.1196\n",
      "2022-04-15 10:32:31,836 INFO: val Loss:1.857 | Acc:0.0545 | F1:0.0967\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.40it/s]\n",
      "2022-04-15 10:32:43,904 INFO: Epoch:[013/070]\n",
      "2022-04-15 10:32:43,905 INFO: Train Loss:1.773 | Acc:0.5859 | F1:0.1422\n",
      "2022-04-15 10:32:45,570 INFO: val Loss:1.807 | Acc:0.3455 | F1:0.1217\n",
      "2022-04-15 10:32:46,408 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:32:58,387 INFO: Epoch:[014/070]\n",
      "2022-04-15 10:32:58,387 INFO: Train Loss:1.753 | Acc:0.7209 | F1:0.1414\n",
      "2022-04-15 10:33:00,085 INFO: val Loss:1.861 | Acc:0.2182 | F1:0.0690\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:33:12,052 INFO: Epoch:[015/070]\n",
      "2022-04-15 10:33:12,053 INFO: Train Loss:1.721 | Acc:0.7975 | F1:0.1612\n",
      "2022-04-15 10:33:13,650 INFO: val Loss:1.878 | Acc:0.6364 | F1:0.1534\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:33:25,742 INFO: Epoch:[016/070]\n",
      "2022-04-15 10:33:25,742 INFO: Train Loss:1.710 | Acc:0.8344 | F1:0.1516\n",
      "2022-04-15 10:33:27,413 INFO: val Loss:1.911 | Acc:0.7091 | F1:0.1413\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.41it/s]\n",
      "2022-04-15 10:33:39,451 INFO: Epoch:[017/070]\n",
      "2022-04-15 10:33:39,451 INFO: Train Loss:1.688 | Acc:0.8129 | F1:0.1495\n",
      "2022-04-15 10:33:41,105 INFO: val Loss:1.921 | Acc:0.8364 | F1:0.1518\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.42it/s]\n",
      "2022-04-15 10:33:53,115 INFO: Epoch:[018/070]\n",
      "2022-04-15 10:33:53,115 INFO: Train Loss:1.710 | Acc:0.8313 | F1:0.1518\n",
      "2022-04-15 10:33:54,810 INFO: val Loss:1.995 | Acc:0.3455 | F1:0.0931\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.40it/s]\n",
      "2022-04-15 10:34:06,889 INFO: Epoch:[019/070]\n",
      "2022-04-15 10:34:06,890 INFO: Train Loss:1.687 | Acc:0.7975 | F1:0.1598\n",
      "2022-04-15 10:34:08,534 INFO: val Loss:2.021 | Acc:0.1273 | F1:0.0451\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:34:20,512 INFO: Epoch:[020/070]\n",
      "2022-04-15 10:34:20,512 INFO: Train Loss:1.743 | Acc:0.8098 | F1:0.1742\n",
      "2022-04-15 10:34:22,053 INFO: val Loss:1.895 | Acc:0.5636 | F1:0.1260\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.48it/s]\n",
      "2022-04-15 10:34:33,835 INFO: Epoch:[021/070]\n",
      "2022-04-15 10:34:33,835 INFO: Train Loss:1.707 | Acc:0.8282 | F1:0.1510\n",
      "2022-04-15 10:34:35,511 INFO: val Loss:1.922 | Acc:0.5636 | F1:0.1260\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.46it/s]\n",
      "2022-04-15 10:34:47,373 INFO: Epoch:[022/070]\n",
      "2022-04-15 10:34:47,374 INFO: Train Loss:1.706 | Acc:0.8374 | F1:0.1522\n",
      "2022-04-15 10:34:49,031 INFO: val Loss:1.897 | Acc:0.7818 | F1:0.1463\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.46it/s]\n",
      "2022-04-15 10:35:00,873 INFO: Epoch:[023/070]\n",
      "2022-04-15 10:35:00,874 INFO: Train Loss:1.703 | Acc:0.8252 | F1:0.1510\n",
      "2022-04-15 10:35:02,462 INFO: val Loss:1.790 | Acc:0.8364 | F1:0.2626\n",
      "2022-04-15 10:35:03,331 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:35:15,443 INFO: Epoch:[024/070]\n",
      "2022-04-15 10:35:15,444 INFO: Train Loss:1.696 | Acc:0.8067 | F1:0.1491\n",
      "2022-04-15 10:35:17,110 INFO: val Loss:1.843 | Acc:0.7636 | F1:0.1458\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.42it/s]\n",
      "2022-04-15 10:35:29,124 INFO: Epoch:[025/070]\n",
      "2022-04-15 10:35:29,125 INFO: Train Loss:1.688 | Acc:0.8252 | F1:0.1948\n",
      "2022-04-15 10:35:30,669 INFO: val Loss:1.902 | Acc:0.7091 | F1:0.1444\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.46it/s]\n",
      "2022-04-15 10:35:42,510 INFO: Epoch:[026/070]\n",
      "2022-04-15 10:35:42,510 INFO: Train Loss:1.708 | Acc:0.8282 | F1:0.1523\n",
      "2022-04-15 10:35:44,073 INFO: val Loss:1.917 | Acc:0.5273 | F1:0.1208\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:35:56,044 INFO: Epoch:[027/070]\n",
      "2022-04-15 10:35:56,044 INFO: Train Loss:1.653 | Acc:0.8098 | F1:0.2054\n",
      "2022-04-15 10:35:57,603 INFO: val Loss:1.843 | Acc:0.7273 | F1:0.2360\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.38it/s]\n",
      "2022-04-15 10:36:09,731 INFO: Epoch:[028/070]\n",
      "2022-04-15 10:36:09,732 INFO: Train Loss:1.669 | Acc:0.8006 | F1:0.1487\n",
      "2022-04-15 10:36:11,363 INFO: val Loss:1.830 | Acc:0.8182 | F1:0.2842\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.49it/s]\n",
      "2022-04-15 10:36:23,110 INFO: Epoch:[029/070]\n",
      "2022-04-15 10:36:23,111 INFO: Train Loss:1.680 | Acc:0.8067 | F1:0.1953\n",
      "2022-04-15 10:36:24,652 INFO: val Loss:1.734 | Acc:0.6000 | F1:0.1658\n",
      "2022-04-15 10:36:25,577 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.52it/s]\n",
      "2022-04-15 10:36:37,234 INFO: Epoch:[030/070]\n",
      "2022-04-15 10:36:37,235 INFO: Train Loss:1.629 | Acc:0.7791 | F1:0.1853\n",
      "2022-04-15 10:36:38,769 INFO: val Loss:1.663 | Acc:0.7273 | F1:0.1899\n",
      "2022-04-15 10:36:39,956 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.44it/s]\n",
      "2022-04-15 10:36:51,900 INFO: Epoch:[031/070]\n",
      "2022-04-15 10:36:51,901 INFO: Train Loss:1.718 | Acc:0.8006 | F1:0.1938\n",
      "2022-04-15 10:36:53,600 INFO: val Loss:1.609 | Acc:0.8182 | F1:0.2342\n",
      "2022-04-15 10:36:54,426 INFO: -----------------SAVE:31epoch----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:12<00:00,  3.37it/s]\n",
      "2022-04-15 10:37:06,595 INFO: Epoch:[032/070]\n",
      "2022-04-15 10:37:06,595 INFO: Train Loss:1.661 | Acc:0.7975 | F1:0.2139\n",
      "2022-04-15 10:37:08,181 INFO: val Loss:1.619 | Acc:0.8182 | F1:0.2604\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.35it/s]\n",
      "2022-04-15 10:37:20,446 INFO: Epoch:[033/070]\n",
      "2022-04-15 10:37:20,446 INFO: Train Loss:1.681 | Acc:0.7822 | F1:0.2162\n",
      "2022-04-15 10:37:22,009 INFO: val Loss:1.604 | Acc:0.8545 | F1:0.4163\n",
      "2022-04-15 10:37:22,957 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.46it/s]\n",
      "2022-04-15 10:37:34,804 INFO: Epoch:[034/070]\n",
      "2022-04-15 10:37:34,805 INFO: Train Loss:1.585 | Acc:0.7669 | F1:0.2457\n",
      "2022-04-15 10:37:36,369 INFO: val Loss:1.596 | Acc:0.8545 | F1:0.2880\n",
      "2022-04-15 10:37:37,211 INFO: -----------------SAVE:34epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.48it/s]\n",
      "2022-04-15 10:37:49,007 INFO: Epoch:[035/070]\n",
      "2022-04-15 10:37:49,007 INFO: Train Loss:1.605 | Acc:0.7975 | F1:0.2194\n",
      "2022-04-15 10:37:50,557 INFO: val Loss:1.602 | Acc:0.6545 | F1:0.1752\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.44it/s]\n",
      "2022-04-15 10:38:02,484 INFO: Epoch:[036/070]\n",
      "2022-04-15 10:38:02,485 INFO: Train Loss:1.566 | Acc:0.7607 | F1:0.2065\n",
      "2022-04-15 10:38:04,052 INFO: val Loss:1.538 | Acc:0.7636 | F1:0.2055\n",
      "2022-04-15 10:38:04,961 INFO: -----------------SAVE:36epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.48it/s]\n",
      "2022-04-15 10:38:16,756 INFO: Epoch:[037/070]\n",
      "2022-04-15 10:38:16,757 INFO: Train Loss:1.574 | Acc:0.7822 | F1:0.2451\n",
      "2022-04-15 10:38:18,367 INFO: val Loss:1.571 | Acc:0.8182 | F1:0.2358\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.46it/s]\n",
      "2022-04-15 10:38:30,238 INFO: Epoch:[038/070]\n",
      "2022-04-15 10:38:30,238 INFO: Train Loss:1.553 | Acc:0.8006 | F1:0.2617\n",
      "2022-04-15 10:38:31,897 INFO: val Loss:1.498 | Acc:0.8364 | F1:0.2377\n",
      "2022-04-15 10:38:32,718 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.47it/s]\n",
      "2022-04-15 10:38:44,549 INFO: Epoch:[039/070]\n",
      "2022-04-15 10:38:44,550 INFO: Train Loss:1.627 | Acc:0.8098 | F1:0.2769\n",
      "2022-04-15 10:38:46,223 INFO: val Loss:1.424 | Acc:0.8364 | F1:0.3327\n",
      "2022-04-15 10:38:47,079 INFO: -----------------SAVE:39epoch----------------\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.30it/s]\n",
      "2022-04-15 10:38:59,521 INFO: Epoch:[040/070]\n",
      "2022-04-15 10:38:59,521 INFO: Train Loss:1.467 | Acc:0.7853 | F1:0.2674\n",
      "2022-04-15 10:39:01,133 INFO: val Loss:1.531 | Acc:0.7091 | F1:0.1894\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:39:13,225 INFO: Epoch:[041/070]\n",
      "2022-04-15 10:39:13,226 INFO: Train Loss:1.618 | Acc:0.7515 | F1:0.2240\n",
      "2022-04-15 10:39:14,852 INFO: val Loss:1.537 | Acc:0.7273 | F1:0.3029\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:39:26,947 INFO: Epoch:[042/070]\n",
      "2022-04-15 10:39:26,947 INFO: Train Loss:1.548 | Acc:0.7945 | F1:0.2656\n",
      "2022-04-15 10:39:28,673 INFO: val Loss:1.500 | Acc:0.7636 | F1:0.4203\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.52it/s]\n",
      "2022-04-15 10:39:40,345 INFO: Epoch:[043/070]\n",
      "2022-04-15 10:39:40,346 INFO: Train Loss:1.516 | Acc:0.7485 | F1:0.2508\n",
      "2022-04-15 10:39:42,022 INFO: val Loss:1.463 | Acc:0.6364 | F1:0.3484\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.45it/s]\n",
      "2022-04-15 10:39:53,912 INFO: Epoch:[044/070]\n",
      "2022-04-15 10:39:53,913 INFO: Train Loss:1.555 | Acc:0.7515 | F1:0.2951\n",
      "2022-04-15 10:39:55,468 INFO: val Loss:1.310 | Acc:0.7273 | F1:0.4028\n",
      "2022-04-15 10:39:56,313 INFO: -----------------SAVE:44epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.47it/s]\n",
      "2022-04-15 10:40:08,154 INFO: Epoch:[045/070]\n",
      "2022-04-15 10:40:08,155 INFO: Train Loss:1.495 | Acc:0.7791 | F1:0.3725\n",
      "2022-04-15 10:40:09,889 INFO: val Loss:1.416 | Acc:0.6182 | F1:0.3172\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:40:21,859 INFO: Epoch:[046/070]\n",
      "2022-04-15 10:40:21,859 INFO: Train Loss:1.410 | Acc:0.7607 | F1:0.2960\n",
      "2022-04-15 10:40:23,534 INFO: val Loss:1.269 | Acc:0.8000 | F1:0.4370\n",
      "2022-04-15 10:40:24,384 INFO: -----------------SAVE:46epoch----------------\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:40:36,473 INFO: Epoch:[047/070]\n",
      "2022-04-15 10:40:36,473 INFO: Train Loss:1.438 | Acc:0.8037 | F1:0.3128\n",
      "2022-04-15 10:40:38,062 INFO: val Loss:1.248 | Acc:0.8182 | F1:0.5109\n",
      "2022-04-15 10:40:38,982 INFO: -----------------SAVE:47epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.50it/s]\n",
      "2022-04-15 10:40:50,700 INFO: Epoch:[048/070]\n",
      "2022-04-15 10:40:50,701 INFO: Train Loss:1.395 | Acc:0.8190 | F1:0.3522\n",
      "2022-04-15 10:40:52,307 INFO: val Loss:1.474 | Acc:0.5455 | F1:0.2492\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.39it/s]\n",
      "2022-04-15 10:41:04,418 INFO: Epoch:[049/070]\n",
      "2022-04-15 10:41:04,418 INFO: Train Loss:1.511 | Acc:0.7791 | F1:0.3538\n",
      "2022-04-15 10:41:06,108 INFO: val Loss:1.333 | Acc:0.6727 | F1:0.4330\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.44it/s]\n",
      "2022-04-15 10:41:18,039 INFO: Epoch:[050/070]\n",
      "2022-04-15 10:41:18,040 INFO: Train Loss:1.423 | Acc:0.8190 | F1:0.3253\n",
      "2022-04-15 10:41:19,768 INFO: val Loss:1.254 | Acc:0.9273 | F1:0.6058\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.46it/s]\n",
      "2022-04-15 10:41:31,619 INFO: Epoch:[051/070]\n",
      "2022-04-15 10:41:31,619 INFO: Train Loss:1.496 | Acc:0.7975 | F1:0.2715\n",
      "2022-04-15 10:41:33,231 INFO: val Loss:1.332 | Acc:0.8909 | F1:0.5688\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.56it/s]\n",
      "2022-04-15 10:41:44,762 INFO: Epoch:[052/070]\n",
      "2022-04-15 10:41:44,763 INFO: Train Loss:1.453 | Acc:0.7945 | F1:0.3665\n",
      "2022-04-15 10:41:46,435 INFO: val Loss:1.369 | Acc:0.9273 | F1:0.6281\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.53it/s]\n",
      "2022-04-15 10:41:58,068 INFO: Epoch:[053/070]\n",
      "2022-04-15 10:41:58,068 INFO: Train Loss:1.417 | Acc:0.8067 | F1:0.3727\n",
      "2022-04-15 10:41:59,760 INFO: val Loss:1.345 | Acc:0.8182 | F1:0.4926\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.46it/s]\n",
      "2022-04-15 10:42:11,617 INFO: Epoch:[054/070]\n",
      "2022-04-15 10:42:11,618 INFO: Train Loss:1.375 | Acc:0.8221 | F1:0.4095\n",
      "2022-04-15 10:42:13,190 INFO: val Loss:1.588 | Acc:0.8000 | F1:0.4458\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.38it/s]\n",
      "2022-04-15 10:42:25,325 INFO: Epoch:[055/070]\n",
      "2022-04-15 10:42:25,326 INFO: Train Loss:1.434 | Acc:0.8006 | F1:0.3431\n",
      "2022-04-15 10:42:26,903 INFO: val Loss:1.244 | Acc:0.8727 | F1:0.5375\n",
      "2022-04-15 10:42:27,827 INFO: -----------------SAVE:55epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.55it/s]\n",
      "2022-04-15 10:42:39,370 INFO: Epoch:[056/070]\n",
      "2022-04-15 10:42:39,370 INFO: Train Loss:1.327 | Acc:0.7975 | F1:0.3657\n",
      "2022-04-15 10:42:40,931 INFO: val Loss:1.246 | Acc:0.8727 | F1:0.5652\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.48it/s]\n",
      "2022-04-15 10:42:52,712 INFO: Epoch:[057/070]\n",
      "2022-04-15 10:42:52,713 INFO: Train Loss:1.371 | Acc:0.7791 | F1:0.3543\n",
      "2022-04-15 10:42:54,328 INFO: val Loss:1.294 | Acc:0.8909 | F1:0.5410\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.52it/s]\n",
      "2022-04-15 10:43:05,995 INFO: Epoch:[058/070]\n",
      "2022-04-15 10:43:05,996 INFO: Train Loss:1.400 | Acc:0.7975 | F1:0.3718\n",
      "2022-04-15 10:43:07,606 INFO: val Loss:1.245 | Acc:0.8909 | F1:0.5410\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.47it/s]\n",
      "2022-04-15 10:43:19,439 INFO: Epoch:[059/070]\n",
      "2022-04-15 10:43:19,439 INFO: Train Loss:1.452 | Acc:0.7914 | F1:0.3608\n",
      "2022-04-15 10:43:21,227 INFO: val Loss:1.194 | Acc:0.8727 | F1:0.5391\n",
      "2022-04-15 10:43:22,076 INFO: -----------------SAVE:59epoch----------------\n",
      "100%|██████████| 41/41 [00:12<00:00,  3.37it/s]\n",
      "2022-04-15 10:43:34,265 INFO: Epoch:[060/070]\n",
      "2022-04-15 10:43:34,266 INFO: Train Loss:1.305 | Acc:0.8129 | F1:0.3934\n",
      "2022-04-15 10:43:35,869 INFO: val Loss:1.178 | Acc:0.9273 | F1:0.6597\n",
      "2022-04-15 10:43:36,716 INFO: -----------------SAVE:60epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:43:48,681 INFO: Epoch:[061/070]\n",
      "2022-04-15 10:43:48,682 INFO: Train Loss:1.343 | Acc:0.8313 | F1:0.3906\n",
      "2022-04-15 10:43:50,359 INFO: val Loss:1.222 | Acc:0.9273 | F1:0.6058\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.47it/s]\n",
      "2022-04-15 10:44:02,174 INFO: Epoch:[062/070]\n",
      "2022-04-15 10:44:02,174 INFO: Train Loss:1.389 | Acc:0.8098 | F1:0.3790\n",
      "2022-04-15 10:44:03,782 INFO: val Loss:1.197 | Acc:0.8909 | F1:0.5410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:12<00:00,  3.41it/s]\n",
      "2022-04-15 10:44:15,832 INFO: Epoch:[063/070]\n",
      "2022-04-15 10:44:15,832 INFO: Train Loss:1.368 | Acc:0.8067 | F1:0.4152\n",
      "2022-04-15 10:44:17,555 INFO: val Loss:1.231 | Acc:0.8727 | F1:0.5391\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.42it/s]\n",
      "2022-04-15 10:44:29,552 INFO: Epoch:[064/070]\n",
      "2022-04-15 10:44:29,553 INFO: Train Loss:1.538 | Acc:0.7914 | F1:0.2987\n",
      "2022-04-15 10:44:31,246 INFO: val Loss:1.193 | Acc:0.8727 | F1:0.5447\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.42it/s]\n",
      "2022-04-15 10:44:43,247 INFO: Epoch:[065/070]\n",
      "2022-04-15 10:44:43,252 INFO: Train Loss:1.375 | Acc:0.8313 | F1:0.4634\n",
      "2022-04-15 10:44:44,867 INFO: val Loss:1.141 | Acc:0.9091 | F1:0.5762\n",
      "2022-04-15 10:44:45,727 INFO: -----------------SAVE:65epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.47it/s]\n",
      "2022-04-15 10:44:57,558 INFO: Epoch:[066/070]\n",
      "2022-04-15 10:44:57,559 INFO: Train Loss:1.310 | Acc:0.8497 | F1:0.4762\n",
      "2022-04-15 10:44:59,091 INFO: val Loss:1.191 | Acc:0.8909 | F1:0.5727\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.55it/s]\n",
      "2022-04-15 10:45:10,661 INFO: Epoch:[067/070]\n",
      "2022-04-15 10:45:10,662 INFO: Train Loss:1.324 | Acc:0.8037 | F1:0.4133\n",
      "2022-04-15 10:45:12,289 INFO: val Loss:1.138 | Acc:0.9273 | F1:0.6058\n",
      "2022-04-15 10:45:13,151 INFO: -----------------SAVE:67epoch----------------\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.51it/s]\n",
      "2022-04-15 10:45:24,845 INFO: Epoch:[068/070]\n",
      "2022-04-15 10:45:24,846 INFO: Train Loss:1.340 | Acc:0.7945 | F1:0.3603\n",
      "2022-04-15 10:45:26,514 INFO: val Loss:1.424 | Acc:0.8909 | F1:0.5190\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.42it/s]\n",
      "2022-04-15 10:45:38,507 INFO: Epoch:[069/070]\n",
      "2022-04-15 10:45:38,508 INFO: Train Loss:1.533 | Acc:0.7699 | F1:0.3356\n",
      "2022-04-15 10:45:40,092 INFO: val Loss:1.278 | Acc:0.8727 | F1:0.4544\n",
      "100%|██████████| 41/41 [00:11<00:00,  3.43it/s]\n",
      "2022-04-15 10:45:52,063 INFO: Epoch:[070/070]\n",
      "2022-04-15 10:45:52,064 INFO: Train Loss:1.395 | Acc:0.7577 | F1:0.3182\n",
      "2022-04-15 10:45:53,785 INFO: val Loss:1.199 | Acc:0.8909 | F1:0.5577\n",
      "2022-04-15 10:45:53,787 INFO: \n",
      "Best Val Epoch:67 | Val Loss:1.1380 | Val Acc:0.9273 | Val F1:0.6058\n",
      "2022-04-15 10:45:53,787 INFO: Total Process time:16.136Minute\n",
      "2022-04-15 10:45:53,812 INFO: {'exp_num': '0', 'class_name': 'cable', 'class_num': 9, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name  class      state            label\n",
      "0        8  10008.png  cable  bent_wire  cable-bent_wire\n",
      "1       14  10014.png  cable       good       cable-good\n",
      "2       32  10032.png  cable       good       cable-good\n",
      "3       38  10038.png  cable       good       cable-good\n",
      "4       39  10039.png  cable       good       cable-good\n",
      "..     ...        ...    ...        ...              ...\n",
      "266   4207  14207.png  cable       good       cable-good\n",
      "267   4212  14212.png  cable       good       cable-good\n",
      "268   4238  14238.png  cable       good       cable-good\n",
      "269   4241  14241.png  cable       good       cable-good\n",
      "270   4251  14251.png  cable   combined   cable-combined\n",
      "\n",
      "[271 rows x 5 columns]\n",
      "good                    224\n",
      "bent_wire                 7\n",
      "cut_inner_insulation      7\n",
      "cable_swap                6\n",
      "combined                  6\n",
      "missing_cable             6\n",
      "cut_outer_insulation      5\n",
      "missing_wire              5\n",
      "poke_insulation           5\n",
      "Name: state, dtype: int64\n",
      "9\n",
      "<---- Training Params ---->\n",
      "Dataset size:232\n",
      "Dataset size:39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:45:54,261 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:46:03,716 INFO: Epoch:[001/070]\n",
      "2022-04-15 10:46:03,716 INFO: Train Loss:2.174 | Acc:0.0647 | F1:0.0161\n",
      "2022-04-15 10:46:05,561 INFO: val Loss:2.206 | Acc:0.0256 | F1:0.0064\n",
      "2022-04-15 10:46:06,410 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.07it/s]\n",
      "2022-04-15 10:46:15,856 INFO: Epoch:[002/070]\n",
      "2022-04-15 10:46:15,857 INFO: Train Loss:2.203 | Acc:0.0819 | F1:0.0301\n",
      "2022-04-15 10:46:17,728 INFO: val Loss:2.194 | Acc:0.0513 | F1:0.0127\n",
      "2022-04-15 10:46:18,672 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 10:46:27,915 INFO: Epoch:[003/070]\n",
      "2022-04-15 10:46:27,915 INFO: Train Loss:2.184 | Acc:0.1078 | F1:0.0634\n",
      "2022-04-15 10:46:29,720 INFO: val Loss:2.181 | Acc:0.0256 | F1:0.0064\n",
      "2022-04-15 10:46:30,544 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:46:39,708 INFO: Epoch:[004/070]\n",
      "2022-04-15 10:46:39,709 INFO: Train Loss:2.166 | Acc:0.0862 | F1:0.0341\n",
      "2022-04-15 10:46:41,561 INFO: val Loss:2.166 | Acc:0.1282 | F1:0.0329\n",
      "2022-04-15 10:46:42,397 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.19it/s]\n",
      "2022-04-15 10:46:51,490 INFO: Epoch:[005/070]\n",
      "2022-04-15 10:46:51,490 INFO: Train Loss:2.177 | Acc:0.1164 | F1:0.0278\n",
      "2022-04-15 10:46:53,389 INFO: val Loss:2.181 | Acc:0.1282 | F1:0.0285\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 10:47:02,581 INFO: Epoch:[006/070]\n",
      "2022-04-15 10:47:02,582 INFO: Train Loss:2.158 | Acc:0.1293 | F1:0.0473\n",
      "2022-04-15 10:47:04,377 INFO: val Loss:2.176 | Acc:0.1026 | F1:0.0263\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 10:47:13,408 INFO: Epoch:[007/070]\n",
      "2022-04-15 10:47:13,409 INFO: Train Loss:2.167 | Acc:0.2026 | F1:0.0957\n",
      "2022-04-15 10:47:15,263 INFO: val Loss:2.177 | Acc:0.2308 | F1:0.0465\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:47:24,285 INFO: Epoch:[008/070]\n",
      "2022-04-15 10:47:24,285 INFO: Train Loss:2.148 | Acc:0.1638 | F1:0.0372\n",
      "2022-04-15 10:47:26,156 INFO: val Loss:2.172 | Acc:0.2564 | F1:0.0505\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:47:35,171 INFO: Epoch:[009/070]\n",
      "2022-04-15 10:47:35,172 INFO: Train Loss:2.182 | Acc:0.2198 | F1:0.0464\n",
      "2022-04-15 10:47:36,977 INFO: val Loss:2.167 | Acc:0.2821 | F1:0.0520\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.18it/s]\n",
      "2022-04-15 10:47:46,103 INFO: Epoch:[010/070]\n",
      "2022-04-15 10:47:46,103 INFO: Train Loss:2.161 | Acc:0.2543 | F1:0.0729\n",
      "2022-04-15 10:47:47,974 INFO: val Loss:2.138 | Acc:0.4615 | F1:0.0714\n",
      "2022-04-15 10:47:48,842 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.18it/s]\n",
      "2022-04-15 10:47:57,978 INFO: Epoch:[011/070]\n",
      "2022-04-15 10:47:57,978 INFO: Train Loss:2.137 | Acc:0.3750 | F1:0.0669\n",
      "2022-04-15 10:47:59,838 INFO: val Loss:2.175 | Acc:0.4359 | F1:0.0687\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.19it/s]\n",
      "2022-04-15 10:48:08,942 INFO: Epoch:[012/070]\n",
      "2022-04-15 10:48:08,943 INFO: Train Loss:2.083 | Acc:0.4871 | F1:0.0814\n",
      "2022-04-15 10:48:10,730 INFO: val Loss:2.110 | Acc:0.6667 | F1:0.1000\n",
      "2022-04-15 10:48:11,594 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:48:20,750 INFO: Epoch:[013/070]\n",
      "2022-04-15 10:48:20,751 INFO: Train Loss:2.086 | Acc:0.6466 | F1:0.1111\n",
      "2022-04-15 10:48:22,621 INFO: val Loss:2.108 | Acc:0.7949 | F1:0.1107\n",
      "2022-04-15 10:48:23,474 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.03it/s]\n",
      "2022-04-15 10:48:33,043 INFO: Epoch:[014/070]\n",
      "2022-04-15 10:48:33,044 INFO: Train Loss:2.081 | Acc:0.7069 | F1:0.1390\n",
      "2022-04-15 10:48:34,834 INFO: val Loss:2.037 | Acc:0.7949 | F1:0.1107\n",
      "2022-04-15 10:48:35,683 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:48:44,910 INFO: Epoch:[015/070]\n",
      "2022-04-15 10:48:44,910 INFO: Train Loss:2.019 | Acc:0.7457 | F1:0.1405\n",
      "2022-04-15 10:48:46,762 INFO: val Loss:2.030 | Acc:0.8205 | F1:0.1127\n",
      "2022-04-15 10:48:47,700 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.18it/s]\n",
      "2022-04-15 10:48:56,827 INFO: Epoch:[016/070]\n",
      "2022-04-15 10:48:56,828 INFO: Train Loss:2.053 | Acc:0.6983 | F1:0.0990\n",
      "2022-04-15 10:48:58,665 INFO: val Loss:2.052 | Acc:0.8205 | F1:0.1127\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:49:07,819 INFO: Epoch:[017/070]\n",
      "2022-04-15 10:49:07,820 INFO: Train Loss:2.003 | Acc:0.7241 | F1:0.0952\n",
      "2022-04-15 10:49:09,630 INFO: val Loss:2.054 | Acc:0.8205 | F1:0.1127\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.13it/s]\n",
      "2022-04-15 10:49:18,902 INFO: Epoch:[018/070]\n",
      "2022-04-15 10:49:18,903 INFO: Train Loss:1.951 | Acc:0.7586 | F1:0.1280\n",
      "2022-04-15 10:49:20,759 INFO: val Loss:2.031 | Acc:0.8205 | F1:0.1127\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:49:29,905 INFO: Epoch:[019/070]\n",
      "2022-04-15 10:49:29,906 INFO: Train Loss:1.927 | Acc:0.8233 | F1:0.1637\n",
      "2022-04-15 10:49:31,789 INFO: val Loss:2.073 | Acc:0.8205 | F1:0.1127\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.14it/s]\n",
      "2022-04-15 10:49:41,036 INFO: Epoch:[020/070]\n",
      "2022-04-15 10:49:41,037 INFO: Train Loss:1.928 | Acc:0.8276 | F1:0.2023\n",
      "2022-04-15 10:49:42,841 INFO: val Loss:2.013 | Acc:0.7949 | F1:0.0984\n",
      "2022-04-15 10:49:43,720 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.23it/s]\n",
      "2022-04-15 10:49:52,707 INFO: Epoch:[021/070]\n",
      "2022-04-15 10:49:52,707 INFO: Train Loss:1.865 | Acc:0.8276 | F1:0.1847\n",
      "2022-04-15 10:49:54,605 INFO: val Loss:1.960 | Acc:0.8205 | F1:0.1127\n",
      "2022-04-15 10:49:55,467 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.13it/s]\n",
      "2022-04-15 10:50:04,740 INFO: Epoch:[022/070]\n",
      "2022-04-15 10:50:04,740 INFO: Train Loss:1.879 | Acc:0.8362 | F1:0.2188\n",
      "2022-04-15 10:50:06,571 INFO: val Loss:1.949 | Acc:0.8205 | F1:0.1127\n",
      "2022-04-15 10:50:07,401 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 10:50:16,579 INFO: Epoch:[023/070]\n",
      "2022-04-15 10:50:16,580 INFO: Train Loss:1.812 | Acc:0.8319 | F1:0.1696\n",
      "2022-04-15 10:50:18,414 INFO: val Loss:1.889 | Acc:0.8205 | F1:0.1127\n",
      "2022-04-15 10:50:19,266 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.19it/s]\n",
      "2022-04-15 10:50:28,361 INFO: Epoch:[024/070]\n",
      "2022-04-15 10:50:28,362 INFO: Train Loss:1.804 | Acc:0.8103 | F1:0.2633\n",
      "2022-04-15 10:50:30,177 INFO: val Loss:1.788 | Acc:0.8205 | F1:0.1127\n",
      "2022-04-15 10:50:31,025 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 10:50:40,089 INFO: Epoch:[025/070]\n",
      "2022-04-15 10:50:40,090 INFO: Train Loss:1.790 | Acc:0.8233 | F1:0.2942\n",
      "2022-04-15 10:50:41,872 INFO: val Loss:1.919 | Acc:0.8205 | F1:0.1127\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.07it/s]\n",
      "2022-04-15 10:50:51,313 INFO: Epoch:[026/070]\n",
      "2022-04-15 10:50:51,313 INFO: Train Loss:1.663 | Acc:0.8621 | F1:0.3839\n",
      "2022-04-15 10:50:53,181 INFO: val Loss:1.797 | Acc:0.8718 | F1:0.3659\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.06it/s]\n",
      "2022-04-15 10:51:02,674 INFO: Epoch:[027/070]\n",
      "2022-04-15 10:51:02,675 INFO: Train Loss:1.776 | Acc:0.8448 | F1:0.2763\n",
      "2022-04-15 10:51:04,536 INFO: val Loss:1.705 | Acc:0.8718 | F1:0.3659\n",
      "2022-04-15 10:51:05,377 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:51:14,394 INFO: Epoch:[028/070]\n",
      "2022-04-15 10:51:14,394 INFO: Train Loss:1.700 | Acc:0.7931 | F1:0.2919\n",
      "2022-04-15 10:51:16,291 INFO: val Loss:1.689 | Acc:0.8718 | F1:0.3659\n",
      "2022-04-15 10:51:17,138 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:51:26,163 INFO: Epoch:[029/070]\n",
      "2022-04-15 10:51:26,163 INFO: Train Loss:1.605 | Acc:0.8147 | F1:0.4182\n",
      "2022-04-15 10:51:28,059 INFO: val Loss:1.632 | Acc:0.8974 | F1:0.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:51:28,902 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.08it/s]\n",
      "2022-04-15 10:51:38,314 INFO: Epoch:[030/070]\n",
      "2022-04-15 10:51:38,315 INFO: Train Loss:1.558 | Acc:0.8362 | F1:0.3797\n",
      "2022-04-15 10:51:40,016 INFO: val Loss:1.608 | Acc:0.8718 | F1:0.3659\n",
      "2022-04-15 10:51:40,913 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 10:51:49,946 INFO: Epoch:[031/070]\n",
      "2022-04-15 10:51:49,946 INFO: Train Loss:1.541 | Acc:0.8578 | F1:0.5008\n",
      "2022-04-15 10:51:51,880 INFO: val Loss:1.508 | Acc:0.8718 | F1:0.4091\n",
      "2022-04-15 10:51:52,711 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:52:01,914 INFO: Epoch:[032/070]\n",
      "2022-04-15 10:52:01,915 INFO: Train Loss:1.461 | Acc:0.8448 | F1:0.4740\n",
      "2022-04-15 10:52:03,820 INFO: val Loss:1.403 | Acc:0.9231 | F1:0.5795\n",
      "2022-04-15 10:52:04,643 INFO: -----------------SAVE:32epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:52:13,870 INFO: Epoch:[033/070]\n",
      "2022-04-15 10:52:13,871 INFO: Train Loss:1.450 | Acc:0.8707 | F1:0.4737\n",
      "2022-04-15 10:52:15,688 INFO: val Loss:1.317 | Acc:0.9231 | F1:0.6194\n",
      "2022-04-15 10:52:16,546 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 10:52:25,724 INFO: Epoch:[034/070]\n",
      "2022-04-15 10:52:25,725 INFO: Train Loss:1.500 | Acc:0.8190 | F1:0.4153\n",
      "2022-04-15 10:52:27,563 INFO: val Loss:1.595 | Acc:0.8205 | F1:0.3785\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.19it/s]\n",
      "2022-04-15 10:52:36,661 INFO: Epoch:[035/070]\n",
      "2022-04-15 10:52:36,662 INFO: Train Loss:1.413 | Acc:0.7845 | F1:0.3181\n",
      "2022-04-15 10:52:38,453 INFO: val Loss:1.416 | Acc:0.7436 | F1:0.4125\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.11it/s]\n",
      "2022-04-15 10:52:47,791 INFO: Epoch:[036/070]\n",
      "2022-04-15 10:52:47,792 INFO: Train Loss:1.411 | Acc:0.8448 | F1:0.4703\n",
      "2022-04-15 10:52:49,685 INFO: val Loss:1.294 | Acc:0.8205 | F1:0.5523\n",
      "2022-04-15 10:52:50,625 INFO: -----------------SAVE:36epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.11it/s]\n",
      "2022-04-15 10:52:59,953 INFO: Epoch:[037/070]\n",
      "2022-04-15 10:52:59,953 INFO: Train Loss:1.301 | Acc:0.8060 | F1:0.3799\n",
      "2022-04-15 10:53:01,871 INFO: val Loss:1.200 | Acc:0.7949 | F1:0.4010\n",
      "2022-04-15 10:53:02,717 INFO: -----------------SAVE:37epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.13it/s]\n",
      "2022-04-15 10:53:12,006 INFO: Epoch:[038/070]\n",
      "2022-04-15 10:53:12,006 INFO: Train Loss:1.344 | Acc:0.8276 | F1:0.4484\n",
      "2022-04-15 10:53:13,828 INFO: val Loss:1.094 | Acc:0.8462 | F1:0.4692\n",
      "2022-04-15 10:53:14,692 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.12it/s]\n",
      "2022-04-15 10:53:23,996 INFO: Epoch:[039/070]\n",
      "2022-04-15 10:53:23,997 INFO: Train Loss:1.414 | Acc:0.7629 | F1:0.3884\n",
      "2022-04-15 10:53:25,850 INFO: val Loss:1.269 | Acc:0.7436 | F1:0.5886\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.23it/s]\n",
      "2022-04-15 10:53:34,838 INFO: Epoch:[040/070]\n",
      "2022-04-15 10:53:34,839 INFO: Train Loss:1.352 | Acc:0.8276 | F1:0.4930\n",
      "2022-04-15 10:53:36,799 INFO: val Loss:1.302 | Acc:0.6923 | F1:0.5496\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 10:53:45,876 INFO: Epoch:[041/070]\n",
      "2022-04-15 10:53:45,877 INFO: Train Loss:1.190 | Acc:0.8060 | F1:0.4887\n",
      "2022-04-15 10:53:47,794 INFO: val Loss:1.261 | Acc:0.6154 | F1:0.3829\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:53:56,820 INFO: Epoch:[042/070]\n",
      "2022-04-15 10:53:56,821 INFO: Train Loss:1.386 | Acc:0.7888 | F1:0.4502\n",
      "2022-04-15 10:53:58,798 INFO: val Loss:1.026 | Acc:0.8462 | F1:0.6375\n",
      "2022-04-15 10:53:59,670 INFO: -----------------SAVE:42epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:54:08,686 INFO: Epoch:[043/070]\n",
      "2022-04-15 10:54:08,687 INFO: Train Loss:1.191 | Acc:0.8190 | F1:0.4969\n",
      "2022-04-15 10:54:10,430 INFO: val Loss:0.998 | Acc:0.8462 | F1:0.5128\n",
      "2022-04-15 10:54:11,283 INFO: -----------------SAVE:43epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:54:20,440 INFO: Epoch:[044/070]\n",
      "2022-04-15 10:54:20,441 INFO: Train Loss:1.214 | Acc:0.8319 | F1:0.5276\n",
      "2022-04-15 10:54:22,311 INFO: val Loss:0.969 | Acc:0.8718 | F1:0.6814\n",
      "2022-04-15 10:54:23,195 INFO: -----------------SAVE:44epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.13it/s]\n",
      "2022-04-15 10:54:32,471 INFO: Epoch:[045/070]\n",
      "2022-04-15 10:54:32,472 INFO: Train Loss:1.333 | Acc:0.8233 | F1:0.4873\n",
      "2022-04-15 10:54:34,369 INFO: val Loss:0.988 | Acc:0.8974 | F1:0.6710\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.07it/s]\n",
      "2022-04-15 10:54:43,817 INFO: Epoch:[046/070]\n",
      "2022-04-15 10:54:43,818 INFO: Train Loss:1.663 | Acc:0.7500 | F1:0.2254\n",
      "2022-04-15 10:54:45,654 INFO: val Loss:0.838 | Acc:0.8974 | F1:0.7522\n",
      "2022-04-15 10:54:46,517 INFO: -----------------SAVE:46epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.22it/s]\n",
      "2022-04-15 10:54:55,542 INFO: Epoch:[047/070]\n",
      "2022-04-15 10:54:55,543 INFO: Train Loss:1.236 | Acc:0.8448 | F1:0.4642\n",
      "2022-04-15 10:54:57,335 INFO: val Loss:1.011 | Acc:0.8974 | F1:0.6293\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.12it/s]\n",
      "2022-04-15 10:55:06,651 INFO: Epoch:[048/070]\n",
      "2022-04-15 10:55:06,652 INFO: Train Loss:1.173 | Acc:0.8276 | F1:0.4893\n",
      "2022-04-15 10:55:08,506 INFO: val Loss:0.992 | Acc:0.9487 | F1:0.7064\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 10:55:17,696 INFO: Epoch:[049/070]\n",
      "2022-04-15 10:55:17,697 INFO: Train Loss:1.019 | Acc:0.8836 | F1:0.6137\n",
      "2022-04-15 10:55:19,576 INFO: val Loss:0.699 | Acc:0.9487 | F1:0.7897\n",
      "2022-04-15 10:55:20,447 INFO: -----------------SAVE:49epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:55:29,595 INFO: Epoch:[050/070]\n",
      "2022-04-15 10:55:29,596 INFO: Train Loss:1.430 | Acc:0.8405 | F1:0.4467\n",
      "2022-04-15 10:55:31,487 INFO: val Loss:0.689 | Acc:0.9744 | F1:0.8333\n",
      "2022-04-15 10:55:32,312 INFO: -----------------SAVE:50epoch----------------\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.27it/s]\n",
      "2022-04-15 10:55:41,186 INFO: Epoch:[051/070]\n",
      "2022-04-15 10:55:41,186 INFO: Train Loss:1.056 | Acc:0.8491 | F1:0.5223\n",
      "2022-04-15 10:55:43,011 INFO: val Loss:0.769 | Acc:0.8205 | F1:0.5876\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.20it/s]\n",
      "2022-04-15 10:55:52,094 INFO: Epoch:[052/070]\n",
      "2022-04-15 10:55:52,095 INFO: Train Loss:0.936 | Acc:0.9009 | F1:0.6566\n",
      "2022-04-15 10:55:54,091 INFO: val Loss:0.680 | Acc:0.8462 | F1:0.7335\n",
      "2022-04-15 10:55:54,939 INFO: -----------------SAVE:52epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 10:56:03,991 INFO: Epoch:[053/070]\n",
      "2022-04-15 10:56:03,991 INFO: Train Loss:1.398 | Acc:0.8276 | F1:0.4188\n",
      "2022-04-15 10:56:05,905 INFO: val Loss:0.707 | Acc:0.8205 | F1:0.6499\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.17it/s]\n",
      "2022-04-15 10:56:15,051 INFO: Epoch:[054/070]\n",
      "2022-04-15 10:56:15,052 INFO: Train Loss:1.239 | Acc:0.8707 | F1:0.5937\n",
      "2022-04-15 10:56:16,900 INFO: val Loss:0.696 | Acc:0.9231 | F1:0.7668\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.03it/s]\n",
      "2022-04-15 10:56:26,491 INFO: Epoch:[055/070]\n",
      "2022-04-15 10:56:26,491 INFO: Train Loss:1.125 | Acc:0.8621 | F1:0.5303\n",
      "2022-04-15 10:56:28,293 INFO: val Loss:0.661 | Acc:0.9744 | F1:0.8333\n",
      "2022-04-15 10:56:29,162 INFO: -----------------SAVE:55epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:56:38,366 INFO: Epoch:[056/070]\n",
      "2022-04-15 10:56:38,367 INFO: Train Loss:1.340 | Acc:0.8147 | F1:0.4590\n",
      "2022-04-15 10:56:40,206 INFO: val Loss:0.773 | Acc:0.8718 | F1:0.6814\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.29it/s]\n",
      "2022-04-15 10:56:49,039 INFO: Epoch:[057/070]\n",
      "2022-04-15 10:56:49,039 INFO: Train Loss:1.166 | Acc:0.8405 | F1:0.5097\n",
      "2022-04-15 10:56:50,841 INFO: val Loss:0.750 | Acc:0.8974 | F1:0.7522\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.28it/s]\n",
      "2022-04-15 10:56:59,679 INFO: Epoch:[058/070]\n",
      "2022-04-15 10:56:59,680 INFO: Train Loss:1.307 | Acc:0.7931 | F1:0.4280\n",
      "2022-04-15 10:57:01,549 INFO: val Loss:0.609 | Acc:0.9231 | F1:0.7668\n",
      "2022-04-15 10:57:02,410 INFO: -----------------SAVE:58epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.11it/s]\n",
      "2022-04-15 10:57:11,745 INFO: Epoch:[059/070]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:57:11,745 INFO: Train Loss:1.149 | Acc:0.8405 | F1:0.5080\n",
      "2022-04-15 10:57:13,605 INFO: val Loss:0.578 | Acc:0.9487 | F1:0.7897\n",
      "2022-04-15 10:57:14,470 INFO: -----------------SAVE:59epoch----------------\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.12it/s]\n",
      "2022-04-15 10:57:23,775 INFO: Epoch:[060/070]\n",
      "2022-04-15 10:57:23,776 INFO: Train Loss:0.887 | Acc:0.8534 | F1:0.5825\n",
      "2022-04-15 10:57:25,632 INFO: val Loss:0.621 | Acc:0.8718 | F1:0.7000\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.11it/s]\n",
      "2022-04-15 10:57:34,973 INFO: Epoch:[061/070]\n",
      "2022-04-15 10:57:34,974 INFO: Train Loss:1.066 | Acc:0.8664 | F1:0.5631\n",
      "2022-04-15 10:57:36,822 INFO: val Loss:0.627 | Acc:0.8974 | F1:0.7522\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.13it/s]\n",
      "2022-04-15 10:57:46,109 INFO: Epoch:[062/070]\n",
      "2022-04-15 10:57:46,110 INFO: Train Loss:1.249 | Acc:0.8750 | F1:0.5733\n",
      "2022-04-15 10:57:47,942 INFO: val Loss:0.625 | Acc:0.9487 | F1:0.7897\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.05it/s]\n",
      "2022-04-15 10:57:57,469 INFO: Epoch:[063/070]\n",
      "2022-04-15 10:57:57,470 INFO: Train Loss:1.151 | Acc:0.7931 | F1:0.4645\n",
      "2022-04-15 10:57:59,234 INFO: val Loss:0.591 | Acc:0.9744 | F1:0.8333\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.16it/s]\n",
      "2022-04-15 10:58:08,420 INFO: Epoch:[064/070]\n",
      "2022-04-15 10:58:08,421 INFO: Train Loss:0.983 | Acc:0.8621 | F1:0.5996\n",
      "2022-04-15 10:58:10,319 INFO: val Loss:0.655 | Acc:0.9487 | F1:0.7897\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.15it/s]\n",
      "2022-04-15 10:58:19,538 INFO: Epoch:[065/070]\n",
      "2022-04-15 10:58:19,539 INFO: Train Loss:1.149 | Acc:0.8707 | F1:0.5364\n",
      "2022-04-15 10:58:21,360 INFO: val Loss:0.625 | Acc:0.9744 | F1:0.8333\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.05it/s]\n",
      "2022-04-15 10:58:30,890 INFO: Epoch:[066/070]\n",
      "2022-04-15 10:58:30,890 INFO: Train Loss:1.110 | Acc:0.8060 | F1:0.4269\n",
      "2022-04-15 10:58:32,723 INFO: val Loss:0.699 | Acc:0.9487 | F1:0.7897\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.21it/s]\n",
      "2022-04-15 10:58:41,772 INFO: Epoch:[067/070]\n",
      "2022-04-15 10:58:41,773 INFO: Train Loss:0.868 | Acc:0.8491 | F1:0.5400\n",
      "2022-04-15 10:58:43,578 INFO: val Loss:0.701 | Acc:0.9231 | F1:0.6628\n",
      "100%|██████████| 29/29 [00:08<00:00,  3.23it/s]\n",
      "2022-04-15 10:58:52,576 INFO: Epoch:[068/070]\n",
      "2022-04-15 10:58:52,577 INFO: Train Loss:0.966 | Acc:0.8621 | F1:0.5907\n",
      "2022-04-15 10:58:54,556 INFO: val Loss:0.611 | Acc:0.9231 | F1:0.7668\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.08it/s]\n",
      "2022-04-15 10:59:03,981 INFO: Epoch:[069/070]\n",
      "2022-04-15 10:59:03,982 INFO: Train Loss:1.012 | Acc:0.8879 | F1:0.6123\n",
      "2022-04-15 10:59:05,799 INFO: val Loss:0.597 | Acc:0.9487 | F1:0.7897\n",
      "100%|██████████| 29/29 [00:09<00:00,  3.06it/s]\n",
      "2022-04-15 10:59:15,293 INFO: Epoch:[070/070]\n",
      "2022-04-15 10:59:15,294 INFO: Train Loss:1.045 | Acc:0.8664 | F1:0.5320\n",
      "2022-04-15 10:59:17,081 INFO: val Loss:0.627 | Acc:0.8462 | F1:0.7335\n",
      "2022-04-15 10:59:17,082 INFO: \n",
      "Best Val Epoch:59 | Val Loss:0.5785 | Val Acc:0.9487 | Val F1:0.7897\n",
      "2022-04-15 10:59:17,083 INFO: Total Process time:13.376Minute\n",
      "2022-04-15 10:59:17,108 INFO: {'exp_num': '0', 'class_name': 'carpet', 'class_num': 6, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name   class  state         label\n",
      "0       10  10010.png  carpet   hole   carpet-hole\n",
      "1       41  10041.png  carpet   good   carpet-good\n",
      "2       50  10050.png  carpet   good   carpet-good\n",
      "3       51  10051.png  carpet   good   carpet-good\n",
      "4       57  10057.png  carpet   good   carpet-good\n",
      "..     ...        ...     ...    ...           ...\n",
      "322   4156  14156.png  carpet   good   carpet-good\n",
      "323   4182  14182.png  carpet  color  carpet-color\n",
      "324   4213  14213.png  carpet  color  carpet-color\n",
      "325   4225  14225.png  carpet   good   carpet-good\n",
      "326   4229  14229.png  carpet   good   carpet-good\n",
      "\n",
      "[327 rows x 5 columns]\n",
      "good                   280\n",
      "thread                  10\n",
      "color                   10\n",
      "metal_contamination      9\n",
      "hole                     9\n",
      "cut                      9\n",
      "Name: state, dtype: int64\n",
      "6\n",
      "<---- Training Params ---->\n",
      "Dataset size:280\n",
      "Dataset size:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 10:59:17,560 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.12it/s]\n",
      "2022-04-15 10:59:29,036 INFO: Epoch:[001/070]\n",
      "2022-04-15 10:59:29,037 INFO: Train Loss:1.823 | Acc:0.0179 | F1:0.0508\n",
      "2022-04-15 10:59:31,045 INFO: val Loss:1.825 | Acc:0.0213 | F1:0.0098\n",
      "2022-04-15 10:59:31,888 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.30it/s]\n",
      "2022-04-15 10:59:42,490 INFO: Epoch:[002/070]\n",
      "2022-04-15 10:59:42,490 INFO: Train Loss:1.804 | Acc:0.0357 | F1:0.0327\n",
      "2022-04-15 10:59:44,461 INFO: val Loss:1.837 | Acc:0.0213 | F1:0.0076\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n",
      "2022-04-15 10:59:55,183 INFO: Epoch:[003/070]\n",
      "2022-04-15 10:59:55,183 INFO: Train Loss:1.825 | Acc:0.0143 | F1:0.0115\n",
      "2022-04-15 10:59:57,298 INFO: val Loss:1.806 | Acc:0.0213 | F1:0.0076\n",
      "2022-04-15 10:59:58,123 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.31it/s]\n",
      "2022-04-15 11:00:08,717 INFO: Epoch:[004/070]\n",
      "2022-04-15 11:00:08,717 INFO: Train Loss:1.795 | Acc:0.0250 | F1:0.0407\n",
      "2022-04-15 11:00:10,851 INFO: val Loss:1.832 | Acc:0.0213 | F1:0.0076\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.42it/s]\n",
      "2022-04-15 11:00:21,106 INFO: Epoch:[005/070]\n",
      "2022-04-15 11:00:21,107 INFO: Train Loss:1.793 | Acc:0.0250 | F1:0.0232\n",
      "2022-04-15 11:00:23,113 INFO: val Loss:1.812 | Acc:0.0213 | F1:0.0079\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.29it/s]\n",
      "2022-04-15 11:00:33,774 INFO: Epoch:[006/070]\n",
      "2022-04-15 11:00:33,775 INFO: Train Loss:1.810 | Acc:0.0214 | F1:0.0212\n",
      "2022-04-15 11:00:35,853 INFO: val Loss:1.805 | Acc:0.0426 | F1:0.0169\n",
      "2022-04-15 11:00:36,698 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.32it/s]\n",
      "2022-04-15 11:00:47,247 INFO: Epoch:[007/070]\n",
      "2022-04-15 11:00:47,248 INFO: Train Loss:1.787 | Acc:0.0393 | F1:0.0311\n",
      "2022-04-15 11:00:49,231 INFO: val Loss:1.798 | Acc:0.0213 | F1:0.0098\n",
      "2022-04-15 11:00:50,137 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n",
      "2022-04-15 11:01:00,964 INFO: Epoch:[008/070]\n",
      "2022-04-15 11:01:00,965 INFO: Train Loss:1.781 | Acc:0.0429 | F1:0.0466\n",
      "2022-04-15 11:01:03,033 INFO: val Loss:1.807 | Acc:0.0638 | F1:0.0317\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.31it/s]\n",
      "2022-04-15 11:01:13,608 INFO: Epoch:[009/070]\n",
      "2022-04-15 11:01:13,609 INFO: Train Loss:1.801 | Acc:0.0536 | F1:0.0471\n",
      "2022-04-15 11:01:15,601 INFO: val Loss:1.810 | Acc:0.0851 | F1:0.0314\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n",
      "2022-04-15 11:01:26,331 INFO: Epoch:[010/070]\n",
      "2022-04-15 11:01:26,332 INFO: Train Loss:1.807 | Acc:0.0607 | F1:0.0414\n",
      "2022-04-15 11:01:28,453 INFO: val Loss:1.776 | Acc:0.1915 | F1:0.0679\n",
      "2022-04-15 11:01:29,297 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n",
      "2022-04-15 11:01:40,111 INFO: Epoch:[011/070]\n",
      "2022-04-15 11:01:40,112 INFO: Train Loss:1.766 | Acc:0.1179 | F1:0.0531\n",
      "2022-04-15 11:01:42,116 INFO: val Loss:1.754 | Acc:0.6170 | F1:0.2028\n",
      "2022-04-15 11:01:42,896 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n",
      "2022-04-15 11:01:53,862 INFO: Epoch:[012/070]\n",
      "2022-04-15 11:01:53,863 INFO: Train Loss:1.755 | Acc:0.2321 | F1:0.0953\n",
      "2022-04-15 11:01:55,819 INFO: val Loss:1.764 | Acc:0.4255 | F1:0.1214\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n",
      "2022-04-15 11:02:06,859 INFO: Epoch:[013/070]\n",
      "2022-04-15 11:02:06,859 INFO: Train Loss:1.755 | Acc:0.2679 | F1:0.0900\n",
      "2022-04-15 11:02:08,862 INFO: val Loss:1.752 | Acc:0.5957 | F1:0.1906\n",
      "2022-04-15 11:02:09,696 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n",
      "2022-04-15 11:02:20,396 INFO: Epoch:[014/070]\n",
      "2022-04-15 11:02:20,396 INFO: Train Loss:1.760 | Acc:0.3536 | F1:0.1056\n",
      "2022-04-15 11:02:22,486 INFO: val Loss:1.734 | Acc:0.4681 | F1:0.1314\n",
      "2022-04-15 11:02:23,348 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.33it/s]\n",
      "2022-04-15 11:02:33,859 INFO: Epoch:[015/070]\n",
      "2022-04-15 11:02:33,860 INFO: Train Loss:1.728 | Acc:0.4643 | F1:0.1415\n",
      "2022-04-15 11:02:35,913 INFO: val Loss:1.726 | Acc:0.5319 | F1:0.1488\n",
      "2022-04-15 11:02:36,818 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.16it/s]\n",
      "2022-04-15 11:02:47,901 INFO: Epoch:[016/070]\n",
      "2022-04-15 11:02:47,902 INFO: Train Loss:1.726 | Acc:0.5536 | F1:0.1402\n",
      "2022-04-15 11:02:49,982 INFO: val Loss:1.694 | Acc:0.7660 | F1:0.1558\n",
      "2022-04-15 11:02:50,825 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.16it/s]\n",
      "2022-04-15 11:03:01,900 INFO: Epoch:[017/070]\n",
      "2022-04-15 11:03:01,901 INFO: Train Loss:1.757 | Acc:0.6286 | F1:0.1618\n",
      "2022-04-15 11:03:03,916 INFO: val Loss:1.645 | Acc:0.8298 | F1:0.1974\n",
      "2022-04-15 11:03:04,768 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.28it/s]\n",
      "2022-04-15 11:03:15,453 INFO: Epoch:[018/070]\n",
      "2022-04-15 11:03:15,454 INFO: Train Loss:1.663 | Acc:0.7286 | F1:0.1883\n",
      "2022-04-15 11:03:17,358 INFO: val Loss:1.642 | Acc:0.7660 | F1:0.1813\n",
      "2022-04-15 11:03:18,216 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n",
      "2022-04-15 11:03:28,963 INFO: Epoch:[019/070]\n",
      "2022-04-15 11:03:28,964 INFO: Train Loss:1.657 | Acc:0.7286 | F1:0.1996\n",
      "2022-04-15 11:03:31,047 INFO: val Loss:1.576 | Acc:0.7872 | F1:0.1857\n",
      "2022-04-15 11:03:31,940 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n",
      "2022-04-15 11:03:42,748 INFO: Epoch:[020/070]\n",
      "2022-04-15 11:03:42,748 INFO: Train Loss:1.685 | Acc:0.6964 | F1:0.1567\n",
      "2022-04-15 11:03:44,777 INFO: val Loss:1.480 | Acc:0.7660 | F1:0.2899\n",
      "2022-04-15 11:03:45,626 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n",
      "2022-04-15 11:03:56,555 INFO: Epoch:[021/070]\n",
      "2022-04-15 11:03:56,556 INFO: Train Loss:1.703 | Acc:0.7893 | F1:0.1667\n",
      "2022-04-15 11:03:58,608 INFO: val Loss:1.512 | Acc:0.8511 | F1:0.3105\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n",
      "2022-04-15 11:04:09,440 INFO: Epoch:[022/070]\n",
      "2022-04-15 11:04:09,441 INFO: Train Loss:1.649 | Acc:0.7464 | F1:0.1800\n",
      "2022-04-15 11:04:11,398 INFO: val Loss:1.422 | Acc:0.8085 | F1:0.4124\n",
      "2022-04-15 11:04:12,253 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n",
      "2022-04-15 11:04:23,117 INFO: Epoch:[023/070]\n",
      "2022-04-15 11:04:23,118 INFO: Train Loss:1.655 | Acc:0.7750 | F1:0.1838\n",
      "2022-04-15 11:04:25,148 INFO: val Loss:1.437 | Acc:0.7872 | F1:0.2944\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n",
      "2022-04-15 11:04:36,084 INFO: Epoch:[024/070]\n",
      "2022-04-15 11:04:36,085 INFO: Train Loss:1.676 | Acc:0.7786 | F1:0.1918\n",
      "2022-04-15 11:04:38,134 INFO: val Loss:1.443 | Acc:0.8511 | F1:0.2365\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n",
      "2022-04-15 11:04:49,237 INFO: Epoch:[025/070]\n",
      "2022-04-15 11:04:49,237 INFO: Train Loss:1.655 | Acc:0.8143 | F1:0.2388\n",
      "2022-04-15 11:04:51,151 INFO: val Loss:1.485 | Acc:0.6809 | F1:0.3345\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n",
      "2022-04-15 11:05:01,933 INFO: Epoch:[026/070]\n",
      "2022-04-15 11:05:01,933 INFO: Train Loss:1.672 | Acc:0.7786 | F1:0.2124\n",
      "2022-04-15 11:05:03,970 INFO: val Loss:1.546 | Acc:0.4043 | F1:0.1735\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.20it/s]\n",
      "2022-04-15 11:05:14,899 INFO: Epoch:[027/070]\n",
      "2022-04-15 11:05:14,899 INFO: Train Loss:1.575 | Acc:0.8214 | F1:0.2152\n",
      "2022-04-15 11:05:16,892 INFO: val Loss:1.431 | Acc:0.8936 | F1:0.2407\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n",
      "2022-04-15 11:05:27,805 INFO: Epoch:[028/070]\n",
      "2022-04-15 11:05:27,806 INFO: Train Loss:1.567 | Acc:0.8071 | F1:0.2398\n",
      "2022-04-15 11:05:29,773 INFO: val Loss:1.392 | Acc:0.8936 | F1:0.2407\n",
      "2022-04-15 11:05:30,614 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.14it/s]\n",
      "2022-04-15 11:05:41,757 INFO: Epoch:[029/070]\n",
      "2022-04-15 11:05:41,758 INFO: Train Loss:1.679 | Acc:0.8036 | F1:0.1946\n",
      "2022-04-15 11:05:43,816 INFO: val Loss:1.382 | Acc:0.8936 | F1:0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 11:05:44,679 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n",
      "2022-04-15 11:05:55,725 INFO: Epoch:[030/070]\n",
      "2022-04-15 11:05:55,726 INFO: Train Loss:1.668 | Acc:0.8143 | F1:0.2070\n",
      "2022-04-15 11:05:57,787 INFO: val Loss:1.339 | Acc:0.6809 | F1:0.2591\n",
      "2022-04-15 11:05:58,643 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n",
      "2022-04-15 11:06:09,697 INFO: Epoch:[031/070]\n",
      "2022-04-15 11:06:09,698 INFO: Train Loss:1.607 | Acc:0.8036 | F1:0.2056\n",
      "2022-04-15 11:06:11,621 INFO: val Loss:1.272 | Acc:0.9149 | F1:0.3611\n",
      "2022-04-15 11:06:12,536 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n",
      "2022-04-15 11:06:23,554 INFO: Epoch:[032/070]\n",
      "2022-04-15 11:06:23,555 INFO: Train Loss:1.614 | Acc:0.7786 | F1:0.3121\n",
      "2022-04-15 11:06:25,564 INFO: val Loss:1.330 | Acc:0.8511 | F1:0.3546\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.31it/s]\n",
      "2022-04-15 11:06:36,161 INFO: Epoch:[033/070]\n",
      "2022-04-15 11:06:36,161 INFO: Train Loss:1.605 | Acc:0.7679 | F1:0.2064\n",
      "2022-04-15 11:06:38,126 INFO: val Loss:1.282 | Acc:0.9149 | F1:0.3611\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n",
      "2022-04-15 11:06:49,004 INFO: Epoch:[034/070]\n",
      "2022-04-15 11:06:49,005 INFO: Train Loss:1.594 | Acc:0.7786 | F1:0.2533\n",
      "2022-04-15 11:06:50,998 INFO: val Loss:1.336 | Acc:0.8723 | F1:0.3476\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.16it/s]\n",
      "2022-04-15 11:07:02,085 INFO: Epoch:[035/070]\n",
      "2022-04-15 11:07:02,086 INFO: Train Loss:1.576 | Acc:0.8036 | F1:0.2888\n",
      "2022-04-15 11:07:04,014 INFO: val Loss:1.207 | Acc:0.9362 | F1:0.5397\n",
      "2022-04-15 11:07:04,862 INFO: -----------------SAVE:35epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.34it/s]\n",
      "2022-04-15 11:07:15,337 INFO: Epoch:[036/070]\n",
      "2022-04-15 11:07:15,338 INFO: Train Loss:1.561 | Acc:0.7786 | F1:0.2508\n",
      "2022-04-15 11:07:17,530 INFO: val Loss:1.321 | Acc:0.4255 | F1:0.2939\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n",
      "2022-04-15 11:07:28,363 INFO: Epoch:[037/070]\n",
      "2022-04-15 11:07:28,363 INFO: Train Loss:1.556 | Acc:0.7571 | F1:0.2886\n",
      "2022-04-15 11:07:30,438 INFO: val Loss:1.219 | Acc:0.3191 | F1:0.5380\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n",
      "2022-04-15 11:07:41,351 INFO: Epoch:[038/070]\n",
      "2022-04-15 11:07:41,352 INFO: Train Loss:1.560 | Acc:0.7821 | F1:0.3426\n",
      "2022-04-15 11:07:43,329 INFO: val Loss:1.182 | Acc:0.6596 | F1:0.5758\n",
      "2022-04-15 11:07:44,206 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.11it/s]\n",
      "2022-04-15 11:07:55,475 INFO: Epoch:[039/070]\n",
      "2022-04-15 11:07:55,475 INFO: Train Loss:1.618 | Acc:0.8321 | F1:0.3182\n",
      "2022-04-15 11:07:57,474 INFO: val Loss:1.201 | Acc:0.7021 | F1:0.4020\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.27it/s]\n",
      "2022-04-15 11:08:08,200 INFO: Epoch:[040/070]\n",
      "2022-04-15 11:08:08,201 INFO: Train Loss:1.508 | Acc:0.8036 | F1:0.3206\n",
      "2022-04-15 11:08:10,213 INFO: val Loss:1.201 | Acc:0.7447 | F1:0.4074\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n",
      "2022-04-15 11:08:20,980 INFO: Epoch:[041/070]\n",
      "2022-04-15 11:08:20,980 INFO: Train Loss:1.525 | Acc:0.7964 | F1:0.2873\n",
      "2022-04-15 11:08:23,040 INFO: val Loss:1.194 | Acc:0.6383 | F1:0.3932\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n",
      "2022-04-15 11:08:34,035 INFO: Epoch:[042/070]\n",
      "2022-04-15 11:08:34,035 INFO: Train Loss:1.559 | Acc:0.8036 | F1:0.3393\n",
      "2022-04-15 11:08:36,051 INFO: val Loss:1.151 | Acc:0.6809 | F1:0.3992\n",
      "2022-04-15 11:08:36,887 INFO: -----------------SAVE:42epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.33it/s]\n",
      "2022-04-15 11:08:47,419 INFO: Epoch:[043/070]\n",
      "2022-04-15 11:08:47,420 INFO: Train Loss:1.506 | Acc:0.7821 | F1:0.3032\n",
      "2022-04-15 11:08:49,424 INFO: val Loss:1.080 | Acc:0.8936 | F1:0.4243\n",
      "2022-04-15 11:08:50,282 INFO: -----------------SAVE:43epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n",
      "2022-04-15 11:09:01,064 INFO: Epoch:[044/070]\n",
      "2022-04-15 11:09:01,064 INFO: Train Loss:1.575 | Acc:0.7786 | F1:0.3023\n",
      "2022-04-15 11:09:03,156 INFO: val Loss:1.136 | Acc:0.8085 | F1:0.4151\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n",
      "2022-04-15 11:09:14,134 INFO: Epoch:[045/070]\n",
      "2022-04-15 11:09:14,135 INFO: Train Loss:1.549 | Acc:0.7786 | F1:0.3373\n",
      "2022-04-15 11:09:16,181 INFO: val Loss:1.156 | Acc:0.8511 | F1:0.6902\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n",
      "2022-04-15 11:09:27,301 INFO: Epoch:[046/070]\n",
      "2022-04-15 11:09:27,301 INFO: Train Loss:1.508 | Acc:0.7893 | F1:0.3930\n",
      "2022-04-15 11:09:29,440 INFO: val Loss:1.071 | Acc:0.9149 | F1:0.5291\n",
      "2022-04-15 11:09:30,328 INFO: -----------------SAVE:46epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.39it/s]\n",
      "2022-04-15 11:09:40,656 INFO: Epoch:[047/070]\n",
      "2022-04-15 11:09:40,656 INFO: Train Loss:1.434 | Acc:0.7429 | F1:0.3475\n",
      "2022-04-15 11:09:42,649 INFO: val Loss:0.963 | Acc:0.9574 | F1:0.5778\n",
      "2022-04-15 11:09:43,485 INFO: -----------------SAVE:47epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.30it/s]\n",
      "2022-04-15 11:09:54,089 INFO: Epoch:[048/070]\n",
      "2022-04-15 11:09:54,090 INFO: Train Loss:1.490 | Acc:0.7821 | F1:0.3526\n",
      "2022-04-15 11:09:56,206 INFO: val Loss:1.040 | Acc:0.9362 | F1:0.5479\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n",
      "2022-04-15 11:10:07,170 INFO: Epoch:[049/070]\n",
      "2022-04-15 11:10:07,170 INFO: Train Loss:1.505 | Acc:0.7393 | F1:0.3474\n",
      "2022-04-15 11:10:09,215 INFO: val Loss:1.039 | Acc:0.9362 | F1:0.4333\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.15it/s]\n",
      "2022-04-15 11:10:20,334 INFO: Epoch:[050/070]\n",
      "2022-04-15 11:10:20,335 INFO: Train Loss:1.396 | Acc:0.7857 | F1:0.4486\n",
      "2022-04-15 11:10:22,309 INFO: val Loss:1.005 | Acc:0.9574 | F1:0.9124\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.16it/s]\n",
      "2022-04-15 11:10:33,402 INFO: Epoch:[051/070]\n",
      "2022-04-15 11:10:33,403 INFO: Train Loss:1.432 | Acc:0.8143 | F1:0.4091\n",
      "2022-04-15 11:10:35,388 INFO: val Loss:1.043 | Acc:0.9362 | F1:0.6312\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.16it/s]\n",
      "2022-04-15 11:10:46,470 INFO: Epoch:[052/070]\n",
      "2022-04-15 11:10:46,471 INFO: Train Loss:1.483 | Acc:0.7821 | F1:0.3738\n",
      "2022-04-15 11:10:48,515 INFO: val Loss:1.018 | Acc:0.9787 | F1:0.7778\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n",
      "2022-04-15 11:10:59,373 INFO: Epoch:[053/070]\n",
      "2022-04-15 11:10:59,374 INFO: Train Loss:1.433 | Acc:0.8036 | F1:0.4729\n",
      "2022-04-15 11:11:01,438 INFO: val Loss:1.101 | Acc:0.9362 | F1:0.6646\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.11it/s]\n",
      "2022-04-15 11:11:12,709 INFO: Epoch:[054/070]\n",
      "2022-04-15 11:11:12,710 INFO: Train Loss:1.437 | Acc:0.8143 | F1:0.4446\n",
      "2022-04-15 11:11:14,725 INFO: val Loss:1.116 | Acc:0.9362 | F1:0.5931\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n",
      "2022-04-15 11:11:25,785 INFO: Epoch:[055/070]\n",
      "2022-04-15 11:11:25,786 INFO: Train Loss:1.493 | Acc:0.7786 | F1:0.3195\n",
      "2022-04-15 11:11:27,871 INFO: val Loss:1.060 | Acc:0.9362 | F1:0.5931\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n",
      "2022-04-15 11:11:38,637 INFO: Epoch:[056/070]\n",
      "2022-04-15 11:11:38,637 INFO: Train Loss:1.419 | Acc:0.8393 | F1:0.3380\n",
      "2022-04-15 11:11:40,715 INFO: val Loss:1.027 | Acc:0.9362 | F1:0.4444\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.33it/s]\n",
      "2022-04-15 11:11:51,243 INFO: Epoch:[057/070]\n",
      "2022-04-15 11:11:51,243 INFO: Train Loss:1.374 | Acc:0.8429 | F1:0.5019\n",
      "2022-04-15 11:11:53,264 INFO: val Loss:0.999 | Acc:0.9787 | F1:0.7778\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.24it/s]\n",
      "2022-04-15 11:12:04,075 INFO: Epoch:[058/070]\n",
      "2022-04-15 11:12:04,075 INFO: Train Loss:1.470 | Acc:0.8321 | F1:0.3861\n",
      "2022-04-15 11:12:06,066 INFO: val Loss:1.001 | Acc:0.9362 | F1:0.5931\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.21it/s]\n",
      "2022-04-15 11:12:16,968 INFO: Epoch:[059/070]\n",
      "2022-04-15 11:12:16,969 INFO: Train Loss:1.368 | Acc:0.8429 | F1:0.4658\n",
      "2022-04-15 11:12:19,109 INFO: val Loss:0.870 | Acc:0.9787 | F1:0.7778\n",
      "2022-04-15 11:12:20,000 INFO: -----------------SAVE:59epoch----------------\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.13it/s]\n",
      "2022-04-15 11:12:31,188 INFO: Epoch:[060/070]\n",
      "2022-04-15 11:12:31,188 INFO: Train Loss:1.331 | Acc:0.8536 | F1:0.4496\n",
      "2022-04-15 11:12:33,202 INFO: val Loss:0.927 | Acc:0.9787 | F1:0.8000\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.12it/s]\n",
      "2022-04-15 11:12:44,441 INFO: Epoch:[061/070]\n",
      "2022-04-15 11:12:44,442 INFO: Train Loss:1.395 | Acc:0.8321 | F1:0.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 11:12:46,371 INFO: val Loss:0.948 | Acc:0.9787 | F1:0.7778\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n",
      "2022-04-15 11:12:57,381 INFO: Epoch:[062/070]\n",
      "2022-04-15 11:12:57,382 INFO: Train Loss:1.486 | Acc:0.8500 | F1:0.4710\n",
      "2022-04-15 11:12:59,487 INFO: val Loss:0.883 | Acc:0.9787 | F1:0.7778\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.19it/s]\n",
      "2022-04-15 11:13:10,474 INFO: Epoch:[063/070]\n",
      "2022-04-15 11:13:10,475 INFO: Train Loss:1.459 | Acc:0.8536 | F1:0.4466\n",
      "2022-04-15 11:13:12,539 INFO: val Loss:1.053 | Acc:0.9787 | F1:0.8000\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.33it/s]\n",
      "2022-04-15 11:13:23,047 INFO: Epoch:[064/070]\n",
      "2022-04-15 11:13:23,048 INFO: Train Loss:1.486 | Acc:0.8464 | F1:0.4171\n",
      "2022-04-15 11:13:25,083 INFO: val Loss:0.910 | Acc:0.9787 | F1:0.8000\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.10it/s]\n",
      "2022-04-15 11:13:36,379 INFO: Epoch:[065/070]\n",
      "2022-04-15 11:13:36,380 INFO: Train Loss:1.281 | Acc:0.8714 | F1:0.5539\n",
      "2022-04-15 11:13:38,558 INFO: val Loss:0.922 | Acc:0.9787 | F1:0.7778\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n",
      "2022-04-15 11:13:49,447 INFO: Epoch:[066/070]\n",
      "2022-04-15 11:13:49,448 INFO: Train Loss:1.410 | Acc:0.8750 | F1:0.4735\n",
      "2022-04-15 11:13:51,465 INFO: val Loss:1.060 | Acc:0.9574 | F1:0.7423\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.22it/s]\n",
      "2022-04-15 11:14:02,336 INFO: Epoch:[067/070]\n",
      "2022-04-15 11:14:02,336 INFO: Train Loss:1.449 | Acc:0.8500 | F1:0.4908\n",
      "2022-04-15 11:14:04,391 INFO: val Loss:0.937 | Acc:0.9787 | F1:0.7778\n",
      "100%|██████████| 35/35 [00:11<00:00,  3.17it/s]\n",
      "2022-04-15 11:14:15,458 INFO: Epoch:[068/070]\n",
      "2022-04-15 11:14:15,458 INFO: Train Loss:1.377 | Acc:0.8536 | F1:0.5037\n",
      "2022-04-15 11:14:17,452 INFO: val Loss:0.896 | Acc:0.9787 | F1:0.7778\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.26it/s]\n",
      "2022-04-15 11:14:28,183 INFO: Epoch:[069/070]\n",
      "2022-04-15 11:14:28,183 INFO: Train Loss:1.374 | Acc:0.8786 | F1:0.5516\n",
      "2022-04-15 11:14:30,251 INFO: val Loss:0.832 | Acc:0.9787 | F1:0.7778\n",
      "2022-04-15 11:14:31,095 INFO: -----------------SAVE:69epoch----------------\n",
      "100%|██████████| 35/35 [00:10<00:00,  3.23it/s]\n",
      "2022-04-15 11:14:41,939 INFO: Epoch:[070/070]\n",
      "2022-04-15 11:14:41,939 INFO: Train Loss:1.417 | Acc:0.8286 | F1:0.4381\n",
      "2022-04-15 11:14:44,031 INFO: val Loss:0.883 | Acc:0.9787 | F1:0.7778\n",
      "2022-04-15 11:14:44,033 INFO: \n",
      "Best Val Epoch:69 | Val Loss:0.8322 | Val Acc:0.9787 | Val F1:0.7778\n",
      "2022-04-15 11:14:44,033 INFO: Total Process time:15.437Minute\n",
      "2022-04-15 11:14:44,059 INFO: {'exp_num': '0', 'class_name': 'hazelnut', 'class_num': 5, 'data_path': './open', 'Kfold': 7, 'model_path': 'results/', 'image_type': 'train_1024', 'model_name': 'regnety_064', 'drop_path_rate': 0.2, 'img_size': 352, 'batch_size': 8, 'epochs': 70, 'optimizer': 'Lamb', 'initial_lr': 4e-05, 'weight_decay': 0.0001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.0005, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': True, 'logging': False, 'num_workers': 4, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  file_name     class  state           label\n",
      "0       11  10011.png  hazelnut   good   hazelnut-good\n",
      "1       25  10025.png  hazelnut   good   hazelnut-good\n",
      "2       31  10031.png  hazelnut   good   hazelnut-good\n",
      "3       33  10033.png  hazelnut  crack  hazelnut-crack\n",
      "4       64  10064.png  hazelnut   good   hazelnut-good\n",
      "..     ...        ...       ...    ...             ...\n",
      "422   4256  14256.png  hazelnut   good   hazelnut-good\n",
      "423   4257  14257.png  hazelnut   good   hazelnut-good\n",
      "424   4258  14258.png  hazelnut   good   hazelnut-good\n",
      "425   4267  14267.png  hazelnut   good   hazelnut-good\n",
      "426   4268  14268.png  hazelnut   good   hazelnut-good\n",
      "\n",
      "[427 rows x 5 columns]\n",
      "good     391\n",
      "crack      9\n",
      "print      9\n",
      "hole       9\n",
      "cut        9\n",
      "Name: state, dtype: int64\n",
      "5\n",
      "<---- Training Params ---->\n",
      "Dataset size:366\n",
      "Dataset size:61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 11:14:44,496 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_064-0a48325c.pth)\n",
      " 98%|█████████▊| 45/46 [00:14<00:00,  3.19it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (6) to match target batch_size (8).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4db1e3f1e1a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mmodels_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-b8f019bfb66f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Create model directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-35fce6198ce0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, save_path)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# Model weight in Multi_GPU or Single GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-35fce6198ce0>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-2548f86d8659>\u001b[0m in \u001b[0;36mmixup_criterion\u001b[0;34m(criterion, pred, y_a, y_b, lam)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmixup_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (6) to match target batch_size (8)."
     ]
    }
   ],
   "source": [
    "args.step = 0\n",
    "models_path = []\n",
    "for class_name in class_list:\n",
    "    args.class_name = class_name\n",
    "    \n",
    "    train_df = pd.read_csv(os.path.join(DATA_DIR, 'train_df.csv'))\n",
    "    train_df = train_df[train_df['class'] == class_name]\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    print(train_df)\n",
    "\n",
    "    train_labels = train_df[\"state\"]\n",
    "    print(train_df[\"state\"].value_counts())\n",
    "\n",
    "    label_unique = sorted(np.unique(train_labels))\n",
    "    label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "    train_labels = [label_unique[k] for k in train_labels]\n",
    "    train_labels\n",
    "\n",
    "    train_df['state2'] = train_labels\n",
    "\n",
    "    train_df.to_csv('./open/train_df_%s.csv' % class_name, index=False)\n",
    "    \n",
    "    class_num = len(train_df['state2'].unique())\n",
    "    print(class_num)\n",
    "    args.class_num = class_num\n",
    "    \n",
    "    for s_fold in range(1): # 5fold\n",
    "        args.fold = s_fold\n",
    "        args.exp_num = str(s_fold)\n",
    "        save_path = main(args)\n",
    "        models_path.append(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
